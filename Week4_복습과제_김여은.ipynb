{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmbrNadxsBr7"
      },
      "source": [
        "## Convolution Layer Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAyG6GGTU_mC",
        "outputId": "05151d94-a950-4eeb-9d39-7b19ee36f94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "연산 전 torch.Size([10, 1, 20, 20])\n",
            "conv1 연산 후 torch.Size([10, 3, 16, 16])\n",
            "conv2 연산 후 torch.Size([10, 10, 12, 12])\n",
            "차원 감소 후 torch.Size([10, 1440])\n",
            "fc1 연산 후 torch.Size([10, 50])\n",
            "fc2 연산 후 torch.Size([10, 10])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    ## 조건1: conv layer 2개 & fc layer 2개\n",
        "    ## 조건2: kernel size=5, stride=1로 통일\n",
        "    ## output을 참고하여 차원을 계산해주세요!\n",
        "    ## 답안 ##\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5, stride=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5, stride=1)\n",
        "    self.fc1 = nn.Linear(10*12*12, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(\"연산 전\", x.size())\n",
        "    x = F.relu(self.conv1(x))\n",
        "    print(\"conv1 연산 후\", x.size())\n",
        "    x = F.relu(self.conv2(x))\n",
        "    print(\"conv2 연산 후\",x.size())\n",
        "    x = x.view(-1, 10 * 12 * 12)\n",
        "    print(\"차원 감소 후\", x.size())\n",
        "    x = F.relu(self.fc1(x))\n",
        "    print(\"fc1 연산 후\", x.size())\n",
        "    x = self.fc2(x)\n",
        "    print(\"fc2 연산 후\", x.size())\n",
        "    return x\n",
        "\n",
        "cnn = CNN()\n",
        "output = cnn(torch.randn(10, 1, 20, 20))  # Input Size: (10, 1, 20, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0It8H-mysBr-"
      },
      "source": [
        "## Max Pooling Layer Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkOwXPFNchie",
        "outputId": "00290cf9-2948-43d5-831f-b84cc2b4ab38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "연산 전 torch.Size([10, 1, 20, 20])\n",
            "max_pool1 연산 후 torch.Size([10, 1, 10, 10])\n",
            "max_pool2 연산 후 torch.Size([10, 1, 5, 5])\n",
            "차원 감소 후 torch.Size([1, 250])\n",
            "fc1 연산 후 torch.Size([1, 50])\n",
            "fc2 연산 후 torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    ## 조건1: 최대풀링 layer 2개 & fc layer 2개\n",
        "    ## 조건2: kernel size=2로 통일, stride는 따로 지정할 필요 없음\n",
        "    ## output을 참고하여 차원을 계산해주세요!\n",
        "    ## 답안 ##\n",
        "    self.max_pool1 = nn.MaxPool2d(kernel_size=2)  #20x20->10x10\n",
        "    self.max_pool2 = nn.MaxPool2d(kernel_size=2)  #10x10->5x5\n",
        "\n",
        "    self.fc1 = nn.Linear(10*5*5, 50)  #250->50\n",
        "    self.fc2 = nn.Linear(50, 10) #50->10\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(\"연산 전\", x.size())\n",
        "    x = F.relu(self.max_pool1(x))\n",
        "    print(\"max_pool1 연산 후\", x.size())\n",
        "    x = F.relu(self.max_pool2(x))\n",
        "    print(\"max_pool2 연산 후\",x.size())\n",
        "    x = x.view(-1, 10 * 5 * 5)\n",
        "    print(\"차원 감소 후\", x.size())\n",
        "    x = F.relu(self.fc1(x))\n",
        "    print(\"fc1 연산 후\", x.size())\n",
        "    x = self.fc2(x)\n",
        "    print(\"fc2 연산 후\", x.size())\n",
        "    return x\n",
        "\n",
        "cnn = CNN()\n",
        "output = cnn(torch.randn(10, 1, 20, 20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDMn2y5_sBr-"
      },
      "source": [
        "## MNIST 데이터셋 train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YhfopkrQcp1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf04f602-66ea-4862-d2ff-100d109268f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->torchvision) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CqFN5YM5cqKe"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IJb_C4ptcu6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87cc911f-6f9a-444a-c170-853f9c737ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 548kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.50MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.64MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.MNIST('./data/', train=True, download=True, transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])) # 학습 데이터\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=50, shuffle=True)\n",
        "\n",
        "test_data = datasets.MNIST('./data/', train=False, transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])) # 테스트 데이터\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=50, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YP3tEuo6ct8A"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        ## 조건1: conv layer 2개 & fc layer 2개\n",
        "            ## 첫 번째 conv layer: 입력 채널 1, 출력 채널 20\n",
        "            ## 두 번째 fc layer: 출력 채널 10\n",
        "        ## 조건2: kernel_size=5, stride=1\n",
        "        ## 답안 ##\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(50*4*4, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ## 조건1: relu -> max_pool2d -> relu -> max_pool2d 순서로 이루어짐\n",
        "        ## 조건2: kernel_size=2, stride=2\n",
        "        ## 답안 ##\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = x.view(-1, 4 * 4 * 50) # [batch_size, 50, 4, 4]\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EO2ULx3Sc2GM"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gAwckNWhc4Nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41cdc752-9c4d-4993-f783-96125b492504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss of 0 epoch, 0 index : 2.3149216175079346\n",
            "loss of 0 epoch, 100 index : 1.852768898010254\n",
            "loss of 0 epoch, 200 index : 0.5097163915634155\n",
            "loss of 0 epoch, 300 index : 0.15928427875041962\n",
            "loss of 0 epoch, 400 index : 0.3664044141769409\n",
            "loss of 0 epoch, 500 index : 0.35440391302108765\n",
            "loss of 0 epoch, 600 index : 0.09425690025091171\n",
            "loss of 0 epoch, 700 index : 0.14355945587158203\n",
            "loss of 0 epoch, 800 index : 0.10739117860794067\n",
            "loss of 0 epoch, 900 index : 0.3260100185871124\n",
            "loss of 0 epoch, 1000 index : 0.12697499990463257\n",
            "loss of 0 epoch, 1100 index : 0.09556528925895691\n",
            "loss of 1 epoch, 0 index : 0.17530490458011627\n",
            "loss of 1 epoch, 100 index : 0.046717338263988495\n",
            "loss of 1 epoch, 200 index : 0.13864047825336456\n",
            "loss of 1 epoch, 300 index : 0.24391122162342072\n",
            "loss of 1 epoch, 400 index : 0.18803024291992188\n",
            "loss of 1 epoch, 500 index : 0.06296250224113464\n",
            "loss of 1 epoch, 600 index : 0.11210749298334122\n",
            "loss of 1 epoch, 700 index : 0.05758848786354065\n",
            "loss of 1 epoch, 800 index : 0.07556289434432983\n",
            "loss of 1 epoch, 900 index : 0.011948803439736366\n",
            "loss of 1 epoch, 1000 index : 0.037936724722385406\n",
            "loss of 1 epoch, 1100 index : 0.13171140849590302\n",
            "loss of 2 epoch, 0 index : 0.02459820918738842\n",
            "loss of 2 epoch, 100 index : 0.013851926662027836\n",
            "loss of 2 epoch, 200 index : 0.10048255324363708\n",
            "loss of 2 epoch, 300 index : 0.11989303678274155\n",
            "loss of 2 epoch, 400 index : 0.02384081296622753\n",
            "loss of 2 epoch, 500 index : 0.06624166667461395\n",
            "loss of 2 epoch, 600 index : 0.1723855584859848\n",
            "loss of 2 epoch, 700 index : 0.34854722023010254\n",
            "loss of 2 epoch, 800 index : 0.04464533179998398\n",
            "loss of 2 epoch, 900 index : 0.19346895813941956\n",
            "loss of 2 epoch, 1000 index : 0.10642194002866745\n",
            "loss of 2 epoch, 1100 index : 0.024808280169963837\n",
            "loss of 3 epoch, 0 index : 0.09323950856924057\n",
            "loss of 3 epoch, 100 index : 0.011407331563532352\n",
            "loss of 3 epoch, 200 index : 0.013581872917711735\n",
            "loss of 3 epoch, 300 index : 0.011731970123946667\n",
            "loss of 3 epoch, 400 index : 0.06756290793418884\n",
            "loss of 3 epoch, 500 index : 0.03360361233353615\n",
            "loss of 3 epoch, 600 index : 0.17592506110668182\n",
            "loss of 3 epoch, 700 index : 0.008678779937326908\n",
            "loss of 3 epoch, 800 index : 0.05469431355595589\n",
            "loss of 3 epoch, 900 index : 0.024622807279229164\n",
            "loss of 3 epoch, 1000 index : 0.01100180670619011\n",
            "loss of 3 epoch, 1100 index : 0.04114381968975067\n",
            "loss of 4 epoch, 0 index : 0.025855224579572678\n",
            "loss of 4 epoch, 100 index : 0.09217305481433868\n",
            "loss of 4 epoch, 200 index : 0.020101601257920265\n",
            "loss of 4 epoch, 300 index : 0.060781899839639664\n",
            "loss of 4 epoch, 400 index : 0.03617367893457413\n",
            "loss of 4 epoch, 500 index : 0.09235736727714539\n",
            "loss of 4 epoch, 600 index : 0.029294254258275032\n",
            "loss of 4 epoch, 700 index : 0.020868048071861267\n",
            "loss of 4 epoch, 800 index : 0.030708713456988335\n",
            "loss of 4 epoch, 900 index : 0.010912860743701458\n",
            "loss of 4 epoch, 1000 index : 0.040836334228515625\n",
            "loss of 4 epoch, 1100 index : 0.025535382330417633\n",
            "loss of 5 epoch, 0 index : 0.03477131202816963\n",
            "loss of 5 epoch, 100 index : 0.0226863082498312\n",
            "loss of 5 epoch, 200 index : 0.047937650233507156\n",
            "loss of 5 epoch, 300 index : 0.01017819531261921\n",
            "loss of 5 epoch, 400 index : 0.04554221034049988\n",
            "loss of 5 epoch, 500 index : 0.01895037852227688\n",
            "loss of 5 epoch, 600 index : 0.005412572994828224\n",
            "loss of 5 epoch, 700 index : 0.007742522284388542\n",
            "loss of 5 epoch, 800 index : 0.006367498077452183\n",
            "loss of 5 epoch, 900 index : 0.03256692737340927\n",
            "loss of 5 epoch, 1000 index : 0.08222046494483948\n",
            "loss of 5 epoch, 1100 index : 0.0037307869642972946\n",
            "loss of 6 epoch, 0 index : 0.03951569274067879\n",
            "loss of 6 epoch, 100 index : 0.01474231481552124\n",
            "loss of 6 epoch, 200 index : 0.01894395239651203\n",
            "loss of 6 epoch, 300 index : 0.04134910926222801\n",
            "loss of 6 epoch, 400 index : 0.01323824655264616\n",
            "loss of 6 epoch, 500 index : 0.06213141605257988\n",
            "loss of 6 epoch, 600 index : 0.13605371117591858\n",
            "loss of 6 epoch, 700 index : 0.03420857712626457\n",
            "loss of 6 epoch, 800 index : 0.061162319034338\n",
            "loss of 6 epoch, 900 index : 0.02385435253381729\n",
            "loss of 6 epoch, 1000 index : 0.11894548684358597\n",
            "loss of 6 epoch, 1100 index : 0.01942520961165428\n",
            "loss of 7 epoch, 0 index : 0.01383107528090477\n",
            "loss of 7 epoch, 100 index : 0.021246083080768585\n",
            "loss of 7 epoch, 200 index : 0.011046061292290688\n",
            "loss of 7 epoch, 300 index : 0.004263346083462238\n",
            "loss of 7 epoch, 400 index : 0.008398286998271942\n",
            "loss of 7 epoch, 500 index : 0.1004355177283287\n",
            "loss of 7 epoch, 600 index : 0.13571912050247192\n",
            "loss of 7 epoch, 700 index : 0.010947011411190033\n",
            "loss of 7 epoch, 800 index : 0.06241076439619064\n",
            "loss of 7 epoch, 900 index : 0.043734945356845856\n",
            "loss of 7 epoch, 1000 index : 0.046184517443180084\n",
            "loss of 7 epoch, 1100 index : 0.02789180539548397\n",
            "loss of 8 epoch, 0 index : 0.043941713869571686\n",
            "loss of 8 epoch, 100 index : 0.004498298745602369\n",
            "loss of 8 epoch, 200 index : 0.06701835989952087\n",
            "loss of 8 epoch, 300 index : 0.08425818383693695\n",
            "loss of 8 epoch, 400 index : 0.03319732844829559\n",
            "loss of 8 epoch, 500 index : 0.09750593453645706\n",
            "loss of 8 epoch, 600 index : 0.01931079477071762\n",
            "loss of 8 epoch, 700 index : 0.006612793076783419\n",
            "loss of 8 epoch, 800 index : 0.022587258368730545\n",
            "loss of 8 epoch, 900 index : 0.012477017939090729\n",
            "loss of 8 epoch, 1000 index : 0.04333775117993355\n",
            "loss of 8 epoch, 1100 index : 0.009853897616267204\n",
            "loss of 9 epoch, 0 index : 0.010779288597404957\n",
            "loss of 9 epoch, 100 index : 0.040737804025411606\n",
            "loss of 9 epoch, 200 index : 0.0026842195075005293\n",
            "loss of 9 epoch, 300 index : 0.010809329338371754\n",
            "loss of 9 epoch, 400 index : 0.1036941334605217\n",
            "loss of 9 epoch, 500 index : 0.022739844396710396\n",
            "loss of 9 epoch, 600 index : 0.04960814118385315\n",
            "loss of 9 epoch, 700 index : 0.007546944543719292\n",
            "loss of 9 epoch, 800 index : 0.12527430057525635\n",
            "loss of 9 epoch, 900 index : 0.002489594044163823\n",
            "loss of 9 epoch, 1000 index : 0.005083112046122551\n",
            "loss of 9 epoch, 1100 index : 0.023213276639580727\n"
          ]
        }
      ],
      "source": [
        "cnn.train()  # 학습을 위함\n",
        "for epoch in range(10):\n",
        "  for index, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()  # 기울기 초기화\n",
        "    output = cnn(data)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()  # 역전파\n",
        "    optimizer.step()\n",
        "\n",
        "    if index % 100 == 0:\n",
        "      print(\"loss of {} epoch, {} index : {}\".format(epoch, index, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "l2PnlaXIc6dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0366962-2320-4bfa-e679-c0bf0355b353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 6.9654, Accuracy: 9890/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cnn.eval()  # test case 학습 방지를 위함\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for data, target in test_loader:\n",
        "    output = cnn(data)\n",
        "    test_loss += criterion(output, target).item() # sum up batch loss\n",
        "    pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}