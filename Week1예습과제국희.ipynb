{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RZ5mA1AIilgZ",
        "ThnUTIPCeRy-",
        "a67KtQkNijDs",
        "TrIss3SCzjE1",
        "0MqdzEGBrGND",
        "T-XUhuAss0NL",
        "nL_jSFXEtdFA",
        "Fdp7gWZTve6G"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2장"
      ],
      "metadata": {
        "id": "ojdOAeLWXY9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서 다루기"
      ],
      "metadata": {
        "id": "RZ5mA1AIilgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서 생성"
      ],
      "metadata": {
        "id": "H8m6N1PAcvNc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKsGGExzW6zV"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.tensor([[1,2],[3,4]]))  #2차원 형태의 텐서 생성\n",
        "print(torch.tensor([[1,2],[3,4]], device=\"cuda:0\"))  #gpu에 텐서 생성\n",
        "print(torch.tensor([[1,2],[3,4]],dtype=torch.float64))  #dtype을 이용하여 텐서 생성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agLRYEZMcP2W",
        "outputId": "9901b29a-a5c6-402a-833a-3796c8b4c0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]], device='cuda:0')\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서를 ndarray로 변환"
      ],
      "metadata": {
        "id": "Q6jCDjkKc0Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[1,2],[3,4]])\n",
        "print(temp.numpy())  #텐서를 ndarray로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBP4mvFzctdr",
        "outputId": "4ae181dd-c168-44c8-8061-700ce3f55e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\")\n",
        "print(temp.to(\"cpu\").numpy())  #gpu상의 텐서를 cpu의 텐서로 변환한 후 ndarray로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfbcndoVdjGS",
        "outputId": "2456855e-e724-4f50-f92a-7f124fc226dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서의 인덱스 조작"
      ],
      "metadata": {
        "id": "ThnUTIPCeRy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.FloatTensor([1,2,3,4,5,6,7])  #파이토치로 1차원 벡터 생성\n",
        "print(temp[0],temp[1],temp[-1])  #인덱스로 접근\n",
        "print('--------------------------')\n",
        "print(temp[2:5],temp[4:-1])  #슬라이스로 접근"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkP3caTxeVsM",
        "outputId": "f14bfabd-f27e-4006-c7fa-bcb86b7a2ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.) tensor(2.) tensor(7.)\n",
            "--------------------------\n",
            "tensor([3., 4., 5.]) tensor([5., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 벡터 두 개를 생성하여 사칙 연산"
      ],
      "metadata": {
        "id": "Xtu748IvfG_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([1,2,3])  #길이가 3인 벡터 생성\n",
        "w = torch.tensor([3,4,6])\n",
        "print(w-v)  #길이가 같은 벡터 간 뺄셈 연산"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgISsxX4fLJ8",
        "outputId": "2254d757-9d07-44ef-f790-701a67081803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서의 차원을 조작하는 코드"
      ],
      "metadata": {
        "id": "4ouisD1lf9b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([\n",
        "    [1,2],[3,4]])  #2*2 행렬 생성\n",
        "\n",
        "print(temp.shape)\n",
        "print('-----------------------')\n",
        "print(temp.view(4,1))  #2*2 행렬을 4*1로 변형\n",
        "print('-----------------------')\n",
        "print(temp.view(-1))  #2*2 행렬을 1차원 벡터로 변형\n",
        "print('-----------------------')\n",
        "print(temp.view(1,-1))  #-1은 (1,?)와 같은 의미로 다른 차원으로부터 해당 값을 유추하겠다는 것입니다. temp의 원소 개수(2*2=4)를 유지한 채 (1,?)의 형태를 만족해야 하므로 (1,4)가 됩니다.\n",
        "print('-----------------------')\n",
        "print(temp.view(-1,1))  #앞에서와 마찬가지로 (?,1)의 의미로 temp의 원소 개수(2*2=4)를 유지한 채 (?,1)의 형태를 만족해야 하므로 (4,1)이 됩니다.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcL04HTEgEXL",
        "outputId": "3fd2e4d8-7225-485b-8cff-cffc844f07fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "-----------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "-----------------------\n",
            "tensor([1, 2, 3, 4])\n",
            "-----------------------\n",
            "tensor([[1, 2, 3, 4]])\n",
            "-----------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비"
      ],
      "metadata": {
        "id": "a67KtQkNijDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 라이브러리 설치"
      ],
      "metadata": {
        "id": "pYvMeYMMjYuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtFzonIKjbzr",
        "outputId": "8cef5169-1421-4629-c433-6a3549d101e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라이브러리 호출"
      ],
      "metadata": {
        "id": "sbVwwDOglQT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  #pandas 라이브러리 호출\n",
        "import torch  #torch 라이브러리 호출\n",
        "data = pd.read_csv('../class2.csv')  #csv 파일을 불러옵니다.\n",
        "\n",
        "x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()  #csv 파일의 x칼럼의 값을 넘파이 배열로 받아 tensor(dtype)으로 바꾸어 줍니다.\n",
        "y = torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()  #csv 파일의 y칼럼의 값을 넘파이 배열로 받아 tensor(dtype)으로 바꾸어 줍니다."
      ],
      "metadata": {
        "id": "YeZHRoeZjhIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 커스텀 데이터셋을 만들어서 사용"
      ],
      "metadata": {
        "id": "qqI_kVELk7xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):  #필요한 변수를 선언하고, 데이터셋의 전처리를 해 주는 함수\n",
        "  def __len__(self):  #데이터셋의 길이. 즉, 총 샘플의 수를 가져오는 함수\n",
        "  def __getitem__(self, index):  #데이터셋에서 특정 데이터를 가져오는 함수(index번째 데이터를 변환하는 함수이며, 이때 반환되는 값은 텐서의 형태를 취해야 합니다.)"
      ],
      "metadata": {
        "id": "_6V15U6tlVmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 커스텀 데이터셋 구현 방법"
      ],
      "metadata": {
        "id": "iEU3zpzNopPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, csv_file):  #csv_file 파라미터를 통해 데이터셋을 불러옵니다.\n",
        "      self.label = pd.read_csv(csv_file)\n",
        "\n",
        "  def __len__(self): #전체 데이터셋의 크기(size)를 반환합니다.\n",
        "      return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):  #전체 x와 y 데이터 중에 해당 idx번째의 데이터를 가져옵니다.\n",
        "      sample = torch.tensor(self.label.iloc[idx,0:3]).int()\n",
        "      label = torch.tensor(self.label.iloc[idx,3]).int()\n",
        "      return sample,label\n",
        "\n",
        "tensor_dataset = CustomDataset('../covtype.csv')  #데이터셋으로 covtype.csv를 사용합니다.\n",
        "dataset = DataLoader(tensor_dataset, batch_size=4, shuffle=True)  #데이터셋을 torch.utils.data.DataLoader에 파라미터로 전달합니다."
      ],
      "metadata": {
        "id": "1gqBsynFsGRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(dataset,0):\n",
        "  print(i, end='')\n",
        "  batch=data[0]\n",
        "  print(batch.size())"
      ],
      "metadata": {
        "id": "nepRWJipwwmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### requests 라이브러리 설치"
      ],
      "metadata": {
        "id": "b9RX_JeIxGIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfxWponSxOK2",
        "outputId": "0e338f08-7582-4a21-fc8d-2c8c068dbc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST 데이터셋을 내려받음"
      ],
      "metadata": {
        "id": "mkgWbOrgxVNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(1.0,))\n",
        "])  #평균이 0.5, 표준편차가 1.0이 되도록 데이터의 분포(normalize)를 조정\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "import requests\n",
        "download_root = '../chap02/data/MNIST_DATASET'  #내려받을 경로 지정"
      ],
      "metadata": {
        "id": "xZAUoBnKxZ_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNIST(download_root, transform=mnist_transform, train=True,\n",
        "                      download=True)  #훈련(trainig) 데이터셋\n",
        "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False,\n",
        "                      download=True)  #검증(validation) 데이터셋\n",
        "test_dataset = MNIST(download_root, transform=mnist_transform, train= False,\n",
        "                     download=True)  #테스트(test) 데이터셋"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYTEbCc4ys6n",
        "outputId": "a83e76c5-b898-4e19-ffa6-bc4dd4303f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../chap02/data/MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 15257791.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../chap02/data/MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz to ../chap02/data/MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../chap02/data/MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 480011.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../chap02/data/MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz to ../chap02/data/MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../chap02/data/MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3670126.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../chap02/data/MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz to ../chap02/data/MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../chap02/data/MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 9724619.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../chap02/data/MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../chap02/data/MNIST_DATASET/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 정의"
      ],
      "metadata": {
        "id": "TrIss3SCzjE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단순 신경망을 정의하는 방법"
      ],
      "metadata": {
        "id": "yvNaCejzztcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(in_features=1, out_features=1, bias=True)"
      ],
      "metadata": {
        "id": "-h6qG-aEzpXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파이토치에서 모델을 정의하는 코드"
      ],
      "metadata": {
        "id": "eNPRj3Vnz-9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(Module):\n",
        "  def __init__(self, inputs):\n",
        "      super(MLP, self).__init__()\n",
        "      self.layer = Linear(inputs, 1)  #계층 정의\n",
        "      self.activation = Sigmoid()  #활성화 함수 정의\n",
        "\n",
        "  def forward(self, X):\n",
        "      X = self.layer(X)\n",
        "      X = self.activation(X)\n",
        "      return X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "8KYnptyr0DTX",
        "outputId": "8670daf8-00ac-431b-d018-e046f817200b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Module' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-65e257855dcf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#계층 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#활성화 함수 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Module' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sequential 신경망을 정의하는 방법"
      ],
      "metadata": {
        "id": "mgl1vLVymZzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    self.layer1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2))\n",
        "\n",
        "    self.layer2=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2))\n",
        "\n",
        "    self.layer3=nn.Sequential(\n",
        "        nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
        "        nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "      x= self.layer1(x)\n",
        "      x= self.layer2(x)\n",
        "      x=x.view(x.shape[0],-1)\n",
        "      x=self.layer3(x)\n",
        "      return x\n",
        "model = MLP()\n",
        "\n",
        "print(\"Printing children\\n-----------------\")\n",
        "print(list(model,children()))\n",
        "print(\"\\n\\nPrinting Modules\\n--------------\")\n",
        "print(list(model.modules()))"
      ],
      "metadata": {
        "id": "_p2BmdsFmZW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 함수로 신경망을 정의하는 방법"
      ],
      "metadata": {
        "id": "ZzCEgm13qM13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
        "  hidden = nn.Linear(in_features=in, out_features=hidden_features,\n",
        "                     bias=True)\n",
        "  activation = nn.ReLU()\n",
        "  output=nn.Linear(in_features=hidden_features, out_features=out_features,\n",
        "                   bias=True)\n",
        "  net = nn.Sequential(hidden, activation,output)\n",
        "  return net"
      ],
      "metadata": {
        "id": "LlyCFyGgqPxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델의 파라미터 정의"
      ],
      "metadata": {
        "id": "0MqdzEGBrGND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
        "                                              lr_lambda=lambda epoch: 0.95 ** epoch)\n",
        "for epoch in range(1, 100+1):  #에포크 수만큼 데이터를 반복하여 처리\n",
        "    for x, y in dataloader:  #배치 크기만큼 데이터를 가져와서 학습 진행\n",
        "        optimizer.zero_grad()\n",
        "loss_fn(model(x),y).backward()\n",
        "optimizer.step()\n",
        "scheduler.step()"
      ],
      "metadata": {
        "id": "g53q8VkArIV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련"
      ],
      "metadata": {
        "id": "T-XUhuAss0NL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  yhat = model(x_train)\n",
        "  loss = criterion(yhat, y_train)\n",
        "  optimizer.zero_grad()  #오차가 중첩적으로 쌓이지 않도록 초기화\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "ib3-hXHgs6oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가"
      ],
      "metadata": {
        "id": "nL_jSFXEtdFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 패키지 설치"
      ],
      "metadata": {
        "id": "awU_kbCOtgUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "id": "TwkJIzWFtijf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 함수를 이용하여 모델을 평가"
      ],
      "metadata": {
        "id": "b2BfvKq0tqrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchmetrixs\n",
        "\n",
        "preds = torch.randn(10, 5).softmax(dim=-1)\n",
        "target = torch.randint(5, (10,))\n",
        "\n",
        "acc = torchmetrics.functional.accuracy(preds, target)  #모델을 평가하기 위해 torchmetrics.functional.accuracy 이용\n"
      ],
      "metadata": {
        "id": "O-kWnSLYtv2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모듈을 이용하여 모델을 평가"
      ],
      "metadata": {
        "id": "tvXbMsY2ucbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchmetrics\n",
        "metric = torchmetrics.Accuracy()  #모델 평가(정확도) 초기화\n",
        "\n",
        "n_batches = 10\n",
        "for i in range(n_batches):\n",
        "   preds = torch.randn(10, 5).softmax(dim=-1)\n",
        "   target = torch.randint(5, (10,))\n",
        "\n",
        "   acc = metric(preds, target)\n",
        "   print(f\"Accuracy on batch {i}: {acc}\")  #현재 배치에서 모델 평가(정확도)\n",
        "\n",
        "acc = metric.compute()\n",
        "print(f\"Accuracy on all data: {acc}\")  #모든 배치에서 모델 평가(정확도)"
      ],
      "metadata": {
        "id": "-mXyuaVAuhhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련 과정 모니터링"
      ],
      "metadata": {
        "id": "Fdp7gWZTve6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorboard"
      ],
      "metadata": {
        "id": "16fsMbqXvkQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter(\"../chap02/tensorboard\")  #모니터링에 필요한 값들이 저장될 위치\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model,train()  #학습 모드로 전환(dropout=True)\n",
        "  batch_loss = 0.0\n",
        "\n",
        "  for i, (x, y) in enumerate(dataloader)\n",
        "      x, y = x.to(device).float(), y.to(device).float()\n",
        "      outputs = model(x)\n",
        "      loss = criterion(outputs, y)\n",
        "      writet.add_scalar(\"Loss\",loss, epoch)  #스칼라 값(오차)을 기록\n",
        "      optimizer,zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "writer.close()  #SummaryWriter가 더 이상 필요하지 않으면 close()메서드 호출"
      ],
      "metadata": {
        "id": "S42jJG9_voJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서보드 실행"
      ],
      "metadata": {
        "id": "xx3QXfs8xR1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard --logdir=../chap02/tensorboard -- port=6006\n",
        "\n",
        "#웹 브라우저에서 http://localhost:6006을 입력하면 웹페이지 나옴"
      ],
      "metadata": {
        "id": "suRyfsdZxVLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model.eval()에 대한 사용 방법"
      ],
      "metadata": {
        "id": "MvJsk5_mx0Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  #검증 모드로 전환(dropout=False)\n",
        "with torch.no_grad():  #1\n",
        "    valid_loss = 0\n",
        "\n",
        "    for x,y in valid_dataloader:\n",
        "      outputs = model(x)\n",
        "      loss = F.cross_entropy(outputs, y.long().squeeze())\n",
        "      valid_loss += float(loss)\n",
        "      y_hat +=[outputs]\n",
        "\n",
        "valid_loss = valid_loss / len(valid_loader)"
      ],
      "metadata": {
        "id": "-Ui5iPJ8x4nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 아나콘다 설치"
      ],
      "metadata": {
        "id": "54QxMwDhzFYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 가상 환경 생성 및 파이토치 설치"
      ],
      "metadata": {
        "id": "1ZL4Q8ebzQ70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가상 환경 만들기\n",
        "conda creat -n torch_book python=3.9.0\n",
        "\n",
        "# 가상 환경 확인\n",
        "conda env list\n",
        "\n",
        "# 가상 환경 활성화\n",
        "activate torch_book\n",
        "\n",
        "# 가상 환경 삭제\n",
        "conda env remove -n torch_book\n",
        "\n",
        "# 가상 환경에 커널 설치\n",
        "conda install ipykernel\n",
        "\n",
        "# 가상 환경에 커널 연결\n",
        "ipython kermel install --name tf2_book --user\n",
        "\n",
        "# 주피터 노트북 접속\n",
        "jupyter notebook"
      ],
      "metadata": {
        "id": "-DCjD5glzI7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파이토치 코드 맛보기"
      ],
      "metadata": {
        "id": "d3jwRP-0-gC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라이브러리 설치"
      ],
      "metadata": {
        "id": "1g4Pye7l-lsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib\n",
        "pip install seaborn\n",
        "pip install scikit-learn"
      ],
      "metadata": {
        "id": "8J3-F_1U-nyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 업그레이드"
      ],
      "metadata": {
        "id": "aADf01kR_788"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade matplotlib --use-feature=2020-resolver\n",
        "pip install --upgrade seaborn --use-feature=2020-resolver\n",
        "pip install --upgrade scikit-learn --use-feature=2020-resolver"
      ],
      "metadata": {
        "id": "i8VxCahhAADC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 라이브러리 호출"
      ],
      "metadata": {
        "id": "X_n8kpeUAa76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np  #벡터 및 행렬 연산에서 매우 편리한 기능을 제공하는 파이썬라이브러리 패키지\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "kGCYLW_mAf6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 호출"
      ],
      "metadata": {
        "id": "9D1kzDYMA2n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('../chap02/data/car_evaluation.csv')\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "Sdq-x0cZA40L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예제 데이터셋 분포"
      ],
      "metadata": {
        "id": "ErEjacjuBFbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig_size = plt.rcParams['figure.figsize']\n",
        "fig.size[0]=8\n",
        "fig.size[1]=6\n",
        "plt.rcParams[\"figure.figsize\"]=fig_size\n",
        "dataset.output.value_counts().plot(kind='pie',autopct='%0.05f%%',\n",
        "                                   colors=['lightblue','lightgreen','orange','pink'],explode=(0.05,0.05,0.05,0.05))"
      ],
      "metadata": {
        "id": "UShqP2eBBIJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터를 범주형 타입으로 변환"
      ],
      "metadata": {
        "id": "yi6baNAnCBx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns=['price','maint','doors','persons','lug_capacity','safety']  #예제 데이터셋 칼럼들의 목록\n",
        "\n",
        "for category in categorical_columns:\n",
        "  dataset[category]=dataset[category].astype('category')  #astype()매서드를 이용항 데이터를 범주형으로 변환\n",
        "\n",
        "  price = dataset['price'].cat.codes.values\n",
        "  maint=dataset['maint'].cat.codes.values\n",
        "  doors=dataset['doors'].cat.codes.values\n",
        "  person=dataset['persons'].cat.codes.values\n",
        "  lug_capacity=dataset['lug_capacity'].cat.codes.values\n",
        "  safety=dataset['safety'].cat.codes.values\n",
        "\n",
        "  categorical_data=np.stack([price,maint,doors,person,lug_capacity,safety],1)\n",
        "  categofical_data[:10]  #합친 넘파이 배열 중 열 개의 행을 출력하여 보여줍니다.\n",
        ""
      ],
      "metadata": {
        "id": "lpteoM65CEzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### np.stack과 np.concatenate"
      ],
      "metadata": {
        "id": "-QVKHXxFDjaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.array([[1,2],[3,4]])  #a.shape=(2,2)\n",
        "b=np.array([[5,6],[7,8]])  #b.shape=(2,2)\n",
        "c=np.array([[5,6],[7,8],[9,10]])  #c.shape=(3,2)\n",
        "\n",
        "print(np.concatenate((a,b),axis=0))  #shape=(4,2)\n",
        "print('-------------------')\n",
        "print(np.stack((a,b),axis=0))  #shape=(2,2,2)\n",
        "\n",
        "print(np.concatenate((a,c),axis=0))  #shape=(5,2)\n",
        "\n",
        "print(np.stack((a,c),axis=0))  #차원이 달라 오류발생"
      ],
      "metadata": {
        "id": "ciPZfdRIDqZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 배열을 텐서로 변환"
      ],
      "metadata": {
        "id": "29VfFpJ0Eo3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data = torch.tensor(categorical_data,dtype=torch.int64)\n",
        "categorical_data[:10]"
      ],
      "metadata": {
        "id": "FftJhOl5ErEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 레이블로 사용할 칼럼을 텐서로 변환"
      ],
      "metadata": {
        "id": "bh9pkmZgE3kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=pd.get_dumies(dataset.output)\n",
        "outputs=outputs.values\n",
        "outputs=torch.tensor(outputs).flatten()  #1차원 텐서로 변환\n",
        "\n",
        "print(categorical_data.shape)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "id": "yELNY-97E6hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 성별, 몸무게, 국적이라는 칼럼을 갖는 배열 생성"
      ],
      "metadata": {
        "id": "xUxIO73mFSCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    'gender' : ['male','female','male'],\n",
        "    'weight' : [72,55,68],\n",
        "    'nation' : ['Japan','Korea','Australia']\n",
        "    }\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "df\n",
        "\n",
        "#성별과 국적을 숫자로 변환\n",
        "pd.get_dumies(df)"
      ],
      "metadata": {
        "id": "XG1BR_c8FYYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### revel(),reshpe(),flatten()"
      ],
      "metadata": {
        "id": "2asEu0sOGXzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.array([[1,2],\n",
        "            [3,4]])\n",
        "print(a.revel())\n",
        "print(a.reshape(-1))\n",
        "print(a.flatten())"
      ],
      "metadata": {
        "id": "8fULE5AkGk47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "범주형 칼럼을 n차원으로 변환"
      ],
      "metadata": {
        "id": "rq7MOol-G0ZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns_sizes=[len(dataset[column].cat.categories) for column in categorical_columns]\n",
        "categorical_embedding_sizes=[(col_size,min(50,(col_size+1)//2)) for col_size in categorical_column_sizes]\n",
        "print(categorical_embedding_sizes)"
      ],
      "metadata": {
        "id": "7P733AUQG3EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 분리"
      ],
      "metadata": {
        "id": "lnCj3JPWHr2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_records=1728\n",
        "test_records=int(total_records * .2)  #전체 데이터 중 20%를 테스트 용도로 사용\n",
        "\n",
        "categorical_train_data=categorical_data[:total_records-test_records]\n",
        "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
        "train_outputs=outputs[:total_records-test_records]\n",
        "test_outputs=outputs[total_records-test_records:total_records]"
      ],
      "metadata": {
        "id": "9Skeh9_eHuII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 분리 확인"
      ],
      "metadata": {
        "id": "BOb7yif1IfYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(categorical_train_data))\n",
        "print(len(train_outputs))\n",
        "print(len(categorical_test_dat))\n",
        "print(len(test_outputs))"
      ],
      "metadata": {
        "id": "MGSSJEhJIh2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델의 네트워크 생성"
      ],
      "metadata": {
        "id": "8Woc1AVuIvlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, embedding_size, outut_size,layer, p=0.4):\n",
        "    super().__init__()\n",
        "    self.all_embeddinfs=nn.ModuleList([nn.Embedding(ni,nf) for ni, nf in embedding_size])\n",
        "    self.embeddinf_dropout = nn.Dropout(p)\n",
        "\n",
        "    all_layer=[]\n",
        "    num_categorical_cols=sum((nf for ni, nf in embeddinf_size))\n",
        "    input_size=num_categorical_cols  #입력층의 크기를 찾기 위해 범주형 칼럼 개수를 input_size 변수에 저장\n",
        "\n",
        "    for i in layer:\n",
        "        all_layers.append(nn.Linear(input_size,i))\n",
        "        all_layers.append(nn.ReLU(inplace=True))\n",
        "        all_layers.append(nn.BatchNormld(i))\n",
        "        all_laters.append(nn.Dropout(p))\n",
        "        input_size=i\n",
        "\n",
        "    all_layers.append(nn.Linear(layers[-1],output_size))\n",
        "    self.layers=nn.Sequential(*all_layers)  #신경망의 모든 계층이 순차적으로 실행되도록 모든 계층에 대한 목록(all_layers)을 nn.Sequential클래스로 전달\n",
        "\n",
        "    def forward(self,x_categorical):\n",
        "      embeddings=[]\n",
        "      for i,e in enumerate(self.all_embeddings):\n",
        "        embeddings.append(e(x_categorical[:,i]))\n",
        "        x=torch.cat(embeddings,1)  #넘파이의 concatenate와 같지만 대상이 텐서가 됩니다.\n",
        "        x=self.embedding_dropout(x)\n",
        "        x=self.layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8wtZseVUIxrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 클래스의 객체 생성"
      ],
      "metadata": {
        "id": "1oFwFIbHLVin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(categorical_embedding_sizes,4,[200,100,50],p=0.4)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "ok7ib3AXLYIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델의 파라미터 정의"
      ],
      "metadata": {
        "id": "NgzHSnPKLmBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Ada,(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "qWp0WiJpLopL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CPU/GPU 사용 지정"
      ],
      "metadata": {
        "id": "15Kdfd4cL04Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tirch.cuda.is_available():\n",
        "    device=torch.device('cuda')  #GPU가 있다면 GPU사용\n",
        "else:\n",
        "    device=torch.device('cpu')  #GPU가 없다면 CPU를 사용"
      ],
      "metadata": {
        "id": "XMyr203VL4xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습"
      ],
      "metadata": {
        "id": "VASD4J94MVo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "aggregated_losses=[]\n",
        "train_outputs=train_outputs.to(devise=device,dtype=torch.int64)\n",
        "for i in range(epochs):  #for 문은 500회 반복되며, 각 반복마다 손실 함수가 오차를 계산\n",
        "    i +=1\n",
        "    y_pred = model(categorical_train_data).to(device)\n",
        "    single_loss=loss_function(y_pred,train_outputs)\n",
        "    aggregated_losses.append(single_loss)  #반복할 때마다 오차를 aggregated_losses에 추가\n",
        "\n",
        "    if i%25==1:\n",
        "        print(f'epoch:{i:3} loss:{single_loss.item():10.8f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    single_loss.backward()  #가중치를 업데이트하기 위해 손실함수의 backward()매서드 호출\n",
        "    optimizer.step()  #옵티마이저 함수의 step() 매서드를 이용하여 기울기 업데이트\n",
        "\n",
        "print(f'epoch: {i:3} loss: {single_loss.iten():10.10f}')  #오차가 25 에포크마다 출력"
      ],
      "metadata": {
        "id": "0-ukoEHGMYCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 데이터셋으로 모델 예측"
      ],
      "metadata": {
        "id": "bcRAnMU9ObBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_outputs = test_outputs.to(device=device,dtype=torch.int64)\n",
        "with torch.no_grad():\n",
        "  y_val=model(categorical_test_data)\n",
        "  loss=loss_function(y_val,test_outputs)\n",
        "  print(f'Loss:{loss:.8f}')"
      ],
      "metadata": {
        "id": "JgMk4nbcOfT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델의 예측 확인"
      ],
      "metadata": {
        "id": "7CdezhaaO96o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_val[:5])"
      ],
      "metadata": {
        "id": "5_qvGt9bPAKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 가장 큰 값을 갖는 인덱스 확인"
      ],
      "metadata": {
        "id": "E6AWgahnPEqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = np.argmax(y_val,axis=1)\n",
        "print(y_val[:5])"
      ],
      "metadata": {
        "id": "Z2-9yrASPHW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 데이터셋을 이용한 정확도 확인"
      ],
      "metadata": {
        "id": "0PpX5nW2PSg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classfication_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(test_outputs,y_val))\n",
        "print(classfication_report(test_outputs,y_val))\n",
        "print(accuracy_score(test_outputs,y_val))"
      ],
      "metadata": {
        "id": "-Zam-0ecPYba"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}