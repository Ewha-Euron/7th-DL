{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 딥러닝 구조\n",
        "\n"
      ],
      "metadata": {
        "id": "2WEUHtvoSAlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2.1 딥러닝 용어"
      ],
      "metadata": {
        "id": "TsNKHXG-XyPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "skGIkMmgS3oG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 활성화 함수\n",
        "전달받은 값을 출력할 때 일정 기준에 따라 출력 값을 변화시키는 비선형 함수"
      ],
      "metadata": {
        "id": "7V3f1kzNZuLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5s3VNQwQ5Pi"
      },
      "outputs": [],
      "source": [
        "# 활성화 함수\n",
        "# ReLU 함수(입력<0 -> 0, 입력>0 -> x)와 softmax 함수(입력이 0~1 사이에 출력되도록 정규화. 출력값 총합이 항상 1) 구현 예시\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, n_feature,n_hidden,n_output):\n",
        "        super(Net,self).__init__()\n",
        "        self.hidden=torch.nn.Linear(n_feature, n_hidden) #은닉층\n",
        "        self.relu=torch.nn.ReLu(inplace=True)\n",
        "        self.out=torch.nn.Linear(n_hidden,n_output) #출력층\n",
        "        self.softmax=torch.nn.Softmax(dim=n_output)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.hidden(x)\n",
        "        x=self.relu(x) #은닉층을 위한 렐루 활성화 함수\n",
        "        x=self.out(x)\n",
        "        x=self.softmax(x) #출력층을 위한 소프트맥스 활성화 함수\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 손실 함수\n",
        "학습을 통해 얻은 데이터의 추정치가 실제 데이터와 얼마나 차이가 나는지 평가하는 지표"
      ],
      "metadata": {
        "id": "D7xN_TcMZwsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수로 MSE(Mean Squared Error) 적용\n",
        "loss_fn=torch.nn.MSELoss(reduction='sum')\n",
        "y_pred=model(x)\n",
        "loss=loss_fn(y_pred,y)"
      ],
      "metadata": {
        "id": "rbwef2C2SzcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수로 CEE(Cross Entropy Loss) 적용\n",
        "# CEE는 분류 문제어서 one-hot encoding을 했을 때만 사용 가능\n",
        "import torch.nn as nn\n",
        "loss=nn.CrossEntropyLoss()\n",
        "input=torch.randn(5,6,requires_grad=True) #torch.randn은 평균이 0이고 표준편차가 1인 가우시안 정규분포를 이용하여 숫자 생성\n",
        "target=torch.empty(3,dtype=torch.long).random_(5) #torch.empty는 dtype torch.float32의 랜덤한 값으로 채워진 텐서를 반환\n",
        "output=loss(input,target)\n",
        "output.backward()"
      ],
      "metadata": {
        "id": "i4Ys0AORTUtk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2.3 딥러닝의 문제점과 해결 방안"
      ],
      "metadata": {
        "id": "CLW3aLWHYANn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 드롭아웃\n",
        "과적합 방지 목적으로 학습 과정 중 임의로 일부 노드들을 학습에서 제외"
      ],
      "metadata": {
        "id": "94VlwSwCaPFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 드롭아웃 구현 예시\n",
        "class DropoutModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DropoutModel, self).__init__()\n",
        "        self.layer1=torch.nn.Linear(784,1200)\n",
        "        #50의 노드를 무작위로 선택하여 사용하지 않겠다는 의미\n",
        "        self.dropout1=torch.nn.Dropout(0.5)\n",
        "        self.layer2=torch.nn.Linear(1200,1200)\n",
        "        self.dropout2=torch.nn.Dropout(0.5)\n",
        "        self.layer3=torch.nn.Linear(1200,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=F.relu(self.layer1(x))\n",
        "        x=self.dropout1(x)\n",
        "        x=F.relu(self.layer2(x))\n",
        "        x=self.dropout2\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "Bz7psF6lUVIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mini-batch gradient descent\n",
        "전체 데이터셋을 미니 배치 여러 개로 나눠 미니 배치 1개마다 기울기를 구한 후 그것의 평균 기울기를 이용해 모델을 업데이트해서 학습"
      ],
      "metadata": {
        "id": "pH793bPVaaYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mini-batch gradient descent 구현 예시\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.x_data=[[1,2,3],[4,5,6],[7,8,9]]\n",
        "        self.y_data=[[12],[18],[11]]\n",
        "        def __len__(self):\n",
        "            return len(self.x_data)\n",
        "        def __getitem__(self,idx):\n",
        "            x=torch.FloatTensor(self.x_data[idx])\n",
        "            y=torch.FloatTensor(self.y_data[idx])\n",
        "            return x,y\n",
        "\n",
        "dataset=CustomDataset()\n",
        "dataloader=DataLoader(\n",
        "    dataset, #데이터셋\n",
        "    batch_size=2, #미니 배치 크기로 2의 제곱수를 사용\n",
        "    shuffle=True, #데이터를 불러올 때마다 랜덤으로 섞어서 가져오기\n",
        ")"
      ],
      "metadata": {
        "id": "1tqCEynNVFdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer\n",
        "확률적 경사 하강법의 파라미터 변경 폭이 불안정한 문제를 해결하기 위해 학습 속도와 운동량을 조정"
      ],
      "metadata": {
        "id": "x6JTqkfCV_NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adagrad\n",
        "optimizer=torch.optim.Adagrad(model.parameters(),lr=0.01) #lr: learning rate default=1e-2"
      ],
      "metadata": {
        "id": "8WokqF_RWC18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adadelta\n",
        "optimizer=torch.optim.Adadelta(model.parameters(),lr=1.0) #lr: learning rate default=1.0"
      ],
      "metadata": {
        "id": "vv6UsXX2WQS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSProp\n",
        "optimizer=torch.optim.RMSprop(model.parameters(),lr=0.01) #lr: learning rate default=1e-2"
      ],
      "metadata": {
        "id": "qPn4WDmWWX-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD Momentum(SGD with Momentum)\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "09QwS1DzWian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NAG(Nesterov Accerlerated Gradient)\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01, momentum=0.9, nesterov=True) #nesterov default: False"
      ],
      "metadata": {
        "id": "31w2vVJZWz4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.01) #lr: learning rate default=1e-3"
      ],
      "metadata": {
        "id": "MlZ7yf1zXA5F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}