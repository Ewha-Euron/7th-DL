{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmbrNadxsBr7"
      },
      "source": [
        "## Convolution Layer Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAyG6GGTU_mC",
        "outputId": "118b0f42-fde5-4900-8cea-f4c8709818d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "연산 전 torch.Size([10, 1, 20, 20])\n",
            "conv1 연산 후 torch.Size([10, 3, 16, 16])\n",
            "conv2 연산 후 torch.Size([10, 10, 12, 12])\n",
            "차원 감소 후 torch.Size([10, 1440])\n",
            "fc1 연산 후 torch.Size([10, 50])\n",
            "fc2 연산 후 torch.Size([10, 10])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    \n",
        "    ## 조건1: conv layer 2개 & fc layer 2개\n",
        "    ## 조건2: kernel size=5, stride=1로 통일\n",
        "    ## output을 참고하여 차원을 계산해주세요!\n",
        "    ## 답안 ##\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5, stride=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5, stride=1)\n",
        "    self.fc1 = nn.Linear(in_features=10*12*12, out_features=50)\n",
        "    self.fc2 = nn.Linear(in_features=50, out_features=10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    print(\"연산 전\", x.size())\n",
        "    x = F.relu(self.conv1(x))\n",
        "    print(\"conv1 연산 후\", x.size())\n",
        "    x = F.relu(self.conv2(x))\n",
        "    print(\"conv2 연산 후\",x.size())\n",
        "    x = x.view(-1, 10 * 12 * 12)\n",
        "    print(\"차원 감소 후\", x.size())\n",
        "    x = F.relu(self.fc1(x))\n",
        "    print(\"fc1 연산 후\", x.size())\n",
        "    x = self.fc2(x)\n",
        "    print(\"fc2 연산 후\", x.size())\n",
        "    return x\n",
        "\n",
        "cnn = CNN()\n",
        "output = cnn(torch.randn(10, 1, 20, 20))  # Input Size: (10, 1, 20, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0It8H-mysBr-"
      },
      "source": [
        "## Max Pooling Layer Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkOwXPFNchie",
        "outputId": "a3f022de-8d54-4cf8-9456-f9bbc15ed9cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "연산 전 torch.Size([10, 1, 20, 20])\n",
            "max_pool1 연산 후 torch.Size([10, 1, 10, 10])\n",
            "max_pool2 연산 후 torch.Size([10, 1, 5, 5])\n",
            "차원 감소 후 torch.Size([1, 250])\n",
            "fc1 연산 후 torch.Size([1, 50])\n",
            "fc2 연산 후 torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    ## 조건1: 최대풀링 layer 2개 & fc layer 2개\n",
        "    ## 조건2: kernel size=2로 통일, stride는 따로 지정할 필요 없음\n",
        "    ## output을 참고하여 차원을 계산해주세요!\n",
        "    ## 답안 ##\n",
        "    self.max_pool1 = nn.MaxPool2d(2)\n",
        "    self.max_pool2 = nn.MaxPool2d(2)\n",
        "    self.fc1 = nn.Linear(in_features=250, out_features=50)\n",
        "    self.fc2 = nn.Linear(in_features=50, out_features=10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(\"연산 전\", x.size())\n",
        "    x = F.relu(self.max_pool1(x))\n",
        "    print(\"max_pool1 연산 후\", x.size())\n",
        "    x = F.relu(self.max_pool2(x))\n",
        "    print(\"max_pool2 연산 후\",x.size())\n",
        "    x = x.view(-1, 10 * 5 * 5)\n",
        "    print(\"차원 감소 후\", x.size())\n",
        "    x = F.relu(self.fc1(x))\n",
        "    print(\"fc1 연산 후\", x.size())\n",
        "    x = self.fc2(x)\n",
        "    print(\"fc2 연산 후\", x.size())\n",
        "    return x\n",
        "\n",
        "cnn = CNN()\n",
        "output = cnn(torch.randn(10, 1, 20, 20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDMn2y5_sBr-"
      },
      "source": [
        "## MNIST 데이터셋 train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YhfopkrQcp1P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.18.1a0)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (2.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch->torchvision) (2024.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CqFN5YM5cqKe"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IJb_C4ptcu6G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:03<00:00, 2989333.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 147809.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:02<00:00, 795860.01it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4140519.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.MNIST('./data/', train=True, download=True, transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])) # 학습 데이터\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=50, shuffle=True)\n",
        "\n",
        "test_data = datasets.MNIST('./data/', train=False, transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])) # 테스트 데이터\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=50, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YP3tEuo6ct8A"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        ## 조건1: conv layer 2개 & fc layer 2개\n",
        "            ## 첫 번째 conv layer: 입력 채널 1, 출력 채널 20\n",
        "            ## 두 번째 fc layer: 출력 채널 10\n",
        "        ## 조건2: kernel_size=5, stride=1\n",
        "        ## 답안 ##\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1)\n",
        "        self.fc1 = nn.Linear(in_features = 4*4*50, out_features=100)\n",
        "        self.fc2 = nn.Linear(in_features=100, out_features=10)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        ## 조건1: relu -> max_pool2d -> relu -> max_pool2d 순서로 이루어짐\n",
        "        ## 조건2: kernel_size=2, stride=2\n",
        "        ## 답안 ##\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = x.view(-1, 4 * 4 * 50) # [batch_size, 50, 4, 4]\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EO2ULx3Sc2GM"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gAwckNWhc4Nr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss of 0 epoch, 0 index : 2.306086540222168\n",
            "loss of 0 epoch, 100 index : 1.1925019025802612\n",
            "loss of 0 epoch, 200 index : 0.5607428550720215\n",
            "loss of 0 epoch, 300 index : 0.3305000960826874\n",
            "loss of 0 epoch, 400 index : 0.3802661895751953\n",
            "loss of 0 epoch, 500 index : 0.26330822706222534\n",
            "loss of 0 epoch, 600 index : 0.30376458168029785\n",
            "loss of 0 epoch, 700 index : 0.3894764184951782\n",
            "loss of 0 epoch, 800 index : 0.20059123635292053\n",
            "loss of 0 epoch, 900 index : 0.08993730694055557\n",
            "loss of 0 epoch, 1000 index : 0.2551979720592499\n",
            "loss of 0 epoch, 1100 index : 0.13248619437217712\n",
            "loss of 1 epoch, 0 index : 0.05963374674320221\n",
            "loss of 1 epoch, 100 index : 0.17293351888656616\n",
            "loss of 1 epoch, 200 index : 0.11469367891550064\n",
            "loss of 1 epoch, 300 index : 0.05461176484823227\n",
            "loss of 1 epoch, 400 index : 0.10628736764192581\n",
            "loss of 1 epoch, 500 index : 0.027521874755620956\n",
            "loss of 1 epoch, 600 index : 0.18120624125003815\n",
            "loss of 1 epoch, 700 index : 0.05388624221086502\n",
            "loss of 1 epoch, 800 index : 0.1892755627632141\n",
            "loss of 1 epoch, 900 index : 0.06396523118019104\n",
            "loss of 1 epoch, 1000 index : 0.11940503120422363\n",
            "loss of 1 epoch, 1100 index : 0.026689937338232994\n",
            "loss of 2 epoch, 0 index : 0.052024710923433304\n",
            "loss of 2 epoch, 100 index : 0.01772175170481205\n",
            "loss of 2 epoch, 200 index : 0.05802665278315544\n",
            "loss of 2 epoch, 300 index : 0.023049985989928246\n",
            "loss of 2 epoch, 400 index : 0.03791309520602226\n",
            "loss of 2 epoch, 500 index : 0.11485160142183304\n",
            "loss of 2 epoch, 600 index : 0.02563101053237915\n",
            "loss of 2 epoch, 700 index : 0.18879039585590363\n",
            "loss of 2 epoch, 800 index : 0.017257491126656532\n",
            "loss of 2 epoch, 900 index : 0.029469192028045654\n",
            "loss of 2 epoch, 1000 index : 0.021488001570105553\n",
            "loss of 2 epoch, 1100 index : 0.09790855646133423\n",
            "loss of 3 epoch, 0 index : 0.05401596054434776\n",
            "loss of 3 epoch, 100 index : 0.1215297132730484\n",
            "loss of 3 epoch, 200 index : 0.07523215562105179\n",
            "loss of 3 epoch, 300 index : 0.06701471656560898\n",
            "loss of 3 epoch, 400 index : 0.0461604930460453\n",
            "loss of 3 epoch, 500 index : 0.061223383992910385\n",
            "loss of 3 epoch, 600 index : 0.22718879580497742\n",
            "loss of 3 epoch, 700 index : 0.1476270705461502\n",
            "loss of 3 epoch, 800 index : 0.028519777581095695\n",
            "loss of 3 epoch, 900 index : 0.012072138488292694\n",
            "loss of 3 epoch, 1000 index : 0.050514645874500275\n",
            "loss of 3 epoch, 1100 index : 0.04348475858569145\n",
            "loss of 4 epoch, 0 index : 0.026296906173229218\n",
            "loss of 4 epoch, 100 index : 0.05028017982840538\n",
            "loss of 4 epoch, 200 index : 0.06575661897659302\n",
            "loss of 4 epoch, 300 index : 0.007180690299719572\n",
            "loss of 4 epoch, 400 index : 0.24839967489242554\n",
            "loss of 4 epoch, 500 index : 0.011106428690254688\n",
            "loss of 4 epoch, 600 index : 0.008372554555535316\n",
            "loss of 4 epoch, 700 index : 0.02545320801436901\n",
            "loss of 4 epoch, 800 index : 0.0076981051824986935\n",
            "loss of 4 epoch, 900 index : 0.09221614897251129\n",
            "loss of 4 epoch, 1000 index : 0.010259037837386131\n",
            "loss of 4 epoch, 1100 index : 0.10628890246152878\n",
            "loss of 5 epoch, 0 index : 0.052358478307724\n",
            "loss of 5 epoch, 100 index : 0.04218101128935814\n",
            "loss of 5 epoch, 200 index : 0.03078007698059082\n",
            "loss of 5 epoch, 300 index : 0.05685872212052345\n",
            "loss of 5 epoch, 400 index : 0.006173187401145697\n",
            "loss of 5 epoch, 500 index : 0.04288705438375473\n",
            "loss of 5 epoch, 600 index : 0.03439444676041603\n",
            "loss of 5 epoch, 700 index : 0.03258100152015686\n",
            "loss of 5 epoch, 800 index : 0.001803478691726923\n",
            "loss of 5 epoch, 900 index : 0.02585185319185257\n",
            "loss of 5 epoch, 1000 index : 0.02298544906079769\n",
            "loss of 5 epoch, 1100 index : 0.028986429795622826\n",
            "loss of 6 epoch, 0 index : 0.003953584935516119\n",
            "loss of 6 epoch, 100 index : 0.10981699079275131\n",
            "loss of 6 epoch, 200 index : 0.1082264706492424\n",
            "loss of 6 epoch, 300 index : 0.03323496878147125\n",
            "loss of 6 epoch, 400 index : 0.11985328048467636\n",
            "loss of 6 epoch, 500 index : 0.014962592162191868\n",
            "loss of 6 epoch, 600 index : 0.015217307023704052\n",
            "loss of 6 epoch, 700 index : 0.03235176205635071\n",
            "loss of 6 epoch, 800 index : 0.01628306694328785\n",
            "loss of 6 epoch, 900 index : 0.04699264094233513\n",
            "loss of 6 epoch, 1000 index : 0.006558090448379517\n",
            "loss of 6 epoch, 1100 index : 0.16366496682167053\n",
            "loss of 7 epoch, 0 index : 0.011162850074470043\n",
            "loss of 7 epoch, 100 index : 0.010957331396639347\n",
            "loss of 7 epoch, 200 index : 0.009936243295669556\n",
            "loss of 7 epoch, 300 index : 0.024392826482653618\n",
            "loss of 7 epoch, 400 index : 0.065168097615242\n",
            "loss of 7 epoch, 500 index : 0.001894524204544723\n",
            "loss of 7 epoch, 600 index : 0.06316947191953659\n",
            "loss of 7 epoch, 700 index : 0.005404944997280836\n",
            "loss of 7 epoch, 800 index : 0.05450061336159706\n",
            "loss of 7 epoch, 900 index : 0.004471209831535816\n",
            "loss of 7 epoch, 1000 index : 0.006380477454513311\n",
            "loss of 7 epoch, 1100 index : 0.0232191514223814\n",
            "loss of 8 epoch, 0 index : 0.030513618141412735\n",
            "loss of 8 epoch, 100 index : 0.018335022032260895\n",
            "loss of 8 epoch, 200 index : 0.015950769186019897\n",
            "loss of 8 epoch, 300 index : 0.03802061825990677\n",
            "loss of 8 epoch, 400 index : 0.0402408204972744\n",
            "loss of 8 epoch, 500 index : 0.011117184534668922\n",
            "loss of 8 epoch, 600 index : 0.04862809181213379\n",
            "loss of 8 epoch, 700 index : 0.0029125679284334183\n",
            "loss of 8 epoch, 800 index : 0.0978740006685257\n",
            "loss of 8 epoch, 900 index : 0.004322466440498829\n",
            "loss of 8 epoch, 1000 index : 0.012256413698196411\n",
            "loss of 8 epoch, 1100 index : 0.01596071571111679\n",
            "loss of 9 epoch, 0 index : 0.15793097019195557\n",
            "loss of 9 epoch, 100 index : 0.007873029448091984\n",
            "loss of 9 epoch, 200 index : 0.01713445410132408\n",
            "loss of 9 epoch, 300 index : 0.002717758761718869\n",
            "loss of 9 epoch, 400 index : 0.02440795488655567\n",
            "loss of 9 epoch, 500 index : 0.05733739957213402\n",
            "loss of 9 epoch, 600 index : 0.12160453200340271\n",
            "loss of 9 epoch, 700 index : 0.0223897285759449\n",
            "loss of 9 epoch, 800 index : 0.022267546504735947\n",
            "loss of 9 epoch, 900 index : 0.12765474617481232\n",
            "loss of 9 epoch, 1000 index : 0.010260866023600101\n",
            "loss of 9 epoch, 1100 index : 0.019712502136826515\n"
          ]
        }
      ],
      "source": [
        "cnn.train()  # 학습을 위함\n",
        "for epoch in range(10):\n",
        "  for index, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()  # 기울기 초기화\n",
        "    output = cnn(data)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()  # 역전파\n",
        "    optimizer.step()\n",
        "\n",
        "    if index % 100 == 0:\n",
        "      print(\"loss of {} epoch, {} index : {}\".format(epoch, index, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l2PnlaXIc6dm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 5.6992, Accuracy: 9898/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cnn.eval()  # test case 학습 방지를 위함\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for data, target in test_loader:\n",
        "    output = cnn(data)\n",
        "    test_loss += criterion(output, target).item() # sum up batch loss\n",
        "    pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
