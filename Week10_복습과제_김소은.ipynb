{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number:  17\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600\n",
      "8400\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"/Users/soeunkim/Desktop/D/Euron-DL-세션/Week10/train.csv\",dtype = np.float32)\n",
    "\n",
    "# split data into features(pixels) and labels(numbers from 0 to 9)\n",
    "targets_numpy = train.label.values\n",
    "features_numpy = train.loc[:,train.columns != \"label\"].values/255 # normalization\n",
    "\n",
    "# train test split. Size of train data is 80% and size of test data is 20%. \n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42) \n",
    "\n",
    "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(\"Epoch Number: \",num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# visualize one of the images in data set\n",
    "plt.imshow(features_numpy[10].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[10]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()\n",
    "\n",
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True) # batch_first=True (batch_dim, seq_dim, feature_dim)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # 28 time steps\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "    \n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 2.2603046894073486. Accuracy: 18.4761905670166\n",
      "Iteration: 1000. Loss: 1.0888844728469849. Accuracy: 64.08333587646484\n",
      "Iteration: 1500. Loss: 0.41839399933815. Accuracy: 85.51190185546875\n",
      "Iteration: 2000. Loss: 0.30270329117774963. Accuracy: 91.92857360839844\n",
      "Iteration: 2500. Loss: 0.21008461713790894. Accuracy: 94.41666412353516\n",
      "Iteration: 3000. Loss: 0.1245855838060379. Accuracy: 95.11904907226562\n",
      "Iteration: 3500. Loss: 0.1766708493232727. Accuracy: 95.45237731933594\n",
      "Iteration: 4000. Loss: 0.019658196717500687. Accuracy: 96.35713958740234\n",
      "Iteration: 4500. Loss: 0.07536835968494415. Accuracy: 96.85713958740234\n",
      "Iteration: 5000. Loss: 0.0373028889298439. Accuracy: 96.76190185546875\n",
      "Iteration: 5500. Loss: 0.1274995356798172. Accuracy: 96.8452377319336\n"
     ]
    }
   ],
   "source": [
    "# Number of steps to unroll\n",
    "seq_dim = 28  \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as a torch tensor with gradient accumulation abilities\n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size 100, 10\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "\n",
    "        # Getting gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if count % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                images = images.view(-1, seq_dim, input_dim)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            loss_list.append(loss.data.item())\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(count, loss.data.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization loss \n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"LSTM: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"LSTM: Accuracy vs Number of iteration\")\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
