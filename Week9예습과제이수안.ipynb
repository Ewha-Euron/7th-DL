{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wrzmhiZ1pegW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageTransform():\n",
        "    def __init__(self, resize, mean, std):\n",
        "        self.data_transform = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(resize),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    def __call__(self, img, phase):\n",
        "        return self.data_transform[phase](img)"
      ],
      "metadata": {
        "id": "O58VIKhTpzqw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "GDqkxYq9p0bq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "file_uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "erDLiaE8rxfq",
        "outputId": "c0f624d6-6842-4d0f-8ec2-3131dddbd487"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2e18affd-f0b4-41dc-8090-6dc411e542bd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2e18affd-f0b4-41dc-8090-6dc411e542bd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dogs-vs-cats.zip to dogs-vs-cats.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dogs-vs-cats.zip -d dogs-vs-cats/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O_N_HEIrzbN",
        "outputId": "9ac17632-48de-4e39-9b22-ae60b3c0a2fb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dogs-vs-cats.zip\n",
            "   creating: dogs-vs-cats/Cat/\n",
            "  inflating: dogs-vs-cats/Cat/cat.0.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.1.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.10.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.100.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.101.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.102.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.103.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.104.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.105.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.106.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.107.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.108.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.109.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.11.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.110.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.111.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.112.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.113.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.114.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.115.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.116.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.117.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.118.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.119.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.12.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.120.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.121.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.122.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.123.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.124.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.125.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.126.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.127.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.128.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.129.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.13.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.130.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.131.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.132.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.133.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.134.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.135.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.136.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.137.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.138.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.139.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.14.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.140.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.141.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.142.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.143.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.144.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.145.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.146.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.147.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.148.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.149.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.15.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.150.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.151.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.152.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.153.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.154.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.155.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.156.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.157.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.158.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.159.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.16.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.160.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.161.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.162.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.163.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.164.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.165.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.166.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.167.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.168.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.169.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.17.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.170.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.171.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.172.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.173.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.174.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.175.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.176.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.177.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.178.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.179.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.18.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.180.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.181.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.182.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.183.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.184.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.185.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.186.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.187.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.188.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.189.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.19.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.190.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.191.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.192.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.193.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.194.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.195.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.196.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.197.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.198.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.199.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.2.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.20.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.200.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.201.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.202.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.203.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.204.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.205.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.206.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.207.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.208.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.209.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.21.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.210.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.211.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.212.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.213.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.214.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.215.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.216.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.217.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.218.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.219.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.22.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.220.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.221.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.222.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.223.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.224.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.225.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.226.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.227.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.228.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.229.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.23.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.230.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.231.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.232.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.233.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.234.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.235.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.236.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.237.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.238.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.239.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.24.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.240.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.241.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.242.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.243.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.244.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.245.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.246.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.247.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.248.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.249.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.25.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.250.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.26.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.27.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.28.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.29.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.3.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.30.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.31.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.32.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.33.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.34.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.35.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.36.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.37.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.38.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.39.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.4.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.40.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.41.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.42.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.43.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.44.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.45.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.46.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.47.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.48.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.49.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.5.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.50.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.51.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.52.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.53.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.54.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.55.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.56.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.57.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.58.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.59.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.6.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.60.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.61.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.62.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.63.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.64.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.65.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.66.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.67.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.68.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.69.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.7.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.70.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.71.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.72.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.73.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.74.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.75.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.76.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.77.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.78.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.79.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.8.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.80.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.81.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.82.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.83.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.84.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.85.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.86.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.87.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.88.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.89.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.9.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.90.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.91.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.92.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.93.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.94.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.95.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.96.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.97.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.98.jpg  \n",
            "  inflating: dogs-vs-cats/Cat/cat.99.jpg  \n",
            "   creating: dogs-vs-cats/Dog/\n",
            "  inflating: dogs-vs-cats/Dog/dog.0.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.1.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.10.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.100.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.101.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.102.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.103.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.104.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.105.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.106.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.107.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.108.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.109.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.11.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.110.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.111.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.112.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.113.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.114.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.115.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.116.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.117.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.118.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.119.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.12.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.120.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.121.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.122.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.123.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.124.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.125.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.126.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.127.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.128.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.129.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.13.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.130.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.131.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.132.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.133.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.134.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.135.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.136.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.137.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.138.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.139.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.14.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.140.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.141.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.142.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.143.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.144.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.145.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.146.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.147.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.148.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.149.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.15.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.150.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.151.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.152.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.153.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.154.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.155.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.156.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.157.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.158.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.159.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.16.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.160.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.161.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.162.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.163.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.164.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.165.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.166.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.167.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.168.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.169.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.17.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.170.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.171.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.172.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.173.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.174.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.175.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.176.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.177.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.178.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.179.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.18.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.180.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.181.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.182.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.183.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.184.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.185.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.186.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.187.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.188.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.189.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.19.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.190.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.191.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.192.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.193.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.194.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.195.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.196.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.197.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.198.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.199.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.2.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.20.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.200.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.201.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.202.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.203.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.204.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.205.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.206.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.207.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.208.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.209.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.21.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.210.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.211.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.212.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.213.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.214.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.215.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.216.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.217.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.218.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.219.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.22.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.220.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.221.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.222.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.223.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.224.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.225.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.226.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.227.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.228.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.229.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.23.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.230.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.231.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.232.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.233.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.234.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.235.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.236.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.237.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.238.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.239.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.24.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.240.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.241.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.242.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.243.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.244.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.245.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.246.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.247.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.248.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.249.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.25.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.250.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.26.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.27.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.28.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.29.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.3.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.30.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.31.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.32.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.33.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.34.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.35.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.36.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.37.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.38.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.39.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.4.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.40.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.41.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.42.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.43.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.44.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.45.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.46.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.47.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.48.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.49.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.5.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.50.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.51.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.52.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.53.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.54.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.55.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.56.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.57.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.58.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.59.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.6.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.60.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.61.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.62.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.63.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.64.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.65.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.66.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.67.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.68.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.69.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.7.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.70.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.71.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.72.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.73.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.74.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.75.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.76.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.77.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.78.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.79.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.8.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.80.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.81.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.82.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.83.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.84.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.85.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.86.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.87.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.88.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.89.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.9.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.90.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.91.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.92.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.93.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.94.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.95.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.96.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.97.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.98.jpg  \n",
            "  inflating: dogs-vs-cats/Dog/dog.99.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_directory = 'dogs-vs-cats/Cat/'\n",
        "dog_directory = 'dogs-vs-cats/Dog/'\n",
        "\n",
        "cat_images_filepaths = sorted([os.path.join(cat_directory, f) for f in os.listdir(cat_directory)])\n",
        "dog_images_filepaths = sorted([os.path.join(dog_directory, f) for f in os.listdir(dog_directory)])\n",
        "images_filepaths = [*cat_images_filepaths, *dog_images_filepaths]\n",
        "correct_images_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]"
      ],
      "metadata": {
        "id": "a73_UmYSp0YN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "random.shuffle(correct_images_filepaths)\n",
        "train_images_filepaths = correct_images_filepaths[:400]\n",
        "val_images_filepaths = correct_images_filepaths[400:-10]\n",
        "test_images_filepaths = correct_images_filepaths[-10:]\n",
        "print(len(train_images_filepaths), len(val_images_filepaths), len(test_images_filepaths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npd3IGtWp0WE",
        "outputId": "3b956b5a-c50f-4192-cb14-d0cb5e46b4b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 92 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DogvsCatDataset(Dataset):\n",
        "    def __init__(self, file_list, transform=None, phase='train'):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        self.phase = phase\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        img = Image.open(img_path)\n",
        "        img_transformed = self.transform(img, self.phase)\n",
        "\n",
        "        label = img_path.split('/')[-1].split('.')[0]\n",
        "        if label == 'dog':\n",
        "            label = 1\n",
        "        elif label == 'cat':\n",
        "            label = 0\n",
        "        return img_transformed, label"
      ],
      "metadata": {
        "id": "8dN0TUOtp0T4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DogvsCatDataset(train_images_filepaths, transform=ImageTransform(size, mean, std), phase='train')\n",
        "val_dataset = DogvsCatDataset(val_images_filepaths, transform=ImageTransform(size, mean, std), phase='val')\n",
        "\n",
        "index = 0\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ecSlS37p0R3",
        "outputId": "4283d719-fc55-4496-f978-f4390c4bc60c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_iterator = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "dataloader_dict = {'train': train_iterator, 'val': valid_iterator}\n",
        "\n",
        "batch_iterator = iter(train_iterator)\n",
        "inputs, label = next(batch_iterator)\n",
        "print(inputs.size())\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glM2mWelp0Pq",
        "outputId": "7cb1fa7f-96e3-4c1f-8688-14fc3edc1b6a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 224, 224])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
            "        0, 1, 1, 1, 1, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3,\n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,\n",
        "                               stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1,\n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        i = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "JAaNGMOEp0Nw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                               stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        i = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "4q93Lp_Xp0Lj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim, zero_init_residual=False):\n",
        "        super().__init__()\n",
        "\n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "\n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "        layers = []\n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "\n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        return x, h"
      ],
      "metadata": {
        "id": "EuffMpr3qa3B"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ],
      "metadata": {
        "id": "Hai6wMWsqazd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks = [2,2,2,2],\n",
        "                               channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet34_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks = [3,4,6,3],\n",
        "                               channels = [64, 128, 256, 512])"
      ],
      "metadata": {
        "id": "CPbHb0izqawx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_config = ResNetConfig(block = Bottleneck,\n",
        "                               n_blocks = [3, 4, 6, 3],\n",
        "                               channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet101_config = ResNetConfig(block = Bottleneck,\n",
        "                                n_blocks = [3, 4, 23, 3],\n",
        "                                channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet152_config = ResNetConfig(block = Bottleneck,\n",
        "                                n_blocks = [3, 8, 36, 3],\n",
        "                                channels = [64, 128, 256, 512])"
      ],
      "metadata": {
        "id": "HFHMPPUWqauZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = models.resnet50(pretrained = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQbIIuVHqasC",
        "outputId": "82dabeb9-315a-4096-cdfb-61457875c15a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 213MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pretrained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-GDUy0yqaqE",
        "outputId": "5e8a7bba-80fc-4482-9c4f-5eadd509051d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIM = 2\n",
        "model = ResNet(resnet50_config, OUTPUT_DIM)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBYu1Y0lqans",
        "outputId": "788a7f63-38bc-4ac9-c029-ff287ca277e1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "4jBmT48gqjy2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_topk_accuracy(y_pred, y, k = 2):\n",
        "    with torch.no_grad():\n",
        "        batch_size = y.shape[0]\n",
        "        _, top_pred = y_pred.topk(k, 1)\n",
        "        top_pred = top_pred.t()\n",
        "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
        "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
        "        acc_1 = correct_1 / batch_size\n",
        "        acc_k = correct_k / batch_size\n",
        "    return acc_1, acc_k"
      ],
      "metadata": {
        "id": "GSLkL_2bqjva"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "\n",
        "    model.train()\n",
        "    for (x, y) in iterator:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "\n",
        "        loss = criterion(y_pred[0], y)\n",
        "\n",
        "        acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc_1 += acc_1.item()\n",
        "        epoch_acc_5 += acc_5.item()\n",
        "\n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    epoch_acc_5 /= len(iterator)\n",
        "    return epoch_loss, epoch_acc_1, epoch_acc_5"
      ],
      "metadata": {
        "id": "UJxWuvniqjta"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (x, y) in iterator:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred[0], y)\n",
        "            acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc_1 += acc_1.item()\n",
        "            epoch_acc_5 += acc_5.item()\n",
        "\n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    epoch_acc_5 /= len(iterator)\n",
        "    return epoch_loss, epoch_acc_1, epoch_acc_5"
      ],
      "metadata": {
        "id": "L6SJD0LRqjrV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "EscVxJTfqjpb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.monotonic()\n",
        "\n",
        "    train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_iterator, criterion, device)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'ResNet-model.pt')\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | ' \\\n",
        "          f'Train Acc @5: {train_acc_5*100:6.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}% | ' \\\n",
        "          f'Valid Acc @5: {valid_acc_5*100:6.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPSomq9VqjnM",
        "outputId": "df566ac8-5e83-4be9-924c-2de63aadf258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 3m 2s\n",
            "\tTrain Loss: 0.828 | Train Acc @1:  50.48% | Train Acc @5: 100.00%\n",
            "\tValid Loss: 0.696 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
            "Epoch: 02 | Epoch Time: 2m 52s\n",
            "\tTrain Loss: 0.814 | Train Acc @1:  50.00% | Train Acc @5: 100.00%\n",
            "\tValid Loss: 0.696 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
            "Epoch: 03 | Epoch Time: 2m 53s\n",
            "\tTrain Loss: 0.802 | Train Acc @1:  50.72% | Train Acc @5: 100.00%\n",
            "\tValid Loss: 0.718 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
            "Epoch: 04 | Epoch Time: 2m 55s\n",
            "\tTrain Loss: 0.806 | Train Acc @1:  50.24% | Train Acc @5: 100.00%\n",
            "\tValid Loss: 0.757 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
            "Epoch: 05 | Epoch Time: 2m 52s\n",
            "\tTrain Loss: 0.797 | Train Acc @1:  50.48% | Train Acc @5: 100.00%\n",
            "\tValid Loss: 0.791 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
            "Epoch: 06 | Epoch Time: 2m 52s\n",
            "\tTrain Loss: 0.809 | Train Acc @1:  49.04% | Train Acc @5: 100.00%\n",
            "\tValid Loss: 0.784 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
            "Epoch: 07 | Epoch Time: 2m 55s\n",
            "\tTrain Loss: 0.798 | Train Acc @1:  49.76% | Train Acc @5: 100.00%\n",
            "\tValid Loss: 0.792 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
            "Epoch: 08 | Epoch Time: 2m 54s\n",
            "\tTrain Loss: 0.795 | Train Acc @1:  50.00% | Train Acc @5: 100.00%\n",
            "\tValid Loss: 0.792 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "id_list = []\n",
        "pred_list = []\n",
        "_id=0\n",
        "with torch.no_grad():\n",
        "    for test_path in test_images_filepaths:\n",
        "        img = Image.open(test_path)\n",
        "        _id =test_path.split('/')[-1].split('.')[1]\n",
        "        transform = ImageTransform(size, mean, std)\n",
        "        img = transform(img, phase='val')\n",
        "        img = img.unsqueeze(0)\n",
        "        img = img.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        outputs = model(img)\n",
        "        preds = F.softmax(outputs[0], dim=1)[:, 1].tolist()\n",
        "        id_list.append(_id)\n",
        "        pred_list.append(preds[0])\n",
        "\n",
        "res = pd.DataFrame({\n",
        "    'id': id_list,\n",
        "    'label': pred_list\n",
        "})\n",
        "\n",
        "res.sort_values(by='id', inplace=True)\n",
        "res.reset_index(drop=True, inplace=True)\n",
        "\n",
        "res.to_csv('ReNet.csv', index=False)\n",
        "res.head(10)"
      ],
      "metadata": {
        "id": "SqmxbrPFquBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_ = classes = {0:'cat', 1:'dog'}\n",
        "def display_image_grid(images_filepaths, predicted_labels=(), cols=5):\n",
        "    rows = len(images_filepaths) // cols\n",
        "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
        "    for i, image_filepath in enumerate(images_filepaths):\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        a = random.choice(res['id'].values)\n",
        "        label = res.loc[res['id'] == a, 'label'].values[0]\n",
        "\n",
        "        if label > 0.5:\n",
        "            label = 1\n",
        "        else:\n",
        "            label = 0\n",
        "        ax.ravel()[i].imshow(image)\n",
        "        ax.ravel()[i].set_title(class_[label])\n",
        "        ax.ravel()[i].set_axis_off()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "display_image_grid(test_images_filepaths)"
      ],
      "metadata": {
        "id": "GQqPO3v4qt9y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}