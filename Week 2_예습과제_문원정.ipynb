{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92043e95-eb2f-4376-b5ff-be1023cf0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden) ------ 은닉층\n",
    "        self.relu = torch.nn.ReLu(inplace=True)\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output) ------ 출력층\n",
    "        self.softmax = torch.nn.Softmax(dim=n_output)\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x) ------ 은닉층을 위한 렐루 활성화 함수\n",
    "        x = self.out(x)\n",
    "        x = self.softmax(x) ------ 출력층을 위한 소프트맥스 활성화 함수\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4330c9-788f-4bd2-a01c-f58a83f600a9",
   "metadata": {},
   "source": [
    "self.hidden = torch.nn.Linear(n_feature, n_hidden):\n",
    "입력층과 은닉층을 연결하는 선형 변환을 정의.\n",
    "n_feature는 입력 특성의 수, n_hidden은 은닉층의 노드 수\n",
    "self.relu = torch.nn.ReLU(inplace=True):\n",
    "ReLU 활성화 함수를 정의. ReLU는 음수를 0으로, 양수는 그대로 유지하는 비선형 함수.\n",
    "self.out = torch.nn.Linear(n_hidden, n_output):\n",
    "은닉층과 출력층을 연결하는 선형 변환을 정의. n_output은 출력값의 차원을 의미.\n",
    "self.softmax = torch.nn.Softmax(dim=n_output):\n",
    "Softmax 활성화 함수는 출력층에 사용되며, 출력값을 확률로 변환. 차원이 n_output 방향으로 적용\n",
    "3. forward() (순전파)\n",
    "x = self.hidden(x):\n",
    "입력값 x를 은닉층으로 전달.\n",
    "x = self.relu(x):\n",
    "은닉층을 통과한 결과에 ReLU 활성화 함수를 적용.\n",
    "x = self.out(x):\n",
    "ReLU를 통과한 결과를 출력층에 전달.\n",
    "x = self.softmax(x):\n",
    "출력층 결과에 Softmax 활성화 함수를 적용해, 결과를 확률 분포로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b38366-2039-4c02-9505-16d21e819593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "y_pred = model(x)\n",
    "loss = loss_fn(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e2752-4274-449e-964c-82b97b1876b7",
   "metadata": {},
   "source": [
    "MSELoss는 평균 제곱 오차(MSE: Mean Squared Error) 손실 함수\n",
    "reduction='sum' 옵션은 모든 오류 값을 합산하는 방식을 사용. 즉, 예측값과 실제값 사이의 오차의 제곱을 구한 후 그 값을 모두 더함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1001c8c-a484-4c9e-beff-2d8e9a84a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(5, 6, requires_grad=True) ------ torch.randn은 평균이 0이고 표준편차가 1인 가우시안 정규분포를 이용하여 숫자를 생성\n",
    "target = torch.empty(3, dtype=torch.long).random_(5) ------ torch.empty는 dtype torch.float32의 랜덤한 값으로 채워진 텐서를 반환\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b847afe-3333-41de-aa3d-113392a92c55",
   "metadata": {},
   "source": [
    "크로스 엔트로피 손실 함수를 사용해 예측값과 실제값의 손실을 계산하고, 역전파(backpropagation)를 수행하는 과정\n",
    "이는 분류 문제에서 자주 사용되며, 예측 분포와 실제 분포 사이의 차이를 측정합니다. 주로 다중 클래스 분류에서 사용됨.\n",
    "계산된 손실 output을 기준으로 역전파(backpropagation)를 수행해, 신경망의 각 파라미터에 대한 기울기(gradient)를 계산."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff6c3f-d32a-485e-8354-8208b8701e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DropoutModel, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(784, 1200)\n",
    "        self.dropout1 = torch.nn.Dropout(0.5) ------ 50%의 노드를 무작위로 선택하여 사용하지 않겠다는 의미\n",
    "        self.layer2 = torch.nn.Linear(1200, 1200)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.layer3 = torch.nn.Linear(1200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.dropout2(x)\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694130f1-2007-4538-889f-bfde6b19d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "이 코드는 DropoutModel이라는 신경망을 정의한 것으로, 3개의 선형 계층과 드롭아웃(Dropout)이 적용된 모델이다. \n",
    "드롭아웃은 학습 중에 각 층에서 50%의 노드를 무작위로 비활성화해, 과적합(overfitting)을 방지하는 역할을 한다. \n",
    "forward() 함수에서는 입력 데이터를 각 선형 계층에 통과시키며, ReLU 활성화 함수와 드롭아웃을 적용한 후 마지막 출력층에서 10개의 클래스 예측값을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4ddab-d445-4fda-86ee-2546e8e48789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "        self.y_data = [[12], [18], [11]]\n",
    "        def __len__(self):\n",
    "            return len(self.x_data)\n",
    "        def __getitem__(self, idx):\n",
    "            x = torch.FloatTensor(self.x_data[idx])\n",
    "            y = torch.FloatTensor(self.y_data[idx])\n",
    "            return x, y\n",
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(\n",
    "    dataset, ------ 데이터셋\n",
    "    batch_size=2, ------ 미니 배치 크기로 2의 제곱수를 사용하겠다는 의미입니다.\n",
    "    shuffle=True, ------ 데이터를 불러올 때마다 랜덤으로 섞어서 가져옵니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582abd8-b073-48ed-bf31-03d7c2e9cbad",
   "metadata": {},
   "source": [
    "이 코드는 PyTorch의 CustomDataset을 정의하여 데이터를 모델 학습에 사용할 수 있도록 구성한 것\n",
    "__init__()에서 x_data와 y_data를 초기화해 입력 데이터와 레이블을 저장한다.\n",
    "__len__()은 데이터셋의 크기를 반환하며, __getitem__()은 인덱스에 맞는 데이터를 가져온다.\n",
    "DataLoader는 batch_size=2로 설정되어, 2개의 데이터씩 묶어 미니 배치를 생성하고, shuffle=True로 데이터를 랜덤하게 섞는다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
