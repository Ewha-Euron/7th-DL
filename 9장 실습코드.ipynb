{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbcd27e-ebba-4f3b-9e77-4d5c232ce951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c7438a-4cdd-4120-a7c1-9a6622ace563",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=nltk.word_tokenize('Is it possible to distinguish cats and dogs')\n",
    "# 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f742068-4616-4f75-bfc6-b30e61edfc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Is', 'it', 'possible', 'to', 'distinguish', 'cats', 'and', 'dogs']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perception_tagger: Package\n",
      "[nltk_data]     'averaged_perception_tagger' not found in index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('possible', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('distinguish', 'VB'),\n",
       " ('cats', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('dogs', 'NNS')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text)\n",
    "# 태깅에 필요한 자원 내려받기\n",
    "nltk.download('averaged_perception_tagger')\n",
    "# 품사태깅\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16aa7227-df4c-4a49-9549-52faa6a5cd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'favorite',\n",
       " 'subject',\n",
       " 'is',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'english',\n",
       " ',',\n",
       " 'math',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'science']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk 라이어블리 호출 및 문장 정의\n",
    "string1='my favorite subject is statistics'\n",
    "string2='my favorite subject is statistics, english, math and computer science'\n",
    "# 단어 단위로 분리\n",
    "nltk.word_tokenize(string1)\n",
    "nltk.word_tokenize(string2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44331a30-bfa9-44df-8699-bdfc87d9944f",
   "metadata": {},
   "source": [
    "## **9.2 텍스트 데이터 전처리**\n",
    "#### 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d4676a3-1396-412e-85c1-5be552a6d6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tissue</th>\n",
       "      <th>class</th>\n",
       "      <th>class2</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mdb000</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>N</td>\n",
       "      <td>535.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mdb001</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>N</td>\n",
       "      <td>433.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mdb002</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mdb003</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mdb004</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>I</td>\n",
       "      <td>488.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mdb005</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>B</td>\n",
       "      <td>544.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id tissue class class2      x      y      r\n",
       "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
       "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
       "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
       "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
       "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
       "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치를 확인할 데이터\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/sshyu/OneDrive/바탕 화면/Euron/chap09/data/class2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d444943-d723-46ef-b70c-74e35b33c814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "id            0\n",
       "tissue        0\n",
       "class         0\n",
       "class2        0\n",
       "x             2\n",
       "y             2\n",
       "r             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 개수 확인\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "752ec225-a709-45ab-88f9-a0fbe220e491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0.000000\n",
       "id            0.000000\n",
       "tissue        0.000000\n",
       "class         0.000000\n",
       "class2        0.000000\n",
       "x             0.333333\n",
       "y             0.333333\n",
       "r             0.333333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터 대비 결측치 비율 확인\n",
    "df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa0bc49-5480-42ad-8dd6-e07f36fd59cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tissue</th>\n",
       "      <th>class</th>\n",
       "      <th>class2</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mdb000</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>N</td>\n",
       "      <td>535.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mdb001</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>N</td>\n",
       "      <td>433.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mdb002</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mdb003</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mdb004</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>I</td>\n",
       "      <td>488.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mdb005</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>B</td>\n",
       "      <td>544.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id tissue class class2      x      y      r\n",
       "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
       "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
       "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
       "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
       "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
       "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 행에 결측치가 존재한다면 해당 행을 삭제하는 처리 방법\n",
    "df.dropna(how='all',inplace=True) # 모든 행이 nan일 때만 삭제\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f91c0f31-8742-4175-94e1-1405939b251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tissue</th>\n",
       "      <th>class</th>\n",
       "      <th>class2</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mdb000</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>N</td>\n",
       "      <td>535.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mdb001</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>N</td>\n",
       "      <td>433.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mdb004</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>I</td>\n",
       "      <td>488.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mdb005</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>B</td>\n",
       "      <td>544.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id tissue class class2      x      y      r\n",
       "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
       "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
       "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
       "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터에 하나라도 nan이 있을 때 해당 행을 삭제\n",
    "df1=df.dropna(inplace=False)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7329aad0-05fe-49d6-b232-79c87d6da452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tissue</th>\n",
       "      <th>class</th>\n",
       "      <th>class2</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mdb000</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>N</td>\n",
       "      <td>535.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mdb001</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>N</td>\n",
       "      <td>433.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mdb002</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mdb003</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mdb004</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>I</td>\n",
       "      <td>488.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mdb005</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>B</td>\n",
       "      <td>544.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id tissue class class2      x      y      r\n",
       "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
       "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
       "2           2  mdb002      A  CIRA      I    0.0    0.0    0.0\n",
       "3           3  mdb003      C  CIRC      B    0.0    0.0    0.0\n",
       "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
       "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치를 0으로 채우기\n",
    "df2=df.fillna(0)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a797bbab-4e36-4027-972f-84f78457cecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshyu\\AppData\\Local\\Temp\\ipykernel_5952\\1262216063.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['x'].fillna(df['x'].mean(),inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tissue</th>\n",
       "      <th>class</th>\n",
       "      <th>class2</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mdb000</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>N</td>\n",
       "      <td>535.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mdb001</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>N</td>\n",
       "      <td>433.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mdb002</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>I</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mdb003</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mdb004</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>I</td>\n",
       "      <td>488.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mdb005</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>B</td>\n",
       "      <td>544.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id tissue class class2      x      y      r\n",
       "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
       "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
       "2           2  mdb002      A  CIRA      I  500.0    NaN    NaN\n",
       "3           3  mdb003      C  CIRC      B  500.0    NaN    NaN\n",
       "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
       "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치를 평균으로 채우기\n",
    "df['x'].fillna(df['x'].mean(),inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4943809f-0a3d-437b-a6ad-ca3ff036dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural Language Processing, or NLP, is the process of extracting the meaning, or intent, behind human language.', 'In the field of Conversational artificial intelligence (AI), NLP allows machines and applications to understand the intent of human language inputs, and then generate appropriate responses, resulting in a natural conversation flow.']\n"
     ]
    }
   ],
   "source": [
    "# x의 결측치가 평균인 500으로 채워짐\n",
    "# 문장 토큰화\n",
    "from nltk import sent_tokenize\n",
    "text_sample = 'Natural Language Processing, or NLP, is the process of extracting the meaning, or intent, behind human language. In the field of Conversational artificial intelligence (AI), NLP allows machines and applications to understand the intent of human language inputs, and then generate appropriate responses, resulting in a natural conversation flow.'\n",
    "tokenized_sentences = sent_tokenize(text_sample)\n",
    "print(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94597501-28f1-4bab-ae59-e5b95caf4e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'book', 'is', 'for', 'deep', 'learning', 'learners']\n"
     ]
    }
   ],
   "source": [
    "# 단어 토큰화\n",
    "from nltk import word_tokenize\n",
    "sentence = \" This book is for deep learning learners\"\n",
    "words = word_tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a24676ca-8a85-4488-8ce2-18e5c1f2460f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', '’', 's', 'nothing', 'that', 'you', 'don', '’', 't', 'already', 'know', 'except', 'most', 'people', 'aren', '’', 't', 'aware', 'of', 'how', 'their', 'inner', 'world', 'works', '.']\n"
     ]
    }
   ],
   "source": [
    "# ' 가 포함된 문장 토큰화\n",
    "from nltk.tokenize import WordPunctTokenizer  \n",
    "sentence = \"it’s nothing that you don’t already know except most people aren’t aware of how their inner world works.\"\n",
    "words = WordPunctTokenizer().tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02f951bb-b8b2-475d-bcc2-7c623c9550ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Downloading jpype1-1.5.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting lxml>=4.1.0 (from konlpy)\n",
      "  Using cached lxml-5.3.0-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\sshyu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\sshyu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
      "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "   ---------------------------------------- 0.0/19.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/19.4 MB 8.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.6/19.4 MB 7.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 4.7/19.4 MB 8.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 6.8/19.4 MB 8.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 9.2/19.4 MB 9.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 11.0/19.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 12.6/19.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 14.4/19.4 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 16.5/19.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 18.4/19.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.4/19.4 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading jpype1-1.5.1-cp312-cp312-win_amd64.whl (355 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.1/3.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 9.9 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml, JPype1, konlpy\n",
      "Successfully installed JPype1-1.5.1 konlpy-0.6.0 lxml-5.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce7abe6d-66d2-4fa5-a694-fba1c2140c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\sshyu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sshyu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.8/24.0 MB 9.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.7/24.0 MB 9.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.5/24.0 MB 8.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.6/24.0 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 9.7/24.0 MB 9.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.1/24.0 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.2/24.0 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.5/24.0 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.6/24.0 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.7/24.0 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "   ---------------------------------------- 0.0/45.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.1/45.9 MB 10.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.2/45.9 MB 10.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.8/45.9 MB 10.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.9/45.9 MB 9.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 10.0/45.9 MB 9.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 12.1/45.9 MB 9.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 14.4/45.9 MB 9.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 17.0/45.9 MB 10.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 19.4/45.9 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.5/45.9 MB 10.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.1/45.9 MB 10.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 26.5/45.9 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.8/45.9 MB 10.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.2/45.9 MB 10.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.3/45.9 MB 10.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 35.9/45.9 MB 10.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.3/45.9 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.9/45.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.3/45.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.6/45.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.9/45.9 MB 10.5 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, scipy, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "Successfully installed gensim-4.3.3 scipy-1.13.1 smart-open-7.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sshyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~cipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sshyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~cipy'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87c47c08-e250-4e15-878e-0205d0ffd747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 토큰화 예제\n",
    "import csv\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import word2vec\n",
    "\n",
    "f = open(r\"C:/Users/sshyu/OneDrive/바탕 화면/Euron/chap09/data/ratings_train.txt\", 'r', encoding='utf-8')\n",
    "rdr = csv.reader(f, delimiter='\\t')\n",
    "rdw = list(rdr)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "914b0236-cf0d-4cf3-a2bd-6490be58961c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntwitter=Okt()\\nresult=[]\\nfor line in rdw: # 한줄식 처리\\n    malist=twitter.pos(line[1],norm=True,stem=True) # 형태소 분석\\n    r=[]\\n    for word in malist:\\n        if not word[1] in ['Josa','Eomi','Punctuation']: # 조사 어미 문장 부호는 제외시키기\\n            r.append(word[0])\\n    rl=(' '.join(r)).strip() # 형태소 사이에 공백을 넣고 양쪽 공백은 삭제시키기\\n    result.append(rl)\\n    print(rl)\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오픈 소스 한글 형태소 분석기\n",
    "'''\n",
    "twitter=Okt()\n",
    "result=[]\n",
    "for line in rdw: # 한줄식 처리\n",
    "    malist=twitter.pos(line[1],norm=True,stem=True) # 형태소 분석\n",
    "    r=[]\n",
    "    for word in malist:\n",
    "        if not word[1] in ['Josa','Eomi','Punctuation']: # 조사 어미 문장 부호는 제외시키기\n",
    "            r.append(word[0])\n",
    "    rl=(' '.join(r)).strip() # 형태소 사이에 공백을 넣고 양쪽 공백은 삭제시키기\n",
    "    result.append(rl)\n",
    "    print(rl)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd847048-f052-4909-97c2-2c1ef9634ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 생성한 형태소를 별도의 파일로 저장\\nwith open(\"NaverMovie.nlp\",\\'w\\', encoding=\\'utf-8\\') as fp:\\n    fp.write(\"\\n\".join(result))\\n# Word2Vect 모델을 생성한 후 저장\\nmData = word2vec.LineSentence(\"NaverMovie.nlp\")\\nmModel =word2vec.Word2Vec(mData, vector_size=200, window=10, hs=1, min_count=2, sg=1)\\nmModel.save(\"NaverMovie.model\")\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 생성한 형태소를 별도의 파일로 저장\n",
    "with open(\"NaverMovie.nlp\",'w', encoding='utf-8') as fp:\n",
    "    fp.write(\"\\n\".join(result))\n",
    "# Word2Vect 모델을 생성한 후 저장\n",
    "mData = word2vec.LineSentence(\"NaverMovie.nlp\")\n",
    "mModel =word2vec.Word2Vec(mData, vector_size=200, window=10, hs=1, min_count=2, sg=1)\n",
    "mModel.save(\"NaverMovie.model\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27a74d20-9e46-4ad5-8e78-5666a08c80b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 미적용: ['One', 'of', 'the', 'first', 'things', 'that', 'we', 'ask', 'ourselves', 'is', 'what', 'are', 'the', 'pros', 'and', 'cons', 'of', 'any', 'task', 'we', 'perform', '.'] \n",
      "\n",
      "불용어 제거 적용: ['One', 'first', 'things', 'ask', 'pros', 'cons', 'task', 'perform', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sshyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sshyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 불용어 제거\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "sample_text = \"One of the first things that we ask ourselves is what are the pros and cons of any task we perform.\"\n",
    "text_tokens = word_tokenize(sample_text)\n",
    "\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "print(\"불용어 제거 미적용:\", text_tokens, '\\n')\n",
    "print(\"불용어 제거 적용:\",tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe49bcef-8ada-4424-8e04-d78d5060bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obess obsses\n",
      "standard standard\n",
      "nation nation\n",
      "absent absent\n",
      "tribal tribalic\n"
     ]
    }
   ],
   "source": [
    "# 어간 추출\n",
    "# 포터 알고리즘\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "print(stemmer.stem('obesses'),stemmer.stem('obssesed'))\n",
    "print(stemmer.stem('standardizes'),stemmer.stem('standardization'))\n",
    "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
    "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
    "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2661c168-fdd3-424b-bb0c-253f3f5f5303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obsess obsess\n",
      "standard standard\n",
      "nat nat\n",
      "abs abs\n",
      "trib trib\n"
     ]
    }
   ],
   "source": [
    "# 랭커스터 알고리즘\n",
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('obsesses'),stemmer.stem('obsessed'))\n",
    "print(stemmer.stem('standardizes'),stemmer.stem('standardization'))\n",
    "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
    "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
    "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))\n",
    "# 포터 알고리즘과 달리 랭커스터 알고리즘은 단어 원형을 알아볼 수 없을 정도로 축소시키기 때문에 정확도가 낮음\n",
    "# 따라서 일반적인 상황보다는 데이터셋을 축소시켜야 하는 상황에서 쓰임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cb767ea-c1eb-4ef2-a089-38670e634045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obsess obsess\n",
      "standardizes standardization\n",
      "national nation\n",
      "absentness absently\n",
      "tribalical tribalicalized\n"
     ]
    }
   ],
   "source": [
    "# 표제어 추출\n",
    "# 일반적으로 어간 추출보다 표제어 추출이 문장 내에서 단어 의미도 고려하기 때문에\n",
    "# 더 성능이 좋음\n",
    "# 하지만 어간 추출보다 시간이 더 오래 걸리는 단점이 있음\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "print(stemmer.stem('obsesses'),stemmer.stem('obsessed'))\n",
    "print(lemma.lemmatize('standardizes'),lemma.lemmatize('standardization'))\n",
    "print(lemma.lemmatize('national'), lemma.lemmatize('nation'))\n",
    "print(lemma.lemmatize('absentness'), lemma.lemmatize('absently'))\n",
    "print(lemma.lemmatize('tribalical'), lemma.lemmatize('tribalicalized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44bc50f5-606e-4ae0-a821-7b1f44a1c296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obsess obsessed\n",
      "standardize standardization\n",
      "national nation\n",
      "absentness absently\n",
      "tribalical tribalicalized\n"
     ]
    }
   ],
   "source": [
    "# 표제어 추출의 성능을 높이기 위해 단어에 대한 품사 정보 추가하기\n",
    "print(lemma.lemmatize('obsesses', 'v'),lemma.lemmatize('obsessed','a'))\n",
    "print(lemma.lemmatize('standardizes','v'),lemma.lemmatize('standardization','n'))\n",
    "print(lemma.lemmatize('national','a'), lemma.lemmatize('nation','n'))\n",
    "print(lemma.lemmatize('absentness','n'), lemma.lemmatize('absently','r'))\n",
    "print(lemma.lemmatize('tribalical','a'), lemma.lemmatize('tribalicalized','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53e2a6a5-13e4-464b-aa5a-c72662f56ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c0ff6b4-b4aa-488d-8a7f-d3828a6344ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로 지정과 훈련 테스트 용도로 분리하기\n",
    "df = pd.read_csv(\"C:/Users/sshyu/Downloads/archive/diabetes.csv\")\n",
    "X = df[df.columns[:-1]]\n",
    "y = df['Outcome'] # 당뇨병인지 아닌지 레이블\n",
    "\n",
    "X = X.values\n",
    "y = torch.tensor(y.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a02bd63a-9e31-4602-be67-b952aaa1e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 진행\n",
    "# train data의 경우 standard scaler\n",
    "# test data의 경우 minmax scaler\n",
    "ms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.fit_transform(X_test)\n",
    "y_train =y_train.reshape(-1, 1)\n",
    "y_test =y_test.reshape(-1, 1)\n",
    "y_train = ms.fit_transform(y_train)\n",
    "y_test = ms.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "083dc9ac-a55b-45cd-886d-e3584c24df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 외에도 두가지 더\n",
    "# 하나는 robust scaler로 평균과 분산 대신 median과 iqr를 사용\n",
    "# maxabsscaler는 절댓값이 0-1 사이가 되도록 조정, 이상치에 민감하다는 단점이 있음\n",
    "# 데이터 셋을 더 쉽게 다루기 위해 커스텀 데이터셋 생성하기\n",
    "class customdataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.len = len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ce7afe4-f52b-4901-8cab-252dd6675929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 따라서 배치 단위로 쪼개서 처리하거나, 무작위로 shuffle이 가능함\n",
    "# 데이터 로더에 담아서 배치 단위로 불러오게 하기\n",
    "train_data = customdataset(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "test_data = customdataset(torch.FloatTensor(X_test), \n",
    "                       torch.FloatTensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f11ffdd-36a0-4a86-a09e-f5d76c361b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 생성하기 - 배치 정규화가 포함된 선형 계층으로\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(8, 64, bias=True) # 칼럼이 8개 이므로\n",
    "        self.layer_2 = nn.Linear(64, 64, bias=True)\n",
    "        self.layer_out = nn.Linear(64, 1, bias=True) # 당뇨병인지 아닌지 0,1        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "809739eb-1ee1-43d6-ba62-2102c1b71704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 손실함수와 옵티마이저 지정\n",
    "epochs = 1000+1\n",
    "print_epoch = 100\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "BCE = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "454e70cf-b8e0-4136-85ba-e46ea371009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능 측정 함수 정의\n",
    "def accuracy(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6fcf6d2-4041-4e1d-8c11-d9347b7094b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: epoch: 0 - loss: 0.68608; acc: 60.444\n",
      "Test: epoch: 0 - loss: 0.68412; acc: 64.500\n",
      "Train: epoch: 100 - loss: 0.51557; acc: 76.222\n",
      "Test: epoch: 100 - loss: 0.46019; acc: 77.000\n",
      "Train: epoch: 200 - loss: 0.40767; acc: 82.778\n",
      "Test: epoch: 200 - loss: 0.46051; acc: 76.750\n",
      "Train: epoch: 300 - loss: 0.39077; acc: 81.000\n",
      "Test: epoch: 300 - loss: 0.46713; acc: 79.250\n",
      "Train: epoch: 400 - loss: 0.53455; acc: 79.222\n",
      "Test: epoch: 400 - loss: 0.51361; acc: 75.500\n",
      "Train: epoch: 500 - loss: 0.43211; acc: 78.000\n",
      "Test: epoch: 500 - loss: 0.45575; acc: 78.750\n",
      "Train: epoch: 600 - loss: 0.53097; acc: 70.222\n",
      "Test: epoch: 600 - loss: 0.46291; acc: 79.500\n",
      "Train: epoch: 700 - loss: 0.37893; acc: 83.889\n",
      "Test: epoch: 700 - loss: 0.47937; acc: 78.250\n",
      "Train: epoch: 800 - loss: 0.44165; acc: 74.667\n",
      "Test: epoch: 800 - loss: 0.53757; acc: 76.750\n",
      "Train: epoch: 900 - loss: 0.47297; acc: 77.889\n",
      "Test: epoch: 900 - loss: 0.51639; acc: 76.000\n",
      "Train: epoch: 1000 - loss: 0.43519; acc: 77.111\n",
      "Test: epoch: 1000 - loss: 0.50514; acc: 75.250\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습시키기\n",
    "for epoch in range(epochs):    \n",
    "    iteration_loss = 0.\n",
    "    iteration_accuracy = 0.\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        X, y = data\n",
    "        y_pred = model(X.float())\n",
    "        loss = BCE(y_pred, y.reshape(-1,1).float())     \n",
    "      \n",
    "        iteration_loss += loss\n",
    "        iteration_accuracy += accuracy(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(epoch % print_epoch == 0):\n",
    "        print('Train: epoch: {0} - loss: {1:.5f}; acc: {2:.3f}'.format(epoch, iteration_loss/(i+1), iteration_accuracy/(i+1)))\n",
    "    \n",
    "    iteration_loss = 0.\n",
    "    iteration_accuracy = 0.\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        X, y = data\n",
    "        y_pred = model(X.float())\n",
    "        loss = BCE(y_pred, y.reshape(-1,1).float())\n",
    "        iteration_loss += loss\n",
    "        iteration_accuracy += accuracy(y_pred, y)\n",
    "    if(epoch % print_epoch == 0):\n",
    "        print('Test: epoch: {0} - loss: {1:.5f}; acc: {2:.3f}'.format(epoch, iteration_loss/(i+1), iteration_accuracy/(i+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
