{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#10.1.1 희소표현(Sparse Representation)"
      ],
      "metadata": {
        "id": "gyOk5MvXzeC-"
      },
      "id": "gyOk5MvXzeC-"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files # 데이터 불러오기\n",
        "file_uploaded=files.upload()   # chap10/data/class2.csv 데이터 불러오기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "8p2aHzC0-6wu",
        "outputId": "9bd11104-bbc2-482d-8be9-1766015e4b73"
      },
      "id": "8p2aHzC0-6wu",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-38080a47-805f-4f40-a1af-0c454a6de1cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-38080a47-805f-4f40-a1af-0c454a6de1cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving class2.csv to class2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d93e9e0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93e9e0d",
        "outputId": "5c741ea4-e901-49c6-93b1-6c1807e44ddd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "class2=pd.read_csv(\"class2.csv\")\n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "onehot_encoder = preprocessing.OneHotEncoder()\n",
        "\n",
        "train_x = label_encoder.fit_transform(class2['class2'])\n",
        "train_x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.1.2 횟수기반 임베딩"
      ],
      "metadata": {
        "id": "ZGxq7KS0zn_S"
      },
      "id": "ZGxq7KS0zn_S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Counter Vector"
      ],
      "metadata": {
        "id": "z0kFz8GHzrOu"
      },
      "id": "z0kFz8GHzrOu"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d5298928",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5298928",
        "outputId": "87548617-2fb9-4440-98cf-6627ab6e9383"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'this': 13,\n",
              " 'is': 7,\n",
              " 'last': 8,\n",
              " 'chance': 2,\n",
              " 'and': 0,\n",
              " 'if': 6,\n",
              " 'you': 15,\n",
              " 'do': 3,\n",
              " 'not': 10,\n",
              " 'have': 5,\n",
              " 'will': 14,\n",
              " 'never': 9,\n",
              " 'get': 4,\n",
              " 'any': 1,\n",
              " 'one': 11,\n",
              " 'please': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'This is last chance.',\n",
        "    'and if you do not have this chance.',\n",
        "    'you will never get any chance.',\n",
        "    'will you do get this one?',\n",
        "    'please, get this chance',\n",
        "]\n",
        "vect = CountVectorizer()\n",
        "vect.fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cda3fe3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cda3fe3e",
        "outputId": "ad5fb69e-4cd6-412f-c932-bd885538a5e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "vect.transform(['you will never get any chance.']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6b305aef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b305aef",
        "outputId": "2fdc67f8-2247-4ad3-e19c-c84328ddb3a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last': 6,\n",
              " 'chance': 1,\n",
              " 'if': 5,\n",
              " 'you': 11,\n",
              " 'do': 2,\n",
              " 'not': 8,\n",
              " 'have': 4,\n",
              " 'will': 10,\n",
              " 'never': 7,\n",
              " 'get': 3,\n",
              " 'any': 0,\n",
              " 'one': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"please\", \"this\"]).fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "zXD9qEe1zvng"
      },
      "id": "zXD9qEe1zvng"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8fea52e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fea52e5",
        "outputId": "ee1bfb73-2b60-4455-8e41-9aa715a3e427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유사도를 위한 3 x 3 matrix를 만들었습니다.\n",
            "[[1.       0.224325 0.      ]\n",
            " [0.224325 1.       0.      ]\n",
            " [0.       0.       1.      ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
        "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
        "print ('유사도를 위한', str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), 'matrix를 만들었습니다.')\n",
        "print(doc_distance.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.1.3 예측기반 임베딩"
      ],
      "metadata": {
        "id": "CQ0DJpR9zyl9"
      },
      "id": "CQ0DJpR9zyl9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "4QCD1bSgz1ad"
      },
      "id": "4QCD1bSgz1ad"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmcOz0VU_ROY",
        "outputId": "ef184099-030a-4508-bba2-a77e817437cc"
      },
      "id": "wmcOz0VU_ROY",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL2E_RP3_SB0",
        "outputId": "03f6a374-ee3c-45af-9ff5-7e05e4539068"
      },
      "id": "RL2E_RP3_SB0",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files # 데이터 불러오기\n",
        "file_uploaded=files.upload()   # chap10/data/peter.txt 데이터 불러오기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "DlANtiez_b0r",
        "outputId": "33dbff9a-e1a2-40df-e14e-c67f52d24368"
      },
      "id": "DlANtiez_b0r",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f4e53e4e-bebb-4938-9f78-1099110b8939\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f4e53e4e-bebb-4938-9f78-1099110b8939\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving peter.txt to peter.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d68eed27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d68eed27",
        "outputId": "b4f5d884-5cd4-4dc0-df4b-e10c56faf315"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['once',\n",
              "  'upon',\n",
              "  'a',\n",
              "  'time',\n",
              "  'in',\n",
              "  'london',\n",
              "  ',',\n",
              "  'the',\n",
              "  'darlings',\n",
              "  'went',\n",
              "  'out',\n",
              "  'to',\n",
              "  'a',\n",
              "  'dinner',\n",
              "  'party',\n",
              "  'leaving',\n",
              "  'their',\n",
              "  'three',\n",
              "  'children',\n",
              "  'wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  ',',\n",
              "  'and',\n",
              "  'michael',\n",
              "  'at',\n",
              "  'home',\n",
              "  '.'],\n",
              " ['after',\n",
              "  'wendy',\n",
              "  'had',\n",
              "  'tucked',\n",
              "  'her',\n",
              "  'younger',\n",
              "  'brothers',\n",
              "  'jhon',\n",
              "  'and',\n",
              "  'michael',\n",
              "  'to',\n",
              "  'bed',\n",
              "  ',',\n",
              "  'she',\n",
              "  'went',\n",
              "  'to',\n",
              "  'read',\n",
              "  'a',\n",
              "  'book',\n",
              "  '.'],\n",
              " ['she', 'heard', 'a', 'boy', 'sobbing', 'outside', 'her', 'window', '.'],\n",
              " ['he', 'was', 'flying', '.'],\n",
              " ['there', 'was', 'little', 'fairy', 'fluttering', 'around', 'him', '.'],\n",
              " ['wendy', 'opened', 'the', 'window', 'to', 'talk', 'to', 'him', '.'],\n",
              " ['“', 'hello', '!'],\n",
              " ['who', 'are', 'you', '?'],\n",
              " ['why', 'are', 'you', 'crying', '”', ',', 'wendy', 'asked', 'him', '.'],\n",
              " ['“', 'my', 'name', 'is', 'peter', 'pan', '.'],\n",
              " ['my',\n",
              "  'shadow',\n",
              "  'wouldn',\n",
              "  '’',\n",
              "  't',\n",
              "  'stock',\n",
              "  'to',\n",
              "  'me.',\n",
              "  '”',\n",
              "  ',',\n",
              "  'he',\n",
              "  'replied',\n",
              "  '.'],\n",
              " ['she', 'asked', 'him', 'to', 'come', 'in', '.'],\n",
              " ['peter', 'agreed', 'and', 'came', 'inside', 'the', 'room', '.'],\n",
              " ['wendy',\n",
              "  'took',\n",
              "  'his',\n",
              "  'shadow',\n",
              "  'and',\n",
              "  'sewed',\n",
              "  'it',\n",
              "  'to',\n",
              "  'his',\n",
              "  'shoe',\n",
              "  'tips',\n",
              "  '.'],\n",
              " ['now',\n",
              "  'his',\n",
              "  'shadow',\n",
              "  'followed',\n",
              "  'him',\n",
              "  'wherever',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'went',\n",
              "  '!'],\n",
              " ['he',\n",
              "  'was',\n",
              "  'delighted',\n",
              "  'and',\n",
              "  'asked',\n",
              "  'wendy',\n",
              "  '“',\n",
              "  'why',\n",
              "  'don',\n",
              "  '’',\n",
              "  't',\n",
              "  'you',\n",
              "  'come',\n",
              "  'with',\n",
              "  'me',\n",
              "  'to',\n",
              "  'my',\n",
              "  'home',\n",
              "  '.'],\n",
              " ['the', 'neverland', '.'],\n",
              " ['i',\n",
              "  'lived',\n",
              "  'there',\n",
              "  'with',\n",
              "  'my',\n",
              "  'fairy',\n",
              "  'tinker',\n",
              "  'bell.',\n",
              "  '”',\n",
              "  'wendy',\n",
              "  '?'],\n",
              " ['“', 'oh', '!'],\n",
              " ['what', 'a', 'wonderful', 'idea', '!'],\n",
              " ['let', 'me', 'wake', 'up', 'john', 'and', 'micheal', 'too', '.'],\n",
              " ['could', 'you', 'teach', 'us', 'how', 'to', 'fly', '?', '”', '.'],\n",
              " ['“', 'yes', '!'],\n",
              " ['of', 'course', '!'],\n",
              " ['get',\n",
              "  'them',\n",
              "  'we',\n",
              "  'will',\n",
              "  'all',\n",
              "  'fly',\n",
              "  'together.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'replied',\n",
              "  'and',\n",
              "  'so',\n",
              "  'it',\n",
              "  'was',\n",
              "  '.'],\n",
              " ['five',\n",
              "  'little',\n",
              "  'figures',\n",
              "  'flew',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'window',\n",
              "  'of',\n",
              "  'the',\n",
              "  'darlings',\n",
              "  'and',\n",
              "  'headed',\n",
              "  'towards',\n",
              "  'neverland',\n",
              "  '.'],\n",
              " ['as',\n",
              "  'they',\n",
              "  'flew',\n",
              "  'over',\n",
              "  'the',\n",
              "  'island',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'told',\n",
              "  'the',\n",
              "  'children',\n",
              "  'more',\n",
              "  'about',\n",
              "  'his',\n",
              "  'homeland',\n",
              "  '.'],\n",
              " ['“',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'who',\n",
              "  'get',\n",
              "  'lost',\n",
              "  'come',\n",
              "  'and',\n",
              "  'stay',\n",
              "  'with',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'and',\n",
              "  'me',\n",
              "  ',',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'told',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['the', 'indians', 'also', 'live', 'in', 'neverland', '.'],\n",
              " ['the',\n",
              "  'mermaids',\n",
              "  'live',\n",
              "  'in',\n",
              "  'the',\n",
              "  'lagoon',\n",
              "  'around',\n",
              "  'the',\n",
              "  'island',\n",
              "  '.'],\n",
              " ['and',\n",
              "  'a',\n",
              "  'very',\n",
              "  'mean',\n",
              "  'pirate',\n",
              "  'called',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'keeps',\n",
              "  'troubling',\n",
              "  'everyone',\n",
              "  '.'],\n",
              " ['“', 'crocodile', 'bit', 'his', 'one', 'arm', '.'],\n",
              " ['so',\n",
              "  'the',\n",
              "  'captain',\n",
              "  'had',\n",
              "  'to',\n",
              "  'put',\n",
              "  'a',\n",
              "  'hook',\n",
              "  'in',\n",
              "  'its',\n",
              "  'place',\n",
              "  '.'],\n",
              " ['since', 'then', 'he', 'is', 'afraid', 'of', 'crocodiles', '.'],\n",
              " ['and', 'rightly', 'so', '!'],\n",
              " ['if',\n",
              "  'the',\n",
              "  'crocodile',\n",
              "  'ever',\n",
              "  'found',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'it',\n",
              "  'will',\n",
              "  'eat',\n",
              "  'up',\n",
              "  'the',\n",
              "  'rest',\n",
              "  'of',\n",
              "  'it',\n",
              "  'couldn',\n",
              "  '’',\n",
              "  't',\n",
              "  'eat',\n",
              "  'last',\n",
              "  'time.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'told',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['soon', 'they', 'landed', 'on', 'the', 'island', '.'],\n",
              " ['and',\n",
              "  'to',\n",
              "  'the',\n",
              "  'surprise',\n",
              "  'of',\n",
              "  'wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  'and',\n",
              "  'michael',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'let',\n",
              "  'them',\n",
              "  'in',\n",
              "  'through',\n",
              "  'a',\n",
              "  'small',\n",
              "  'opening',\n",
              "  'in',\n",
              "  'a',\n",
              "  'tree',\n",
              "  '.'],\n",
              " ['inside',\n",
              "  'the',\n",
              "  'tree',\n",
              "  'was',\n",
              "  'a',\n",
              "  'large',\n",
              "  'room',\n",
              "  'with',\n",
              "  'children',\n",
              "  'inside',\n",
              "  'it',\n",
              "  '.'],\n",
              " ['somewhere',\n",
              "  'huddled',\n",
              "  'by',\n",
              "  'the',\n",
              "  'fire',\n",
              "  'in',\n",
              "  'the',\n",
              "  'corner',\n",
              "  'and',\n",
              "  'somewhere',\n",
              "  'playing',\n",
              "  'amongst',\n",
              "  'themselves',\n",
              "  '.'],\n",
              " ['their',\n",
              "  'faces',\n",
              "  'lit',\n",
              "  'up',\n",
              "  'when',\n",
              "  'they',\n",
              "  'saw',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  ',',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  ',',\n",
              "  'and',\n",
              "  'their',\n",
              "  'guests',\n",
              "  '.'],\n",
              " ['“', 'hello', 'everyone', '.'],\n",
              " ['this', 'is', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
              " ['they',\n",
              "  'will',\n",
              "  'be',\n",
              "  'staying',\n",
              "  'with',\n",
              "  'us',\n",
              "  'from',\n",
              "  'now',\n",
              "  'on.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'introduced',\n",
              "  'them',\n",
              "  'to',\n",
              "  'all',\n",
              "  'children',\n",
              "  '.'],\n",
              " ['children', 'welcomed', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
              " ['a', 'few', 'days', 'passed', '.'],\n",
              " ['and', 'they', 'settled', 'into', 'a', 'routine', '.'],\n",
              " ['wendy',\n",
              "  'would',\n",
              "  'take',\n",
              "  'care',\n",
              "  'of',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'in',\n",
              "  'the',\n",
              "  'day',\n",
              "  'and',\n",
              "  'would',\n",
              "  'go',\n",
              "  'out',\n",
              "  'with',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'and',\n",
              "  'her',\n",
              "  'brothers',\n",
              "  'in',\n",
              "  'the',\n",
              "  'evening',\n",
              "  'to',\n",
              "  'learn',\n",
              "  'about',\n",
              "  'the',\n",
              "  'island',\n",
              "  '.'],\n",
              " ['she',\n",
              "  'would',\n",
              "  'cook',\n",
              "  'for',\n",
              "  'them',\n",
              "  'and',\n",
              "  'stitch',\n",
              "  'new',\n",
              "  'clothes',\n",
              "  'for',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'even',\n",
              "  'made',\n",
              "  'a',\n",
              "  'lovely',\n",
              "  'new',\n",
              "  'dress',\n",
              "  'for',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  '.'],\n",
              " ['one',\n",
              "  'evening',\n",
              "  ',',\n",
              "  'as',\n",
              "  'they',\n",
              "  'were',\n",
              "  'out',\n",
              "  'exploring',\n",
              "  'the',\n",
              "  'island',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'warned',\n",
              "  'everyone',\n",
              "  'and',\n",
              "  'said',\n",
              "  ',',\n",
              "  '“',\n",
              "  'hide',\n",
              "  '!'],\n",
              " ['hide', '!'],\n",
              " ['pirates', '!'],\n",
              " ['and',\n",
              "  'they',\n",
              "  'have',\n",
              "  'kidnapped',\n",
              "  'the',\n",
              "  'indian',\n",
              "  'princess',\n",
              "  'tiger',\n",
              "  'lily',\n",
              "  '.'],\n",
              " ['they',\n",
              "  'have',\n",
              "  'kept',\n",
              "  'her',\n",
              "  'there',\n",
              "  ',',\n",
              "  'tied',\n",
              "  'up',\n",
              "  'by',\n",
              "  'the',\n",
              "  'rocks',\n",
              "  ',',\n",
              "  'near',\n",
              "  'the',\n",
              "  'water.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'was',\n",
              "  'afraid',\n",
              "  'and',\n",
              "  'the',\n",
              "  'princess',\n",
              "  'would',\n",
              "  'drown',\n",
              "  ',',\n",
              "  'is',\n",
              "  'she',\n",
              "  'fell',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water',\n",
              "  '.'],\n",
              " ['so',\n",
              "  ',',\n",
              "  'in',\n",
              "  'a',\n",
              "  'voice',\n",
              "  'that',\n",
              "  'sounded',\n",
              "  'like',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  ',',\n",
              "  'he',\n",
              "  'shouted',\n",
              "  'instructions',\n",
              "  'to',\n",
              "  'the',\n",
              "  'pirates',\n",
              "  'who',\n",
              "  'guarded',\n",
              "  'her',\n",
              "  ',',\n",
              "  '“',\n",
              "  'you',\n",
              "  'fools',\n",
              "  '!'],\n",
              " ['let', 'her', 'go', 'at', 'once', '!'],\n",
              " ['do',\n",
              "  'it',\n",
              "  'before',\n",
              "  'i',\n",
              "  'come',\n",
              "  'there',\n",
              "  'or',\n",
              "  'else',\n",
              "  'i',\n",
              "  'will',\n",
              "  'throw',\n",
              "  'each',\n",
              "  'one',\n",
              "  'of',\n",
              "  'you',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water.',\n",
              "  '”',\n",
              "  'the',\n",
              "  'pirates',\n",
              "  'got',\n",
              "  'scared',\n",
              "  'and',\n",
              "  'immediately',\n",
              "  'released',\n",
              "  'the',\n",
              "  'princes',\n",
              "  '.'],\n",
              " ['she',\n",
              "  'quickly',\n",
              "  'dived',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water',\n",
              "  'and',\n",
              "  'swam',\n",
              "  'to',\n",
              "  'the',\n",
              "  'safety',\n",
              "  'of',\n",
              "  'her',\n",
              "  'home',\n",
              "  '.'],\n",
              " ['soon',\n",
              "  'everyone',\n",
              "  'found',\n",
              "  'out',\n",
              "  'how',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'had',\n",
              "  'rescued',\n",
              "  'the',\n",
              "  'princess',\n",
              "  '.'],\n",
              " ['when',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'found',\n",
              "  'out',\n",
              "  'how',\n",
              "  'peter',\n",
              "  'had',\n",
              "  'tricked',\n",
              "  'his',\n",
              "  'men',\n",
              "  'he',\n",
              "  'was',\n",
              "  'furious',\n",
              "  '.'],\n",
              " ['and', 'swore', 'to', 'have', 'his', 'revenge', '.'],\n",
              " ['that',\n",
              "  'night',\n",
              "  'wendy',\n",
              "  'told',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  ',',\n",
              "  'that',\n",
              "  'she',\n",
              "  'and',\n",
              "  'her',\n",
              "  'brother',\n",
              "  'wanted',\n",
              "  'to',\n",
              "  'go',\n",
              "  'back',\n",
              "  'home',\n",
              "  'since',\n",
              "  'they',\n",
              "  'missed',\n",
              "  'their',\n",
              "  'parents',\n",
              "  '.'],\n",
              " ['she',\n",
              "  'said',\n",
              "  'if',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  'could',\n",
              "  'also',\n",
              "  'return',\n",
              "  'to',\n",
              "  'her',\n",
              "  'world',\n",
              "  'they',\n",
              "  'could',\n",
              "  'find',\n",
              "  'a',\n",
              "  'nice',\n",
              "  'home',\n",
              "  'for',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['peter', 'pan', 'didn', '’', 't', 'want', 'to', 'leave', 'neverland', '.'],\n",
              " ['but',\n",
              "  'the',\n",
              "  'sake',\n",
              "  'of',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  'he',\n",
              "  'agreed',\n",
              "  ',',\n",
              "  'although',\n",
              "  'a',\n",
              "  'bit',\n",
              "  'sadly',\n",
              "  '.'],\n",
              " ['he', 'would', 'miss', 'his', 'friends', 'dearly', '.'],\n",
              " ['the',\n",
              "  'next',\n",
              "  'morning',\n",
              "  'all',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  'left',\n",
              "  'with',\n",
              "  'wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  ',',\n",
              "  'and',\n",
              "  'michael',\n",
              "  '.'],\n",
              " ['but',\n",
              "  'on',\n",
              "  'the',\n",
              "  'way',\n",
              "  ',',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'and',\n",
              "  'his',\n",
              "  'men',\n",
              "  'kidnapped',\n",
              "  'all',\n",
              "  'of',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'tied',\n",
              "  'them',\n",
              "  'and',\n",
              "  'kept',\n",
              "  'them',\n",
              "  'on',\n",
              "  'once',\n",
              "  'of',\n",
              "  'his',\n",
              "  'ships',\n",
              "  '.'],\n",
              " ['as',\n",
              "  'soon',\n",
              "  'as',\n",
              "  'peter',\n",
              "  'found',\n",
              "  'out',\n",
              "  'about',\n",
              "  'it',\n",
              "  'he',\n",
              "  'rushed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'ship',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'swung',\n",
              "  'himself',\n",
              "  'from',\n",
              "  'a',\n",
              "  'tress',\n",
              "  'branch',\n",
              "  'and',\n",
              "  'on',\n",
              "  'to',\n",
              "  'the',\n",
              "  'deck',\n",
              "  'of',\n",
              "  'the',\n",
              "  'ship',\n",
              "  'where',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'were',\n",
              "  'tied',\n",
              "  'up',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'swung',\n",
              "  'his',\n",
              "  'sword',\n",
              "  'bravely',\n",
              "  'and',\n",
              "  'threw',\n",
              "  'over',\n",
              "  'the',\n",
              "  'pirates',\n",
              "  'who',\n",
              "  'tried',\n",
              "  'to',\n",
              "  'stop',\n",
              "  'him',\n",
              "  '.'],\n",
              " ['quickly',\n",
              "  'he',\n",
              "  'released',\n",
              "  'everyone',\n",
              "  'from',\n",
              "  'their',\n",
              "  'captor',\n",
              "  '’',\n",
              "  's',\n",
              "  'ties',\n",
              "  '.'],\n",
              " ['wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  ',',\n",
              "  'michael',\n",
              "  'and',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'helped',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water',\n",
              "  ',',\n",
              "  'where',\n",
              "  'their',\n",
              "  'friends',\n",
              "  'from',\n",
              "  'the',\n",
              "  'indian',\n",
              "  'camp',\n",
              "  'were',\n",
              "  'ready',\n",
              "  'with',\n",
              "  'smaller',\n",
              "  'boats',\n",
              "  'to',\n",
              "  'take',\n",
              "  'them',\n",
              "  'to',\n",
              "  'safety',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'now',\n",
              "  'went',\n",
              "  'looking',\n",
              "  'for',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  '.'],\n",
              " ['“',\n",
              "  'let',\n",
              "  'us',\n",
              "  'finished',\n",
              "  'this',\n",
              "  'forever',\n",
              "  'mr.',\n",
              "  'hook',\n",
              "  '”',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'challenged',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  '.'],\n",
              " ['“', 'yes', '!'],\n",
              " ['peter',\n",
              "  'pan',\n",
              "  ',',\n",
              "  'you',\n",
              "  'have',\n",
              "  'caused',\n",
              "  'me',\n",
              "  'enough',\n",
              "  'trouble',\n",
              "  '.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'time',\n",
              "  'that',\n",
              "  'we',\n",
              "  'finished',\n",
              "  'this.',\n",
              "  '”',\n",
              "  'hook',\n",
              "  'replied',\n",
              "  '.'],\n",
              " ['with',\n",
              "  'his',\n",
              "  'sword',\n",
              "  'drawn',\n",
              "  ',',\n",
              "  'he',\n",
              "  'raced',\n",
              "  'towards',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  '.'],\n",
              " ['quick',\n",
              "  'on',\n",
              "  'his',\n",
              "  'feet',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'stepped',\n",
              "  'aside',\n",
              "  'and',\n",
              "  'pushed',\n",
              "  'hook',\n",
              "  'inside',\n",
              "  'the',\n",
              "  'sea',\n",
              "  'where',\n",
              "  'the',\n",
              "  'crocodile',\n",
              "  'was',\n",
              "  'waiting',\n",
              "  'to',\n",
              "  'eat',\n",
              "  'the',\n",
              "  'rest',\n",
              "  'of',\n",
              "  'hook',\n",
              "  '.'],\n",
              " ['everyone',\n",
              "  'rejoiced',\n",
              "  'as',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'was',\n",
              "  'out',\n",
              "  'of',\n",
              "  'their',\n",
              "  'lives',\n",
              "  'forever',\n",
              "  '.'],\n",
              " ['everybody', 'headed', 'back', 'to', 'london', '.'],\n",
              " ['mr.', 'and', 'mrs', '.'],\n",
              " ['darling',\n",
              "  'was',\n",
              "  'so',\n",
              "  'happy',\n",
              "  'to',\n",
              "  'see',\n",
              "  'their',\n",
              "  'children',\n",
              "  'and',\n",
              "  'they',\n",
              "  'agreed',\n",
              "  'to',\n",
              "  'adopt',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  '.'],\n",
              " ['they',\n",
              "  'even',\n",
              "  'asked',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'to',\n",
              "  'come',\n",
              "  'and',\n",
              "  'live',\n",
              "  'with',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['but',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'said',\n",
              "  ',',\n",
              "  'he',\n",
              "  'never',\n",
              "  'wanted',\n",
              "  'to',\n",
              "  'grow',\n",
              "  'up',\n",
              "  ',',\n",
              "  'so',\n",
              "  'he',\n",
              "  'and',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'will',\n",
              "  'go',\n",
              "  'back',\n",
              "  'to',\n",
              "  'neverland',\n",
              "  '.'],\n",
              " ['peter',\n",
              "  'pan',\n",
              "  'promised',\n",
              "  'everyone',\n",
              "  'that',\n",
              "  'he',\n",
              "  'will',\n",
              "  'visit',\n",
              "  'again',\n",
              "  'sometime',\n",
              "  '!'],\n",
              " ['and',\n",
              "  'he',\n",
              "  'flew',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'window',\n",
              "  'with',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'by',\n",
              "  'his',\n",
              "  'side',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings(action = 'ignore')\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sample = open(\"peter.txt\", \"r\", encoding='UTF8')\n",
        "s = sample.read()\n",
        "\n",
        "f = s.replace(\"\\n\", \" \")\n",
        "data = []\n",
        "\n",
        "for i in sent_tokenize(f):\n",
        "    temp = []\n",
        "    for j in word_tokenize(i):\n",
        "        temp.append(j.lower())\n",
        "    data.append(temp)\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CBOW"
      ],
      "metadata": {
        "id": "RuPMq-ywz9MU"
      },
      "id": "RuPMq-ywz9MU"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "bcbd3aed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bcbd3aed",
        "outputId": "021e4ab4-ada0-4a6e-f1f3-5c549f088d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'peter' wendy' - CBOW :  -0.08923974\n"
          ]
        }
      ],
      "source": [
        "model1 = gensim.models.Word2Vec(data, min_count= 1,\n",
        "                              vector_size= 100, window = 5, sg=0)    # 코랩에서는 vector_size를 사용하면 오류가 발생합니다. vector_size를 vector로 바꿔야 합니다.\n",
        "print(\"Cosine similarity between 'peter' \" +\n",
        "                 \"wendy' - CBOW : \",\n",
        "      model1.wv.similarity('peter', 'wendy'))\n",
        "\n",
        "model1 = gensim.models.Word2Vec(data, min_count = 1,\n",
        "                              vector_size = 100, window = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "9f6eac9a",
      "metadata": {
        "id": "9f6eac9a",
        "outputId": "dbb2b6d5-c7a3-4ea6-c3b1-a91210e162fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'peter' hook' - CBOW :  0.030469554\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'peter' \" +\n",
        "                 \"hook' - CBOW : \",\n",
        "      model1.wv.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skip-gram"
      ],
      "metadata": {
        "id": "03b_bcD70AXI"
      },
      "id": "03b_bcD70AXI"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4fb8edd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fb8edd9",
        "outputId": "1ae2155d-c819-4a44-c58f-036537a45a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'peter' wendy' - Skip Gram :  0.28732824\n"
          ]
        }
      ],
      "source": [
        "model2 = gensim.models.Word2Vec(data, min_count = 1, vector_size = 100,\n",
        "                                             window = 5, sg = 1)\n",
        "print(\"Cosine similarity between 'peter' \" +\n",
        "          \"wendy' - Skip Gram : \",\n",
        "    model2.wv.similarity('peter', 'wendy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8128bcb6",
      "metadata": {
        "id": "8128bcb6",
        "outputId": "990ad6ca-cb0d-4307-8a8a-c86694e741ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'peter' hook' - Skip Gram :  0.5432895\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'peter' \" +\n",
        "            \"hook' - Skip Gram : \",\n",
        "      model2.wv.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FastText"
      ],
      "metadata": {
        "id": "EAviWnUW0DqY"
      },
      "id": "EAviWnUW0DqY"
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.fasttext import FastText as ft_gensim\n",
        "stemmed = ['database', 'science', 'scientist', 'mgmt', 'microsoft', 'hire', 'develop', 'mentor', 'team', 'data', 'scientist', 'define', 'dataloader', 'scienc', 'priority', 'deep', 'understand', 'learn', 'goal', 'collabor', 'across', 'triple', 'group', 'set', 'team', 'shortterm', 'longterm', 'goal', 'act', 'strait', 'advisor', 'leadership', 'influenc', 'future', 'direct', 'strategy', 'define', 'partnership', 'align', 'effect', 'broad', 'analyt', 'effort', 'analyticsdata', 'team', 'drive', 'part', 'datadog', 'scienc', 'bi', 'common', 'disciplin', 'microsoftprior', 'experi', 'hire', 'manage', 'runner', 'team', 'data', 'scientist', 'busi', 'domain', 'experi', 'usage', 'analyt', 'must', 'experi', 'across', 'sever', 'relev', 'busi', 'domain', 'util', 'critic', 'think', 'skill', 'concept', 'complex', 'busi', 'problem', 'salt', 'use', 'advanc', 'analsis', 'large', 'scale', 'realworld', 'busi', 'data', 'set', 'candid', 'must', 'abl', 'independ', 'execut', 'analyt', 'project', 'help', 'intern', 'client', 'understand']\n",
        "# def gen_words(stemmed):\n",
        "#     yield stemmed\n",
        "\n",
        "model = ft_gensim(vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
        "model.build_vocab(corpus_iterable=[stemmed])\n",
        "\n",
        "model.train(corpus_iterable=[stemmed], total_examples=len(stemmed), epochs=model.epochs)\n",
        "#model.wv.similarity('data', 'scientist')\n",
        "model.wv.most_similar(positive=['scientist'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV__Oeo6JskG",
        "outputId": "937c681a-36a3-456d-d9af-c8362ff76fd7"
      },
      "id": "lV__Oeo6JskG",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied example count (1) did not equal expected count (101)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied example count (1) did not equal expected count (101)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied example count (1) did not equal expected count (101)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied example count (1) did not equal expected count (101)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied example count (1) did not equal expected count (101)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('scienc', 0.3435826301574707),\n",
              " ('science', 0.2755683660507202),\n",
              " ('part', 0.24521857500076294),\n",
              " ('think', 0.2191305011510849),\n",
              " ('analsis', 0.18588010966777802),\n",
              " ('client', 0.16053123772144318),\n",
              " ('util', 0.15150433778762817),\n",
              " ('intern', 0.14316578209400177),\n",
              " ('domain', 0.14149148762226105),\n",
              " ('future', 0.13051177561283112)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://fasttext.cc/docs/en/pretrained-vectors.html에서 wiki.ko.vec 파일을 따로 내려받으세요.\n",
        "# 내려받은 파일을 불러와 실습합니다.\n",
        "# 파일 크기가 약 2G 이상이므로 PC에서 파일을 불러오는 시간이 오래 걸리기 때문에 구글 드라이브에 파일을 넣어둔 후 불러오겠습니다.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5pDEf67DOCU",
        "outputId": "67ebc28e-960c-4882-9abd-d62e9313a18b"
      },
      "id": "l5pDEf67DOCU",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "4543f02c",
      "metadata": {
        "id": "4543f02c"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model_kr = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Colab Notebooks/wiki.ko.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "b5fb5c1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5fb5c1b",
        "outputId": "0827eb3b-9cae-4f15-8c67-5f56eca78b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: 노력함, Similarity: 0.80\n",
            "Word: 노력중, Similarity: 0.75\n",
            "Word: 노력만, Similarity: 0.72\n",
            "Word: 노력과, Similarity: 0.71\n",
            "Word: 노력의, Similarity: 0.69\n",
            "Word: 노력가, Similarity: 0.69\n",
            "Word: 노력이나, Similarity: 0.69\n",
            "Word: 노력없이, Similarity: 0.68\n",
            "Word: 노력맨, Similarity: 0.68\n",
            "Word: 노력보다는, Similarity: 0.68\n"
          ]
        }
      ],
      "source": [
        "find_similar_to = '노력'\n",
        "\n",
        "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
        "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
        "        similar_word[0], similar_word[1]\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "346acbc3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "346acbc3",
        "outputId": "1a712aaa-d146-49e3-aca8-c776f7bd46e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('초식동물', 0.7804122567176819), ('거대동물', 0.7547270655632019), ('육식동물의', 0.7547166347503662), ('유두동물', 0.753511369228363), ('반추동물', 0.7470757961273193), ('독동물', 0.7466291785240173), ('육상동물', 0.746031641960144), ('유즐동물', 0.7450903654098511), ('극피동물', 0.7449344396591187), ('복모동물', 0.742434561252594)]\n"
          ]
        }
      ],
      "source": [
        "similarities = model_kr.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
        "print(similarities)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.1.4 횟수/예측기반 임베딩"
      ],
      "metadata": {
        "id": "agwsQwoi0PgJ"
      },
      "id": "agwsQwoi0PgJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe"
      ],
      "metadata": {
        "id": "1zo51uYr0TNo"
      },
      "id": "1zo51uYr0TNo"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "c5752236",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5752236",
        "outputId": "9539360f-923a-43d5-95d2-64d55e2c7910"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# PC에서 파일 불러오는 시간이 오래 걸리기 때문에 구글 드라이브에서 불러옵니다.\n",
        "\n",
        "import numpy as np\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_file = datapath('/content/drive/MyDrive/Colab Notebooks/glove.6B.100d.txt')\n",
        "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3db496ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3db496ab",
        "outputId": "a2ce5b1d-24e3-4978-b7ba-87a9bdf9e76d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('legislation', 0.8072139620780945),\n",
              " ('proposal', 0.730686366558075),\n",
              " ('senate', 0.7142541408538818),\n",
              " ('bills', 0.704440176486969),\n",
              " ('measure', 0.6958035230636597),\n",
              " ('passed', 0.690624475479126),\n",
              " ('amendment', 0.6846879720687866),\n",
              " ('provision', 0.6845567226409912),\n",
              " ('plan', 0.6816462874412537),\n",
              " ('clinton', 0.6663140058517456)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
        "model.most_similar('bill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "57d14331",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57d14331",
        "outputId": "cae953d6-cda0-4d07-cb4a-cc4df9140285"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('peach', 0.688809871673584),\n",
              " ('mango', 0.683819055557251),\n",
              " ('plum', 0.6684104204177856),\n",
              " ('berry', 0.6590359210968018),\n",
              " ('grove', 0.658155083656311),\n",
              " ('blossom', 0.6503506302833557),\n",
              " ('raspberry', 0.6477391719818115),\n",
              " ('strawberry', 0.6442098021507263),\n",
              " ('pine', 0.6390928626060486),\n",
              " ('almond', 0.6379212737083435)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "model.most_similar('cherry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c609124b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c609124b",
        "outputId": "2bd8c7cf-7f3d-467d-a7a6-76ea05774cce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kazushige', 0.48343509435653687),\n",
              " ('askerov', 0.4778185784816742),\n",
              " ('lakpa', 0.46915265917778015),\n",
              " ('ex-gay', 0.4571332633495331),\n",
              " ('tadayoshi', 0.4522107243537903),\n",
              " ('turani', 0.44810065627098083),\n",
              " ('saglam', 0.4469599425792694),\n",
              " ('aijun', 0.4435270130634308),\n",
              " ('adjustors', 0.44235292077064514),\n",
              " ('nyum', 0.4423118233680725)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model.most_similar(negative='cherry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "21c9f828",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21c9f828",
        "outputId": "57f3da91-ecc6-4be7-e26e-f7020a7c4d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen: 0.7699\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"{}: {:.4f}\".format(*result[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "72881522",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "72881522",
        "outputId": "3033076a-ae59-43d7-e099-c9e2989499ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'champagne'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "def analogy(x1, x2, y1):\n",
        "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
        "    return result[0][0]\n",
        "analogy('australia', 'beer', 'france')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "9a8a76cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9a8a76cf",
        "outputId": "834f414e-8ae0-460c-8f22-551f85dbd242"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'longest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "analogy('tall', 'tallest', 'long')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "820bf3a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "820bf3a4",
        "outputId": "2ec57aa5-f223-440f-eaf9-d605cf189a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cereal\n"
          ]
        }
      ],
      "source": [
        "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.2.1 Seq2seq"
      ],
      "metadata": {
        "id": "8q-r2dal0Z9X"
      },
      "id": "8q-r2dal0Z9X"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "6ae5b052",
      "metadata": {
        "id": "6ae5b052"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "c4841b42",
      "metadata": {
        "id": "c4841b42"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "58ebe3bd",
      "metadata": {
        "id": "58ebe3bd"
      },
      "outputs": [],
      "source": [
        "def normalizeString(df, lang):\n",
        "    sentence = df[lang].str.lower()\n",
        "    sentence = sentence.str.replace('[^A-Za-z\\s]+', '')\n",
        "    sentence = sentence.str.normalize('NFD')\n",
        "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "    return sentence\n",
        "\n",
        "def read_sentence(df, lang1, lang2):\n",
        "    sentence1 = normalizeString(df, lang1)\n",
        "    sentence2 = normalizeString(df, lang2)\n",
        "    return sentence1, sentence2\n",
        "\n",
        "def read_file(loc, lang1, lang2):\n",
        "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2])\n",
        "    return df\n",
        "\n",
        "def process_data(lang1,lang2):\n",
        "    df = read_file('/content/drive/MyDrive/Colab Notebooks/eng-fra.txt', lang1, lang2)\n",
        "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
        "\n",
        "    input_lang = Lang()\n",
        "    output_lang = Lang()\n",
        "    pairs = []\n",
        "    for i in range(len(df)):\n",
        "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
        "            full = [sentence1[i], sentence2[i]]\n",
        "            input_lang.addSentence(sentence1[i])\n",
        "            output_lang.addSentence(sentence2[i])\n",
        "            pairs.append(full)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "f0c3e7a2",
      "metadata": {
        "id": "f0c3e7a2"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(input_lang, output_lang, pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "e5cda608",
      "metadata": {
        "id": "e5cda608"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_dim, self.embbed_dim)\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src).view(1,1,-1)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "8c8c263c",
      "metadata": {
        "id": "8c8c263c"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, self.embbed_dim)\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.view(1, -1)\n",
        "        embedded = F.relu(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        prediction = self.softmax(self.out(output[0]))\n",
        "        return prediction, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "2e32442e",
      "metadata": {
        "id": "2e32442e"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        input_length = input_lang.size(0)\n",
        "        batch_size = output_lang.shape[1]\n",
        "        target_length = output_lang.shape[0]\n",
        "        vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
        "\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = self.encoder(input_lang[i])\n",
        "\n",
        "        decoder_hidden = encoder_hidden.to(device)\n",
        "        decoder_input = torch.tensor([SOS_token], device=device)\n",
        "\n",
        "        for t in range(target_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            outputs[t] = decoder_output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            input = (output_lang[t] if teacher_force else topi)\n",
        "            if(teacher_force == False and input.item() == EOS_token):\n",
        "                break\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "93d4ebc3",
      "metadata": {
        "id": "93d4ebc3"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def Model(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
        "    model_optimizer.zero_grad()\n",
        "    input_length = input_tensor.size(0)\n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    output = model(input_tensor, target_tensor)\n",
        "    num_iter = output.size(0)\n",
        "\n",
        "    for ot in range(num_iter):\n",
        "        loss += criterion(output[ot], target_tensor[ot])\n",
        "\n",
        "    loss.backward()\n",
        "    model_optimizer.step()\n",
        "    epoch_loss = loss.item() / num_iter\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "9768b4e8",
      "metadata": {
        "id": "9768b4e8"
      },
      "outputs": [],
      "source": [
        "def trainModel(model, input_lang, output_lang, pairs, num_iteration=20000):\n",
        "    model.train()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.NLLLoss()\n",
        "    total_loss_iterations = 0\n",
        "\n",
        "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
        "                      for i in range(num_iteration)]\n",
        "\n",
        "    for iter in range(1, num_iteration+1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = Model(model, input_tensor, target_tensor, optimizer, criterion)\n",
        "        total_loss_iterations += loss\n",
        "\n",
        "        if iter % 5000 == 0:\n",
        "            avarage_loss= total_loss_iterations / 5000\n",
        "            total_loss_iterations = 0\n",
        "            print('%d %.4f' % (iter, avarage_loss))\n",
        "\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/Colab Notebooks/mytraining.pt')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "9bd2079f",
      "metadata": {
        "id": "9bd2079f"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
        "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
        "        decoded_words = []\n",
        "        output = model(input_tensor, output_tensor)\n",
        "\n",
        "        for ot in range(output.size(0)):\n",
        "            topv, topi = output[ot].topk(1)\n",
        "\n",
        "            if topi[0].item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
        "    return decoded_words\n",
        "\n",
        "def evaluateRandomly(model, input_lang, output_lang, pairs, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('input {}'.format(pair[0]))\n",
        "        print('output {}'.format(pair[1]))\n",
        "        output_words = evaluate(model, input_lang, output_lang, pair)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('predicted {}'.format(output_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "b6814115",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6814115",
        "outputId": "2cc37b0b-e0a0-4a55-e865-d30d378549d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random sentence ['he became a famous singer.', 'il devint un chanteur celebre.']\n",
            "Input : 23191 Output : 39387\n",
            "Encoder(\n",
            "  (embedding): Embedding(23191, 256)\n",
            "  (gru): GRU(256, 512)\n",
            ")\n",
            "Decoder(\n",
            "  (embedding): Embedding(39387, 256)\n",
            "  (gru): GRU(256, 512)\n",
            "  (out): Linear(in_features=512, out_features=39387, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n",
            "5000 5.0593\n",
            "10000 4.7944\n",
            "15000 4.7196\n",
            "20000 4.6567\n",
            "25000 4.6604\n",
            "30000 4.6112\n",
            "35000 4.6360\n",
            "40000 4.5883\n",
            "45000 4.6352\n",
            "50000 4.6415\n",
            "55000 4.6002\n",
            "60000 4.6050\n",
            "65000 4.5591\n",
            "70000 4.5599\n",
            "75000 4.6372\n"
          ]
        }
      ],
      "source": [
        "lang1 = 'eng'\n",
        "lang2 = 'fra'\n",
        "input_lang, output_lang, pairs = process_data(lang1, lang2)\n",
        "\n",
        "randomize = random.choice(pairs)\n",
        "print('random sentence {}'.format(randomize))\n",
        "\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "print('Input : {} Output : {}'.format(input_size, output_size))\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_iteration = 75000\n",
        "\n",
        "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "print(encoder)\n",
        "print(decoder)\n",
        "\n",
        "model = trainModel(model, input_lang, output_lang, pairs, num_iteration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "fa2807a7",
      "metadata": {
        "id": "fa2807a7",
        "outputId": "41d92191-0e10-47fb-e029-a09597638ad1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tom learned how to do that from his grandfather.\n",
            "output tom a appris a faire ca avec son grand-pere.\n",
            "predicted je ne pas <EOS>\n",
            "input i ran into a friend of mine on the bus.\n",
            "output je suis tombe sur une amie a moi dans le bus.\n",
            "predicted je ne pas <EOS>\n",
            "input i'll be there in a minute.\n",
            "output j'arrive immediatement.\n",
            "predicted je ne pas\n",
            "input everybody was startled.\n",
            "output tout le monde a ete arrete.\n",
            "predicted je ne pas <EOS>\n",
            "input i hope to marry her.\n",
            "output j'espere l'epouser.\n",
            "predicted je ne pas\n",
            "input i hope to return soon.\n",
            "output j'espere revenir bientot.\n",
            "predicted je ne pas <EOS>\n",
            "input his identity must be kept secret.\n",
            "output son identite doit etre gardee secrete.\n",
            "predicted je ne pas <EOS>\n",
            "input take things as they are.\n",
            "output prends les choses comme elles viennent.\n",
            "predicted je ne pas <EOS>\n",
            "input you should've rejected such an unfair proposal.\n",
            "output tu aurais du refuser une proposition aussi injuste.\n",
            "predicted je ne pas <EOS>\n",
            "input i know what you mean.\n",
            "output je sais ce que vous voulez dire.\n",
            "predicted je ne pas <EOS>\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(model, input_lang, output_lang, pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "6032888a",
      "metadata": {
        "id": "6032888a"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "9bb7ef62",
      "metadata": {
        "id": "9bb7ef62"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = Model(model, input_tensor, target_tensor, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % 5000 == 0:\n",
        "            print_loss_avg = print_loss_total / 5000\n",
        "            print_loss_total = 0\n",
        "            print('%d,  %.4f' % (iter, print_loss_avg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "6df879d6",
      "metadata": {
        "id": "6df879d6",
        "outputId": "232319cd-1320-4c3f-b95d-8814c08c4750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(23191, 256)\n",
            "  (gru): GRU(256, 512)\n",
            ")\n",
            "AttnDecoderRNN(\n",
            "  (embedding): Embedding(39387, 512)\n",
            "  (attn): Linear(in_features=1024, out_features=20, bias=True)\n",
            "  (attn_combine): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (gru): GRU(512, 512)\n",
            "  (out): Linear(in_features=512, out_features=39387, bias=True)\n",
            ")\n",
            "5000,  4.3109\n",
            "10000,  4.2910\n",
            "15000,  4.2680\n",
            "20000,  4.2729\n",
            "25000,  4.3139\n",
            "30000,  4.2536\n",
            "35000,  4.2953\n",
            "40000,  4.2946\n",
            "45000,  4.2838\n",
            "50000,  4.3332\n",
            "55000,  4.3117\n",
            "60000,  4.2628\n",
            "65000,  4.2824\n",
            "70000,  4.3083\n",
            "75000,  4.2725\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "\n",
        "encoder1 = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_size, dropout_p=0.1).to(device)\n",
        "\n",
        "print(encoder1)\n",
        "print(attn_decoder1)\n",
        "\n",
        "attn_model = trainIters(encoder1, attn_decoder1, 75000, print_every=5000, plot_every=100, learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.2.1 Bert"
      ],
      "metadata": {
        "id": "q3E0x1la0oYR"
      },
      "id": "q3E0x1la0oYR"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GalDYeCfJLJF",
        "outputId": "06534951-0d47-435d-b308-204148c49c99"
      },
      "id": "GalDYeCfJLJF",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIsA0wggJZHI",
        "outputId": "3b30923e-844f-4277-e6ba-c22a7ec335c2"
      },
      "id": "DIsA0wggJZHI",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (1.26.4)\n",
            "Collecting boto3 (from pytorch-transformers)\n",
            "  Downloading boto3-1.35.90-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2024.11.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (0.2.0)\n",
            "Collecting sacremoses (from pytorch-transformers)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->pytorch-transformers) (1.3.0)\n",
            "Collecting botocore<1.36.0,>=1.35.90 (from boto3->pytorch-transformers)\n",
            "  Downloading botocore-1.35.90-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-transformers)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->pytorch-transformers)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2024.12.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.90->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.90->boto3->pytorch-transformers) (1.17.0)\n",
            "Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.90-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.90-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "Successfully installed boto3-1.35.90 botocore-1.35.90 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.10.4 sacremoses-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "20b91e5b",
      "metadata": {
        "id": "20b91e5b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "0fa39b29",
      "metadata": {
        "id": "0fa39b29"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/training.txt', sep='\\t') #구글 드라이브에서 파일 경로 복사 후 붙여넣으세요.\n",
        "valid_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/validing.txt', sep='\\t') #구글 드라이브에서 파일 경로 복사 후 붙여넣으세요.\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/testing.txt', sep='\\t') #구글 드라이브에서 파일 경로 복사 후 붙여넣으세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "e620c35f",
      "metadata": {
        "id": "e620c35f"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sample(frac=0.1, random_state=500)\n",
        "valid_df = valid_df.sample(frac=0.1, random_state=500)\n",
        "test_df = test_df.sample(frac=0.1, random_state=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "8506022e",
      "metadata": {
        "id": "8506022e"
      },
      "outputs": [],
      "source": [
        "class Datasets(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx, 1]\n",
        "        label = self.df.iloc[idx, 2]\n",
        "        return text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "97277c2b",
      "metadata": {
        "id": "97277c2b"
      },
      "outputs": [],
      "source": [
        "train_dataset = Datasets(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "valid_dataset = Datasets(valid_df)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "test_dataset = Datasets(test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "106307e9",
      "metadata": {
        "id": "106307e9",
        "outputId": "c1901df1-bb60-4898-a4ed-399ee698b577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 1280748.61B/s]\n",
            "100%|██████████| 433/433 [00:00<00:00, 1389543.71B/s]\n",
            "100%|██████████| 440473133/440473133 [00:16<00:00, 27170939.52B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "7c0f5fef",
      "metadata": {
        "id": "7c0f5fef"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):\n",
        "    if load_path==None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_metrics(load_path):\n",
        "    if load_path==None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "0871e661",
      "metadata": {
        "id": "0871e661"
      },
      "outputs": [],
      "source": [
        "def train(model,\n",
        "          optimizer,\n",
        "          criterion = nn.BCELoss(),\n",
        "          num_epochs = 5,\n",
        "          eval_every = len(train_loader) // 2,\n",
        "          best_valid_loss = float(\"Inf\")):\n",
        "\n",
        "    total_correct = 0.0\n",
        "    total_len = 0.0\n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for text, label in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "\n",
        "            sample = torch.tensor(padded_list)\n",
        "            sample, label = sample.to(device), label.to(device)\n",
        "            labels = torch.tensor(label)\n",
        "            outputs = model(sample, labels=labels)\n",
        "            loss, logits = outputs\n",
        "\n",
        "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "            correct = pred.eq(labels)\n",
        "            total_correct += correct.sum().item()\n",
        "            total_len += len(labels)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_every == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    for text, label in valid_loader:\n",
        "                        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "                        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "                        sample = torch.tensor(padded_list)\n",
        "                        sample, label = sample.to(device), label.to(device)\n",
        "                        labels = torch.tensor(label)\n",
        "                        outputs = model(sample, labels=labels)\n",
        "                        loss, logits = outputs\n",
        "                        valid_running_loss += loss.item()\n",
        "\n",
        "                average_train_loss = running_loss / eval_every\n",
        "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                running_loss = 0.0\n",
        "                valid_running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
        "                              average_train_loss, average_valid_loss))\n",
        "\n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint('/content/drive/MyDrive/Colab Notebooks/model.pt', model, best_valid_loss)\n",
        "                    save_metrics('/content/drive/MyDrive/Colab Notebooks/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "\n",
        "    save_metrics('/content/drive/MyDrive/Colab Notebooks/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    print('훈련 종료!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "7f69dac7",
      "metadata": {
        "id": "7f69dac7",
        "outputId": "1ebe9d24-46b4-416c-abb9-a487d27f784f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [510/5100], Train Loss: 0.7147, Valid Loss: 0.6996\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/model.pt\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/metrics.pt\n",
            "Epoch [1/5], Step [1020/5100], Train Loss: 0.7047, Valid Loss: 0.7008\n",
            "Epoch [2/5], Step [1530/5100], Train Loss: 0.7063, Valid Loss: 0.6927\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/model.pt\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/metrics.pt\n",
            "Epoch [2/5], Step [2040/5100], Train Loss: 0.7035, Valid Loss: 0.6945\n",
            "Epoch [3/5], Step [2550/5100], Train Loss: 0.7046, Valid Loss: 0.7571\n",
            "Epoch [3/5], Step [3060/5100], Train Loss: 0.7056, Valid Loss: 0.6968\n",
            "Epoch [4/5], Step [3570/5100], Train Loss: 0.7005, Valid Loss: 0.6934\n",
            "Epoch [4/5], Step [4080/5100], Train Loss: 0.7030, Valid Loss: 0.7136\n",
            "Epoch [5/5], Step [4590/5100], Train Loss: 0.7005, Valid Loss: 0.6939\n",
            "Epoch [5/5], Step [5100/5100], Train Loss: 0.7021, Valid Loss: 0.6957\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Notebooks/metrics.pt\n",
            "훈련 종료!\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "train(model=model, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "2abbb6cb",
      "metadata": {
        "id": "2abbb6cb",
        "outputId": "b9b986ec-635c-4d67-ab16-fb170d1f2c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== /content/drive/MyDrive/Colab Notebooks/metrics.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "/* global mpl */\n",
              "window.mpl = {};\n",
              "\n",
              "mpl.get_websocket_type = function () {\n",
              "    if (typeof WebSocket !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof MozWebSocket !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert(\n",
              "            'Your browser does not have WebSocket support. ' +\n",
              "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "                'Firefox 4 and 5 are also supported but you ' +\n",
              "                'have to enable WebSockets in about:config.'\n",
              "        );\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = this.ws.binaryType !== undefined;\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById('mpl-warnings');\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent =\n",
              "                'This browser does not support binary websocket messages. ' +\n",
              "                'Performance may be slow.';\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = document.createElement('div');\n",
              "    this.root.setAttribute('style', 'display: inline-block');\n",
              "    this._root_extra_style(this.root);\n",
              "\n",
              "    parent_element.appendChild(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen = function () {\n",
              "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
              "        fig.send_message('send_image_mode', {});\n",
              "        if (fig.ratio !== 1) {\n",
              "            fig.send_message('set_device_pixel_ratio', {\n",
              "                device_pixel_ratio: fig.ratio,\n",
              "            });\n",
              "        }\n",
              "        fig.send_message('refresh', {});\n",
              "    };\n",
              "\n",
              "    this.imageObj.onload = function () {\n",
              "        if (fig.image_mode === 'full') {\n",
              "            // Full images could contain transparency (where diff images\n",
              "            // almost always do), so we need to clear the canvas so that\n",
              "            // there is no ghosting.\n",
              "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "        }\n",
              "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "    };\n",
              "\n",
              "    this.imageObj.onunload = function () {\n",
              "        fig.ws.close();\n",
              "    };\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._init_header = function () {\n",
              "    var titlebar = document.createElement('div');\n",
              "    titlebar.classList =\n",
              "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
              "    var titletext = document.createElement('div');\n",
              "    titletext.classList = 'ui-dialog-title';\n",
              "    titletext.setAttribute(\n",
              "        'style',\n",
              "        'width: 100%; text-align: center; padding: 3px;'\n",
              "    );\n",
              "    titlebar.appendChild(titletext);\n",
              "    this.root.appendChild(titlebar);\n",
              "    this.header = titletext;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function () {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
              "    canvas_div.setAttribute('tabindex', '0');\n",
              "    canvas_div.setAttribute(\n",
              "        'style',\n",
              "        'border: 1px solid #ddd;' +\n",
              "            'box-sizing: content-box;' +\n",
              "            'clear: both;' +\n",
              "            'min-height: 1px;' +\n",
              "            'min-width: 1px;' +\n",
              "            'outline: 0;' +\n",
              "            'overflow: hidden;' +\n",
              "            'position: relative;' +\n",
              "            'resize: both;' +\n",
              "            'z-index: 2;'\n",
              "    );\n",
              "\n",
              "    function on_keyboard_event_closure(name) {\n",
              "        return function (event) {\n",
              "            return fig.key_event(event, name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    canvas_div.addEventListener(\n",
              "        'keydown',\n",
              "        on_keyboard_event_closure('key_press')\n",
              "    );\n",
              "    canvas_div.addEventListener(\n",
              "        'keyup',\n",
              "        on_keyboard_event_closure('key_release')\n",
              "    );\n",
              "\n",
              "    this._canvas_extra_style(canvas_div);\n",
              "    this.root.appendChild(canvas_div);\n",
              "\n",
              "    var canvas = (this.canvas = document.createElement('canvas'));\n",
              "    canvas.classList.add('mpl-canvas');\n",
              "    canvas.setAttribute(\n",
              "        'style',\n",
              "        'box-sizing: content-box;' +\n",
              "            'pointer-events: none;' +\n",
              "            'position: relative;' +\n",
              "            'z-index: 0;'\n",
              "    );\n",
              "\n",
              "    this.context = canvas.getContext('2d');\n",
              "\n",
              "    var backingStore =\n",
              "        this.context.backingStorePixelRatio ||\n",
              "        this.context.webkitBackingStorePixelRatio ||\n",
              "        this.context.mozBackingStorePixelRatio ||\n",
              "        this.context.msBackingStorePixelRatio ||\n",
              "        this.context.oBackingStorePixelRatio ||\n",
              "        this.context.backingStorePixelRatio ||\n",
              "        1;\n",
              "\n",
              "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
              "        'canvas'\n",
              "    ));\n",
              "    rubberband_canvas.setAttribute(\n",
              "        'style',\n",
              "        'box-sizing: content-box;' +\n",
              "            'left: 0;' +\n",
              "            'pointer-events: none;' +\n",
              "            'position: absolute;' +\n",
              "            'top: 0;' +\n",
              "            'z-index: 1;'\n",
              "    );\n",
              "\n",
              "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
              "    if (this.ResizeObserver === undefined) {\n",
              "        if (window.ResizeObserver !== undefined) {\n",
              "            this.ResizeObserver = window.ResizeObserver;\n",
              "        } else {\n",
              "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
              "            this.ResizeObserver = obs.ResizeObserver;\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
              "        var nentries = entries.length;\n",
              "        for (var i = 0; i < nentries; i++) {\n",
              "            var entry = entries[i];\n",
              "            var width, height;\n",
              "            if (entry.contentBoxSize) {\n",
              "                if (entry.contentBoxSize instanceof Array) {\n",
              "                    // Chrome 84 implements new version of spec.\n",
              "                    width = entry.contentBoxSize[0].inlineSize;\n",
              "                    height = entry.contentBoxSize[0].blockSize;\n",
              "                } else {\n",
              "                    // Firefox implements old version of spec.\n",
              "                    width = entry.contentBoxSize.inlineSize;\n",
              "                    height = entry.contentBoxSize.blockSize;\n",
              "                }\n",
              "            } else {\n",
              "                // Chrome <84 implements even older version of spec.\n",
              "                width = entry.contentRect.width;\n",
              "                height = entry.contentRect.height;\n",
              "            }\n",
              "\n",
              "            // Keep the size of the canvas and rubber band canvas in sync with\n",
              "            // the canvas container.\n",
              "            if (entry.devicePixelContentBoxSize) {\n",
              "                // Chrome 84 implements new version of spec.\n",
              "                canvas.setAttribute(\n",
              "                    'width',\n",
              "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
              "                );\n",
              "                canvas.setAttribute(\n",
              "                    'height',\n",
              "                    entry.devicePixelContentBoxSize[0].blockSize\n",
              "                );\n",
              "            } else {\n",
              "                canvas.setAttribute('width', width * fig.ratio);\n",
              "                canvas.setAttribute('height', height * fig.ratio);\n",
              "            }\n",
              "            /* This rescales the canvas back to display pixels, so that it\n",
              "             * appears correct on HiDPI screens. */\n",
              "            canvas.style.width = width + 'px';\n",
              "            canvas.style.height = height + 'px';\n",
              "\n",
              "            rubberband_canvas.setAttribute('width', width);\n",
              "            rubberband_canvas.setAttribute('height', height);\n",
              "\n",
              "            // And update the size in Python. We ignore the initial 0/0 size\n",
              "            // that occurs as the element is placed into the DOM, which should\n",
              "            // otherwise not happen due to the minimum size styling.\n",
              "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
              "                fig.request_resize(width, height);\n",
              "            }\n",
              "        }\n",
              "    });\n",
              "    this.resizeObserverInstance.observe(canvas_div);\n",
              "\n",
              "    function on_mouse_event_closure(name) {\n",
              "        /* User Agent sniffing is bad, but WebKit is busted:\n",
              "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
              "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
              "         * The worst that happens here is that they get an extra browser\n",
              "         * selection when dragging, if this check fails to catch them.\n",
              "         */\n",
              "        var UA = navigator.userAgent;\n",
              "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
              "        if(isWebKit) {\n",
              "            return function (event) {\n",
              "                /* This prevents the web browser from automatically changing to\n",
              "                 * the text insertion cursor when the button is pressed. We\n",
              "                 * want to control all of the cursor setting manually through\n",
              "                 * the 'cursor' event from matplotlib */\n",
              "                event.preventDefault()\n",
              "                return fig.mouse_event(event, name);\n",
              "            };\n",
              "        } else {\n",
              "            return function (event) {\n",
              "                return fig.mouse_event(event, name);\n",
              "            };\n",
              "        }\n",
              "    }\n",
              "\n",
              "    canvas_div.addEventListener(\n",
              "        'mousedown',\n",
              "        on_mouse_event_closure('button_press')\n",
              "    );\n",
              "    canvas_div.addEventListener(\n",
              "        'mouseup',\n",
              "        on_mouse_event_closure('button_release')\n",
              "    );\n",
              "    canvas_div.addEventListener(\n",
              "        'dblclick',\n",
              "        on_mouse_event_closure('dblclick')\n",
              "    );\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    canvas_div.addEventListener(\n",
              "        'mousemove',\n",
              "        on_mouse_event_closure('motion_notify')\n",
              "    );\n",
              "\n",
              "    canvas_div.addEventListener(\n",
              "        'mouseenter',\n",
              "        on_mouse_event_closure('figure_enter')\n",
              "    );\n",
              "    canvas_div.addEventListener(\n",
              "        'mouseleave',\n",
              "        on_mouse_event_closure('figure_leave')\n",
              "    );\n",
              "\n",
              "    canvas_div.addEventListener('wheel', function (event) {\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        on_mouse_event_closure('scroll')(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.appendChild(canvas);\n",
              "    canvas_div.appendChild(rubberband_canvas);\n",
              "\n",
              "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
              "    this.rubberband_context.strokeStyle = '#000000';\n",
              "\n",
              "    this._resize_canvas = function (width, height, forward) {\n",
              "        if (forward) {\n",
              "            canvas_div.style.width = width + 'px';\n",
              "            canvas_div.style.height = height + 'px';\n",
              "        }\n",
              "    };\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
              "        event.preventDefault();\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus() {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function () {\n",
              "    var fig = this;\n",
              "\n",
              "    var toolbar = document.createElement('div');\n",
              "    toolbar.classList = 'mpl-toolbar';\n",
              "    this.root.appendChild(toolbar);\n",
              "\n",
              "    function on_click_closure(name) {\n",
              "        return function (_event) {\n",
              "            return fig.toolbar_button_onclick(name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    function on_mouseover_closure(tooltip) {\n",
              "        return function (event) {\n",
              "            if (!event.currentTarget.disabled) {\n",
              "                return fig.toolbar_button_onmouseover(tooltip);\n",
              "            }\n",
              "        };\n",
              "    }\n",
              "\n",
              "    fig.buttons = {};\n",
              "    var buttonGroup = document.createElement('div');\n",
              "    buttonGroup.classList = 'mpl-button-group';\n",
              "    for (var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            /* Instead of a spacer, we start a new button group. */\n",
              "            if (buttonGroup.hasChildNodes()) {\n",
              "                toolbar.appendChild(buttonGroup);\n",
              "            }\n",
              "            buttonGroup = document.createElement('div');\n",
              "            buttonGroup.classList = 'mpl-button-group';\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        var button = (fig.buttons[name] = document.createElement('button'));\n",
              "        button.classList = 'mpl-widget';\n",
              "        button.setAttribute('role', 'button');\n",
              "        button.setAttribute('aria-disabled', 'false');\n",
              "        button.addEventListener('click', on_click_closure(method_name));\n",
              "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
              "\n",
              "        var icon_img = document.createElement('img');\n",
              "        icon_img.src = '_images/' + image + '.png';\n",
              "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
              "        icon_img.alt = tooltip;\n",
              "        button.appendChild(icon_img);\n",
              "\n",
              "        buttonGroup.appendChild(button);\n",
              "    }\n",
              "\n",
              "    if (buttonGroup.hasChildNodes()) {\n",
              "        toolbar.appendChild(buttonGroup);\n",
              "    }\n",
              "\n",
              "    var fmt_picker = document.createElement('select');\n",
              "    fmt_picker.classList = 'mpl-widget';\n",
              "    toolbar.appendChild(fmt_picker);\n",
              "    this.format_dropdown = fmt_picker;\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = document.createElement('option');\n",
              "        option.selected = fmt === mpl.default_extension;\n",
              "        option.innerHTML = fmt;\n",
              "        fmt_picker.appendChild(option);\n",
              "    }\n",
              "\n",
              "    var status_bar = document.createElement('span');\n",
              "    status_bar.classList = 'mpl-message';\n",
              "    toolbar.appendChild(status_bar);\n",
              "    this.message = status_bar;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.send_message = function (type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function () {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
              "        fig.send_message('refresh', {});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
              "    var x0 = msg['x0'] / fig.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
              "    var x1 = msg['x1'] / fig.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0,\n",
              "        0,\n",
              "        fig.canvas.width / fig.ratio,\n",
              "        fig.canvas.height / fig.ratio\n",
              "    );\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
              "    fig.canvas_div.style.cursor = msg['cursor'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
              "    for (var key in msg) {\n",
              "        if (!(key in fig.buttons)) {\n",
              "            continue;\n",
              "        }\n",
              "        fig.buttons[key].disabled = !msg[key];\n",
              "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
              "    if (msg['mode'] === 'PAN') {\n",
              "        fig.buttons['Pan'].classList.add('active');\n",
              "        fig.buttons['Zoom'].classList.remove('active');\n",
              "    } else if (msg['mode'] === 'ZOOM') {\n",
              "        fig.buttons['Pan'].classList.remove('active');\n",
              "        fig.buttons['Zoom'].classList.add('active');\n",
              "    } else {\n",
              "        fig.buttons['Pan'].classList.remove('active');\n",
              "        fig.buttons['Zoom'].classList.remove('active');\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function () {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message('ack', {});\n",
              "};\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            var img = evt.data;\n",
              "            if (img.type !== 'image/png') {\n",
              "                /* FIXME: We get \"Resource interpreted as Image but\n",
              "                 * transferred with MIME type text/plain:\" errors on\n",
              "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "                 * to be part of the websocket stream */\n",
              "                img.type = 'image/png';\n",
              "            }\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src\n",
              "                );\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                img\n",
              "            );\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        } else if (\n",
              "            typeof evt.data === 'string' &&\n",
              "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
              "        ) {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig['handle_' + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\n",
              "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
              "                msg\n",
              "            );\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\n",
              "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
              "                    e,\n",
              "                    e.stack,\n",
              "                    msg\n",
              "                );\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "};\n",
              "\n",
              "function getModifiers(event) {\n",
              "    var mods = [];\n",
              "    if (event.ctrlKey) {\n",
              "        mods.push('ctrl');\n",
              "    }\n",
              "    if (event.altKey) {\n",
              "        mods.push('alt');\n",
              "    }\n",
              "    if (event.shiftKey) {\n",
              "        mods.push('shift');\n",
              "    }\n",
              "    if (event.metaKey) {\n",
              "        mods.push('meta');\n",
              "    }\n",
              "    return mods;\n",
              "}\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * https://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys(original) {\n",
              "    return Object.keys(original).reduce(function (obj, key) {\n",
              "        if (typeof original[key] !== 'object') {\n",
              "            obj[key] = original[key];\n",
              "        }\n",
              "        return obj;\n",
              "    }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function (event, name) {\n",
              "    if (name === 'button_press') {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    // from https://stackoverflow.com/q/1114465\n",
              "    var boundingRect = this.canvas.getBoundingClientRect();\n",
              "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
              "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
              "\n",
              "    this.send_message(name, {\n",
              "        x: x,\n",
              "        y: y,\n",
              "        button: event.button,\n",
              "        step: event.step,\n",
              "        modifiers: getModifiers(event),\n",
              "        guiEvent: simpleKeys(event),\n",
              "    });\n",
              "\n",
              "    return false;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.key_event = function (event, name) {\n",
              "    // Prevent repeat events\n",
              "    if (name === 'key_press') {\n",
              "        if (event.key === this._key) {\n",
              "            return;\n",
              "        } else {\n",
              "            this._key = event.key;\n",
              "        }\n",
              "    }\n",
              "    if (name === 'key_release') {\n",
              "        this._key = null;\n",
              "    }\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.key !== 'Control') {\n",
              "        value += 'ctrl+';\n",
              "    }\n",
              "    else if (event.altKey && event.key !== 'Alt') {\n",
              "        value += 'alt+';\n",
              "    }\n",
              "    else if (event.shiftKey && event.key !== 'Shift') {\n",
              "        value += 'shift+';\n",
              "    }\n",
              "\n",
              "    value += 'k' + event.key;\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
              "    return false;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
              "    if (name === 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message('toolbar_button', { name: name });\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "\n",
              "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
              "// prettier-ignore\n",
              "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
              "\n",
              "mpl.default_extension = \"png\";/* global mpl */\n",
              "\n",
              "var comm_websocket_adapter = function (comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.binaryType = comm.kernel.ws.binaryType;\n",
              "    ws.readyState = comm.kernel.ws.readyState;\n",
              "    function updateReadyState(_event) {\n",
              "        if (comm.kernel.ws) {\n",
              "            ws.readyState = comm.kernel.ws.readyState;\n",
              "        } else {\n",
              "            ws.readyState = 3; // Closed state.\n",
              "        }\n",
              "    }\n",
              "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
              "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
              "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
              "\n",
              "    ws.close = function () {\n",
              "        comm.close();\n",
              "    };\n",
              "    ws.send = function (m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function (msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        var data = msg['content']['data'];\n",
              "        if (data['blob'] !== undefined) {\n",
              "            data = {\n",
              "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
              "            };\n",
              "        }\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(data);\n",
              "    });\n",
              "    return ws;\n",
              "};\n",
              "\n",
              "mpl.mpl_figure_comm = function (comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = document.getElementById(id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm);\n",
              "\n",
              "    function ondownload(figure, _format) {\n",
              "        window.open(figure.canvas.toDataURL());\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element;\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error('Failed to find cell for figure', id, fig);\n",
              "        return;\n",
              "    }\n",
              "    fig.cell_info[0].output_area.element.on(\n",
              "        'cleared',\n",
              "        { fig: fig },\n",
              "        fig._remove_fig_handler\n",
              "    );\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
              "    var width = fig.canvas.width / fig.ratio;\n",
              "    fig.cell_info[0].output_area.element.off(\n",
              "        'cleared',\n",
              "        fig._remove_fig_handler\n",
              "    );\n",
              "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable();\n",
              "    fig.parent_element.innerHTML =\n",
              "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "    fig.close_ws(fig, msg);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width / this.ratio;\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] =\n",
              "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function () {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message('ack', {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () {\n",
              "        fig.push_to_output();\n",
              "    }, 1000);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function () {\n",
              "    var fig = this;\n",
              "\n",
              "    var toolbar = document.createElement('div');\n",
              "    toolbar.classList = 'btn-toolbar';\n",
              "    this.root.appendChild(toolbar);\n",
              "\n",
              "    function on_click_closure(name) {\n",
              "        return function (_event) {\n",
              "            return fig.toolbar_button_onclick(name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    function on_mouseover_closure(tooltip) {\n",
              "        return function (event) {\n",
              "            if (!event.currentTarget.disabled) {\n",
              "                return fig.toolbar_button_onmouseover(tooltip);\n",
              "            }\n",
              "        };\n",
              "    }\n",
              "\n",
              "    fig.buttons = {};\n",
              "    var buttonGroup = document.createElement('div');\n",
              "    buttonGroup.classList = 'btn-group';\n",
              "    var button;\n",
              "    for (var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            /* Instead of a spacer, we start a new button group. */\n",
              "            if (buttonGroup.hasChildNodes()) {\n",
              "                toolbar.appendChild(buttonGroup);\n",
              "            }\n",
              "            buttonGroup = document.createElement('div');\n",
              "            buttonGroup.classList = 'btn-group';\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        button = fig.buttons[name] = document.createElement('button');\n",
              "        button.classList = 'btn btn-default';\n",
              "        button.href = '#';\n",
              "        button.title = name;\n",
              "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
              "        button.addEventListener('click', on_click_closure(method_name));\n",
              "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
              "        buttonGroup.appendChild(button);\n",
              "    }\n",
              "\n",
              "    if (buttonGroup.hasChildNodes()) {\n",
              "        toolbar.appendChild(buttonGroup);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = document.createElement('span');\n",
              "    status_bar.classList = 'mpl-message pull-right';\n",
              "    toolbar.appendChild(status_bar);\n",
              "    this.message = status_bar;\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = document.createElement('div');\n",
              "    buttongrp.classList = 'btn-group inline pull-right';\n",
              "    button = document.createElement('button');\n",
              "    button.classList = 'btn btn-mini btn-primary';\n",
              "    button.href = '#';\n",
              "    button.title = 'Stop Interaction';\n",
              "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
              "    button.addEventListener('click', function (_evt) {\n",
              "        fig.handle_close(fig, {});\n",
              "    });\n",
              "    button.addEventListener(\n",
              "        'mouseover',\n",
              "        on_mouseover_closure('Stop Interaction')\n",
              "    );\n",
              "    buttongrp.appendChild(button);\n",
              "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
              "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
              "    var fig = event.data.fig;\n",
              "    if (event.target !== this) {\n",
              "        // Ignore bubbled events from children.\n",
              "        return;\n",
              "    }\n",
              "    fig.close_ws(fig, {});\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function (el) {\n",
              "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
              "    // this is important to make the div 'focusable\n",
              "    el.setAttribute('tabindex', 0);\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    } else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which === 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "};\n",
              "\n",
              "mpl.find_output_cell = function (html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i = 0; i < ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code') {\n",
              "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] === html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "};\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel !== null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target(\n",
              "        'matplotlib',\n",
              "        mpl.mpl_figure_comm\n",
              "    );\n",
              "}\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id='219811ae-ee46-4625-a058-5a316fa74544'></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_loss_list, valid_loss_list, global_steps_list = load_metrics('/content/drive/MyDrive/Colab Notebooks/metrics.pt')\n",
        "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "plt.xlabel('Global Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "0cb68692",
      "metadata": {
        "id": "0cb68692"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for text, label in test_loader:\n",
        "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "\n",
        "            sample = torch.tensor(padded_list)\n",
        "            sample, label = sample.to(device), label.to(device)\n",
        "            labels = torch.tensor(label)\n",
        "            output = model(sample, labels=labels)\n",
        "\n",
        "            _, output = output\n",
        "            y_pred.extend(torch.argmax(output, 1).tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "\n",
        "    print('Classification 결과:')\n",
        "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "    ax.xaxis.set_ticklabels(['0', '1'])\n",
        "    ax.yaxis.set_ticklabels(['0', '1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "97dfe435",
      "metadata": {
        "id": "97dfe435",
        "outputId": "d981bd12-0bb7-4378-f049-75d03faa7f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== /content/drive/MyDrive/Colab Notebooks/model.pt\n",
            "Classification 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.5091    1.0000    0.6747       558\n",
            "           0     0.0000    0.0000    0.0000       538\n",
            "\n",
            "    accuracy                         0.5091      1096\n",
            "   macro avg     0.2546    0.5000    0.3374      1096\n",
            "weighted avg     0.2592    0.5091    0.3435      1096\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "best_model = model.to(device)\n",
        "load_checkpoint('/content/drive/MyDrive/Colab Notebooks/model.pt', best_model)\n",
        "evaluate(best_model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}