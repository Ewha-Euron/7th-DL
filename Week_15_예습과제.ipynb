{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzM3_IHs94FM",
        "outputId": "e504cbac-bb77-455b-80d3-25f8de987cad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 1, 0, 1, 0])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "class2 = pd.read_csv('./class2.csv')\n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "onehot_encoder = preprocessing.OneHotEncoder()\n",
        "\n",
        "train_x = label_encoder.fit_transform(class2['class2'])\n",
        "train_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTqcxS2u94FN",
        "outputId": "38ed5489-94c5-4f37-f9c3-4c8e0756a1dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'this': 13,\n",
              " 'is': 7,\n",
              " 'last': 8,\n",
              " 'chance': 2,\n",
              " 'and': 0,\n",
              " 'if': 6,\n",
              " 'you': 15,\n",
              " 'do': 3,\n",
              " 'not': 10,\n",
              " 'have': 5,\n",
              " 'will': 14,\n",
              " 'never': 9,\n",
              " 'get': 4,\n",
              " 'any': 1,\n",
              " 'one': 11,\n",
              " 'please': 12}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'This is last chance.',\n",
        "    'and if you do not have this chance.',\n",
        "    'you will never get any chance.',\n",
        "    'will you do get this one?',\n",
        "    'please, get this chance'\n",
        "]\n",
        "vect = CountVectorizer()\n",
        "vect.fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcozFDti94FO",
        "outputId": "c7dd31f9-73d6-4900-964d-52657b9260b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.transform(['you will never get any chance.']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee-UTy8u94FO",
        "outputId": "1c3e38ad-67a5-4c12-9b0a-c43f6eb0a900"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'last': 6,\n",
              " 'chance': 1,\n",
              " 'if': 5,\n",
              " 'you': 11,\n",
              " 'do': 2,\n",
              " 'not': 8,\n",
              " 'have': 4,\n",
              " 'will': 10,\n",
              " 'never': 7,\n",
              " 'get': 3,\n",
              " 'any': 0,\n",
              " 'one': 9}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect = CountVectorizer(stop_words=['and', 'is', 'please', 'this']).fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OozkQTWs94FO",
        "outputId": "b33cb78e-8518-40bd-ebc9-d0b669c648c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "유사도를 위한 3 x 3 행렬을 만들었습니다.\n",
            "[[1.       0.224325 0.      ]\n",
            " [0.224325 1.       0.      ]\n",
            " [0.       0.       1.      ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
        "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
        "print('유사도를 위한', str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), '행렬을 만들었습니다.')\n",
        "print(doc_distance.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlAwRkCz94FO",
        "outputId": "5f4e31be-8ba9-474c-eb8b-6afcc9e98025"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['once',\n",
              "  'upon',\n",
              "  'a',\n",
              "  'time',\n",
              "  'in',\n",
              "  'london',\n",
              "  ',',\n",
              "  'the',\n",
              "  'darlings',\n",
              "  'went',\n",
              "  'out',\n",
              "  'to',\n",
              "  'a',\n",
              "  'dinner',\n",
              "  'party',\n",
              "  'leaving',\n",
              "  'their',\n",
              "  'three',\n",
              "  'children',\n",
              "  'wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  ',',\n",
              "  'and',\n",
              "  'michael',\n",
              "  'at',\n",
              "  'home',\n",
              "  '.'],\n",
              " ['after',\n",
              "  'wendy',\n",
              "  'had',\n",
              "  'tucked',\n",
              "  'her',\n",
              "  'younger',\n",
              "  'brothers',\n",
              "  'jhon',\n",
              "  'and',\n",
              "  'michael',\n",
              "  'to',\n",
              "  'bed',\n",
              "  ',',\n",
              "  'she',\n",
              "  'went',\n",
              "  'to',\n",
              "  'read',\n",
              "  'a',\n",
              "  'book',\n",
              "  '.'],\n",
              " ['she', 'heard', 'a', 'boy', 'sobbing', 'outside', 'her', 'window', '.'],\n",
              " ['he', 'was', 'flying', '.'],\n",
              " ['there', 'was', 'little', 'fairy', 'fluttering', 'around', 'him', '.'],\n",
              " ['wendy', 'opened', 'the', 'window', 'to', 'talk', 'to', 'him', '.'],\n",
              " ['“', 'hello', '!'],\n",
              " ['who', 'are', 'you', '?'],\n",
              " ['why', 'are', 'you', 'crying', '”', ',', 'wendy', 'asked', 'him', '.'],\n",
              " ['“', 'my', 'name', 'is', 'peter', 'pan', '.'],\n",
              " ['my',\n",
              "  'shadow',\n",
              "  'wouldn',\n",
              "  '’',\n",
              "  't',\n",
              "  'stock',\n",
              "  'to',\n",
              "  'me.',\n",
              "  '”',\n",
              "  ',',\n",
              "  'he',\n",
              "  'replied',\n",
              "  '.'],\n",
              " ['she', 'asked', 'him', 'to', 'come', 'in', '.'],\n",
              " ['peter', 'agreed', 'and', 'came', 'inside', 'the', 'room', '.'],\n",
              " ['wendy',\n",
              "  'took',\n",
              "  'his',\n",
              "  'shadow',\n",
              "  'and',\n",
              "  'sewed',\n",
              "  'it',\n",
              "  'to',\n",
              "  'his',\n",
              "  'shoe',\n",
              "  'tips',\n",
              "  '.'],\n",
              " ['now',\n",
              "  'his',\n",
              "  'shadow',\n",
              "  'followed',\n",
              "  'him',\n",
              "  'wherever',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'went',\n",
              "  '!'],\n",
              " ['he',\n",
              "  'was',\n",
              "  'delighted',\n",
              "  'and',\n",
              "  'asked',\n",
              "  'wendy',\n",
              "  '“',\n",
              "  'why',\n",
              "  'don',\n",
              "  '’',\n",
              "  't',\n",
              "  'you',\n",
              "  'come',\n",
              "  'with',\n",
              "  'me',\n",
              "  'to',\n",
              "  'my',\n",
              "  'home',\n",
              "  '.'],\n",
              " ['the', 'neverland', '.'],\n",
              " ['i',\n",
              "  'lived',\n",
              "  'there',\n",
              "  'with',\n",
              "  'my',\n",
              "  'fairy',\n",
              "  'tinker',\n",
              "  'bell.',\n",
              "  '”',\n",
              "  'wendy',\n",
              "  '?'],\n",
              " ['“', 'oh', '!'],\n",
              " ['what', 'a', 'wonderful', 'idea', '!'],\n",
              " ['let', 'me', 'wake', 'up', 'john', 'and', 'micheal', 'too', '.'],\n",
              " ['could', 'you', 'teach', 'us', 'how', 'to', 'fly', '?', '”', '.'],\n",
              " ['“', 'yes', '!'],\n",
              " ['of', 'course', '!'],\n",
              " ['get',\n",
              "  'them',\n",
              "  'we',\n",
              "  'will',\n",
              "  'all',\n",
              "  'fly',\n",
              "  'together.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'replied',\n",
              "  'and',\n",
              "  'so',\n",
              "  'it',\n",
              "  'was',\n",
              "  '.'],\n",
              " ['five',\n",
              "  'little',\n",
              "  'figures',\n",
              "  'flew',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'window',\n",
              "  'of',\n",
              "  'the',\n",
              "  'darlings',\n",
              "  'and',\n",
              "  'headed',\n",
              "  'towards',\n",
              "  'neverland',\n",
              "  '.'],\n",
              " ['as',\n",
              "  'they',\n",
              "  'flew',\n",
              "  'over',\n",
              "  'the',\n",
              "  'island',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'told',\n",
              "  'the',\n",
              "  'children',\n",
              "  'more',\n",
              "  'about',\n",
              "  'his',\n",
              "  'homeland',\n",
              "  '.'],\n",
              " ['“',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'who',\n",
              "  'get',\n",
              "  'lost',\n",
              "  'come',\n",
              "  'and',\n",
              "  'stay',\n",
              "  'with',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'and',\n",
              "  'me',\n",
              "  ',',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'told',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['the', 'indians', 'also', 'live', 'in', 'neverland', '.'],\n",
              " ['the',\n",
              "  'mermaids',\n",
              "  'live',\n",
              "  'in',\n",
              "  'the',\n",
              "  'lagoon',\n",
              "  'around',\n",
              "  'the',\n",
              "  'island',\n",
              "  '.'],\n",
              " ['and',\n",
              "  'a',\n",
              "  'very',\n",
              "  'mean',\n",
              "  'pirate',\n",
              "  'called',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'keeps',\n",
              "  'troubling',\n",
              "  'everyone',\n",
              "  '.'],\n",
              " ['“', 'crocodile', 'bit', 'his', 'one', 'arm', '.'],\n",
              " ['so',\n",
              "  'the',\n",
              "  'captain',\n",
              "  'had',\n",
              "  'to',\n",
              "  'put',\n",
              "  'a',\n",
              "  'hook',\n",
              "  'in',\n",
              "  'its',\n",
              "  'place',\n",
              "  '.'],\n",
              " ['since', 'then', 'he', 'is', 'afraid', 'of', 'crocodiles', '.'],\n",
              " ['and', 'rightly', 'so', '!'],\n",
              " ['if',\n",
              "  'the',\n",
              "  'crocodile',\n",
              "  'ever',\n",
              "  'found',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'it',\n",
              "  'will',\n",
              "  'eat',\n",
              "  'up',\n",
              "  'the',\n",
              "  'rest',\n",
              "  'of',\n",
              "  'it',\n",
              "  'couldn',\n",
              "  '’',\n",
              "  't',\n",
              "  'eat',\n",
              "  'last',\n",
              "  'time.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'told',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['soon', 'they', 'landed', 'on', 'the', 'island', '.'],\n",
              " ['and',\n",
              "  'to',\n",
              "  'the',\n",
              "  'surprise',\n",
              "  'of',\n",
              "  'wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  'and',\n",
              "  'michael',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'let',\n",
              "  'them',\n",
              "  'in',\n",
              "  'through',\n",
              "  'a',\n",
              "  'small',\n",
              "  'opening',\n",
              "  'in',\n",
              "  'a',\n",
              "  'tree',\n",
              "  '.'],\n",
              " ['inside',\n",
              "  'the',\n",
              "  'tree',\n",
              "  'was',\n",
              "  'a',\n",
              "  'large',\n",
              "  'room',\n",
              "  'with',\n",
              "  'children',\n",
              "  'inside',\n",
              "  'it',\n",
              "  '.'],\n",
              " ['somewhere',\n",
              "  'huddled',\n",
              "  'by',\n",
              "  'the',\n",
              "  'fire',\n",
              "  'in',\n",
              "  'the',\n",
              "  'corner',\n",
              "  'and',\n",
              "  'somewhere',\n",
              "  'playing',\n",
              "  'amongst',\n",
              "  'themselves',\n",
              "  '.'],\n",
              " ['their',\n",
              "  'faces',\n",
              "  'lit',\n",
              "  'up',\n",
              "  'when',\n",
              "  'they',\n",
              "  'saw',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  ',',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  ',',\n",
              "  'and',\n",
              "  'their',\n",
              "  'guests',\n",
              "  '.'],\n",
              " ['“', 'hello', 'everyone', '.'],\n",
              " ['this', 'is', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
              " ['they',\n",
              "  'will',\n",
              "  'be',\n",
              "  'staying',\n",
              "  'with',\n",
              "  'us',\n",
              "  'from',\n",
              "  'now',\n",
              "  'on.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'introduced',\n",
              "  'them',\n",
              "  'to',\n",
              "  'all',\n",
              "  'children',\n",
              "  '.'],\n",
              " ['children', 'welcomed', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
              " ['a', 'few', 'days', 'passed', '.'],\n",
              " ['and', 'they', 'settled', 'into', 'a', 'routine', '.'],\n",
              " ['wendy',\n",
              "  'would',\n",
              "  'take',\n",
              "  'care',\n",
              "  'of',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'in',\n",
              "  'the',\n",
              "  'day',\n",
              "  'and',\n",
              "  'would',\n",
              "  'go',\n",
              "  'out',\n",
              "  'with',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'and',\n",
              "  'her',\n",
              "  'brothers',\n",
              "  'in',\n",
              "  'the',\n",
              "  'evening',\n",
              "  'to',\n",
              "  'learn',\n",
              "  'about',\n",
              "  'the',\n",
              "  'island',\n",
              "  '.'],\n",
              " ['she',\n",
              "  'would',\n",
              "  'cook',\n",
              "  'for',\n",
              "  'them',\n",
              "  'and',\n",
              "  'stitch',\n",
              "  'new',\n",
              "  'clothes',\n",
              "  'for',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'even',\n",
              "  'made',\n",
              "  'a',\n",
              "  'lovely',\n",
              "  'new',\n",
              "  'dress',\n",
              "  'for',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  '.'],\n",
              " ['one',\n",
              "  'evening',\n",
              "  ',',\n",
              "  'as',\n",
              "  'they',\n",
              "  'were',\n",
              "  'out',\n",
              "  'exploring',\n",
              "  'the',\n",
              "  'island',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'warned',\n",
              "  'everyone',\n",
              "  'and',\n",
              "  'said',\n",
              "  ',',\n",
              "  '“',\n",
              "  'hide',\n",
              "  '!'],\n",
              " ['hide', '!'],\n",
              " ['pirates', '!'],\n",
              " ['and',\n",
              "  'they',\n",
              "  'have',\n",
              "  'kidnapped',\n",
              "  'the',\n",
              "  'indian',\n",
              "  'princess',\n",
              "  'tiger',\n",
              "  'lily',\n",
              "  '.'],\n",
              " ['they',\n",
              "  'have',\n",
              "  'kept',\n",
              "  'her',\n",
              "  'there',\n",
              "  ',',\n",
              "  'tied',\n",
              "  'up',\n",
              "  'by',\n",
              "  'the',\n",
              "  'rocks',\n",
              "  ',',\n",
              "  'near',\n",
              "  'the',\n",
              "  'water.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'was',\n",
              "  'afraid',\n",
              "  'and',\n",
              "  'the',\n",
              "  'princess',\n",
              "  'would',\n",
              "  'drown',\n",
              "  ',',\n",
              "  'is',\n",
              "  'she',\n",
              "  'fell',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water',\n",
              "  '.'],\n",
              " ['so',\n",
              "  ',',\n",
              "  'in',\n",
              "  'a',\n",
              "  'voice',\n",
              "  'that',\n",
              "  'sounded',\n",
              "  'like',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  ',',\n",
              "  'he',\n",
              "  'shouted',\n",
              "  'instructions',\n",
              "  'to',\n",
              "  'the',\n",
              "  'pirates',\n",
              "  'who',\n",
              "  'guarded',\n",
              "  'her',\n",
              "  ',',\n",
              "  '“',\n",
              "  'you',\n",
              "  'fools',\n",
              "  '!'],\n",
              " ['let', 'her', 'go', 'at', 'once', '!'],\n",
              " ['do',\n",
              "  'it',\n",
              "  'before',\n",
              "  'i',\n",
              "  'come',\n",
              "  'there',\n",
              "  'or',\n",
              "  'else',\n",
              "  'i',\n",
              "  'will',\n",
              "  'throw',\n",
              "  'each',\n",
              "  'one',\n",
              "  'of',\n",
              "  'you',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water.',\n",
              "  '”',\n",
              "  'the',\n",
              "  'pirates',\n",
              "  'got',\n",
              "  'scared',\n",
              "  'and',\n",
              "  'immediately',\n",
              "  'released',\n",
              "  'the',\n",
              "  'princes',\n",
              "  '.'],\n",
              " ['she',\n",
              "  'quickly',\n",
              "  'dived',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water',\n",
              "  'and',\n",
              "  'swam',\n",
              "  'to',\n",
              "  'the',\n",
              "  'safety',\n",
              "  'of',\n",
              "  'her',\n",
              "  'home',\n",
              "  '.'],\n",
              " ['soon',\n",
              "  'everyone',\n",
              "  'found',\n",
              "  'out',\n",
              "  'how',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'had',\n",
              "  'rescued',\n",
              "  'the',\n",
              "  'princess',\n",
              "  '.'],\n",
              " ['when',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'found',\n",
              "  'out',\n",
              "  'how',\n",
              "  'peter',\n",
              "  'had',\n",
              "  'tricked',\n",
              "  'his',\n",
              "  'men',\n",
              "  'he',\n",
              "  'was',\n",
              "  'furious',\n",
              "  '.'],\n",
              " ['and', 'swore', 'to', 'have', 'his', 'revenge', '.'],\n",
              " ['that',\n",
              "  'night',\n",
              "  'wendy',\n",
              "  'told',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  ',',\n",
              "  'that',\n",
              "  'she',\n",
              "  'and',\n",
              "  'her',\n",
              "  'brother',\n",
              "  'wanted',\n",
              "  'to',\n",
              "  'go',\n",
              "  'back',\n",
              "  'home',\n",
              "  'since',\n",
              "  'they',\n",
              "  'missed',\n",
              "  'their',\n",
              "  'parents',\n",
              "  '.'],\n",
              " ['she',\n",
              "  'said',\n",
              "  'if',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  'could',\n",
              "  'also',\n",
              "  'return',\n",
              "  'to',\n",
              "  'her',\n",
              "  'world',\n",
              "  'they',\n",
              "  'could',\n",
              "  'find',\n",
              "  'a',\n",
              "  'nice',\n",
              "  'home',\n",
              "  'for',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['peter', 'pan', 'didn', '’', 't', 'want', 'to', 'leave', 'neverland', '.'],\n",
              " ['but',\n",
              "  'the',\n",
              "  'sake',\n",
              "  'of',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  'he',\n",
              "  'agreed',\n",
              "  ',',\n",
              "  'although',\n",
              "  'a',\n",
              "  'bit',\n",
              "  'sadly',\n",
              "  '.'],\n",
              " ['he', 'would', 'miss', 'his', 'friends', 'dearly', '.'],\n",
              " ['the',\n",
              "  'next',\n",
              "  'morning',\n",
              "  'all',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  'left',\n",
              "  'with',\n",
              "  'wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  ',',\n",
              "  'and',\n",
              "  'michael',\n",
              "  '.'],\n",
              " ['but',\n",
              "  'on',\n",
              "  'the',\n",
              "  'way',\n",
              "  ',',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'and',\n",
              "  'his',\n",
              "  'men',\n",
              "  'kidnapped',\n",
              "  'all',\n",
              "  'of',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'tied',\n",
              "  'them',\n",
              "  'and',\n",
              "  'kept',\n",
              "  'them',\n",
              "  'on',\n",
              "  'once',\n",
              "  'of',\n",
              "  'his',\n",
              "  'ships',\n",
              "  '.'],\n",
              " ['as',\n",
              "  'soon',\n",
              "  'as',\n",
              "  'peter',\n",
              "  'found',\n",
              "  'out',\n",
              "  'about',\n",
              "  'it',\n",
              "  'he',\n",
              "  'rushed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'ship',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'swung',\n",
              "  'himself',\n",
              "  'from',\n",
              "  'a',\n",
              "  'tress',\n",
              "  'branch',\n",
              "  'and',\n",
              "  'on',\n",
              "  'to',\n",
              "  'the',\n",
              "  'deck',\n",
              "  'of',\n",
              "  'the',\n",
              "  'ship',\n",
              "  'where',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'were',\n",
              "  'tied',\n",
              "  'up',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'swung',\n",
              "  'his',\n",
              "  'sword',\n",
              "  'bravely',\n",
              "  'and',\n",
              "  'threw',\n",
              "  'over',\n",
              "  'the',\n",
              "  'pirates',\n",
              "  'who',\n",
              "  'tried',\n",
              "  'to',\n",
              "  'stop',\n",
              "  'him',\n",
              "  '.'],\n",
              " ['quickly',\n",
              "  'he',\n",
              "  'released',\n",
              "  'everyone',\n",
              "  'from',\n",
              "  'their',\n",
              "  'captor',\n",
              "  '’',\n",
              "  's',\n",
              "  'ties',\n",
              "  '.'],\n",
              " ['wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  ',',\n",
              "  'michael',\n",
              "  'and',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'helped',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water',\n",
              "  ',',\n",
              "  'where',\n",
              "  'their',\n",
              "  'friends',\n",
              "  'from',\n",
              "  'the',\n",
              "  'indian',\n",
              "  'camp',\n",
              "  'were',\n",
              "  'ready',\n",
              "  'with',\n",
              "  'smaller',\n",
              "  'boats',\n",
              "  'to',\n",
              "  'take',\n",
              "  'them',\n",
              "  'to',\n",
              "  'safety',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'now',\n",
              "  'went',\n",
              "  'looking',\n",
              "  'for',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  '.'],\n",
              " ['“',\n",
              "  'let',\n",
              "  'us',\n",
              "  'finished',\n",
              "  'this',\n",
              "  'forever',\n",
              "  'mr.',\n",
              "  'hook',\n",
              "  '”',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'challenged',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  '.'],\n",
              " ['“', 'yes', '!'],\n",
              " ['peter',\n",
              "  'pan',\n",
              "  ',',\n",
              "  'you',\n",
              "  'have',\n",
              "  'caused',\n",
              "  'me',\n",
              "  'enough',\n",
              "  'trouble',\n",
              "  '.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'time',\n",
              "  'that',\n",
              "  'we',\n",
              "  'finished',\n",
              "  'this.',\n",
              "  '”',\n",
              "  'hook',\n",
              "  'replied',\n",
              "  '.'],\n",
              " ['with',\n",
              "  'his',\n",
              "  'sword',\n",
              "  'drawn',\n",
              "  ',',\n",
              "  'he',\n",
              "  'raced',\n",
              "  'towards',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  '.'],\n",
              " ['quick',\n",
              "  'on',\n",
              "  'his',\n",
              "  'feet',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'stepped',\n",
              "  'aside',\n",
              "  'and',\n",
              "  'pushed',\n",
              "  'hook',\n",
              "  'inside',\n",
              "  'the',\n",
              "  'sea',\n",
              "  'where',\n",
              "  'the',\n",
              "  'crocodile',\n",
              "  'was',\n",
              "  'waiting',\n",
              "  'to',\n",
              "  'eat',\n",
              "  'the',\n",
              "  'rest',\n",
              "  'of',\n",
              "  'hook',\n",
              "  '.'],\n",
              " ['everyone',\n",
              "  'rejoiced',\n",
              "  'as',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'was',\n",
              "  'out',\n",
              "  'of',\n",
              "  'their',\n",
              "  'lives',\n",
              "  'forever',\n",
              "  '.'],\n",
              " ['everybody', 'headed', 'back', 'to', 'london', '.'],\n",
              " ['mr.', 'and', 'mrs', '.'],\n",
              " ['darling',\n",
              "  'was',\n",
              "  'so',\n",
              "  'happy',\n",
              "  'to',\n",
              "  'see',\n",
              "  'their',\n",
              "  'children',\n",
              "  'and',\n",
              "  'they',\n",
              "  'agreed',\n",
              "  'to',\n",
              "  'adopt',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  '.'],\n",
              " ['they',\n",
              "  'even',\n",
              "  'asked',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'to',\n",
              "  'come',\n",
              "  'and',\n",
              "  'live',\n",
              "  'with',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['but',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'said',\n",
              "  ',',\n",
              "  'he',\n",
              "  'never',\n",
              "  'wanted',\n",
              "  'to',\n",
              "  'grow',\n",
              "  'up',\n",
              "  ',',\n",
              "  'so',\n",
              "  'he',\n",
              "  'and',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'will',\n",
              "  'go',\n",
              "  'back',\n",
              "  'to',\n",
              "  'neverland',\n",
              "  '.'],\n",
              " ['peter',\n",
              "  'pan',\n",
              "  'promised',\n",
              "  'everyone',\n",
              "  'that',\n",
              "  'he',\n",
              "  'will',\n",
              "  'visit',\n",
              "  'again',\n",
              "  'sometime',\n",
              "  '!'],\n",
              " ['and',\n",
              "  'he',\n",
              "  'flew',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'window',\n",
              "  'with',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'by',\n",
              "  'his',\n",
              "  'side',\n",
              "  '.']]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sample = open('./peter.txt', 'r', encoding='UTF8')\n",
        "s = sample.read()\n",
        "\n",
        "f = s.replace('\\n', ' ')\n",
        "data = []\n",
        "\n",
        "for i in sent_tokenize(f):\n",
        "    temp = []\n",
        "    for j in word_tokenize(i):\n",
        "        temp.append(j.lower())\n",
        "    data.append(temp)\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTxp_cCP94FP",
        "outputId": "3f3b511b-8f34-4de9-b236-92f1c81b7377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between \"peter\" 'wendy' - CBOW :  0.10282581\n"
          ]
        }
      ],
      "source": [
        "model1 = gensim.models.Word2Vec(data, min_count=1,\n",
        "                                max_vocab_size=100, window=5, sg=0)\n",
        "print('Cosine similarity between \"peter\" ' +\n",
        "      \"'wendy' - CBOW : \",\n",
        "      model1.wv.similarity('peter', 'wendy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLohQ3ET94FP",
        "outputId": "82d67e00-30e1-48da-e25b-0034d46d6e0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cosine similarity between 'peter' 'hook' - CBOW :  0.22283737\n"
          ]
        }
      ],
      "source": [
        "print(\"cosine similarity between 'peter' \" +\n",
        "      \"'hook' - CBOW : \",\n",
        "      model1.wv.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89zVFk5194FP",
        "outputId": "5e7a156c-917b-45c6-ebf5-5dab3cdd7f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between \"peter\" 'wendy' - Skip gram :  0.41241685\n"
          ]
        }
      ],
      "source": [
        "model2 = gensim.models.Word2Vec(data, min_count=1,\n",
        "                                window=5, sg=1)\n",
        "print('Cosine similarity between \"peter\" ' +\n",
        "      \"'wendy' - Skip gram : \",\n",
        "      model2.wv.similarity('peter', 'wendy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v22GXecE94FP",
        "outputId": "527f5b9a-e917-4664-db4d-a1c121efacd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between \"peter\" 'hook' - Skip gram :  0.49479905\n"
          ]
        }
      ],
      "source": [
        "print('Cosine similarity between \"peter\" ' +\n",
        "      \"'hook' - Skip gram : \",\n",
        "      model2.wv.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQMgqahF94FP"
      },
      "outputs": [],
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import FastText\n",
        "\n",
        "model = FastText('./peter.txt', window=3, min_count=1, iter=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGg2xuUB94FP",
        "outputId": "31896a85-6b4f-4427-fc9f-3a9dc1265c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.073549405\n"
          ]
        }
      ],
      "source": [
        "sim_score = model.wv.similarity('peter', 'wendy')\n",
        "print(sim_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF8SHy3W94FP",
        "outputId": "6ff28915-14ed-47e8-c54f-7963e4029570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.08767462\n"
          ]
        }
      ],
      "source": [
        "sim_score = model.wv.similarity('peter', 'hook')\n",
        "print(sim_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrwxQlej94FP"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model_kr = KeyedVectors.load_word2vec_format('./wiki.ko.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJEjXa2C94FP",
        "outputId": "9f539c27-b273-4dda-97a3-9ee848a8133e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: 노력함, Similarity: 0.80\n",
            "Word: 노력중, Similarity: 0.75\n",
            "Word: 노력만, Similarity: 0.72\n",
            "Word: 노력과, Similarity: 0.71\n",
            "Word: 노력의, Similarity: 0.69\n",
            "Word: 노력가, Similarity: 0.69\n",
            "Word: 노력이나, Similarity: 0.69\n",
            "Word: 노력없이, Similarity: 0.68\n",
            "Word: 노력맨, Similarity: 0.68\n",
            "Word: 노력보다는, Similarity: 0.68\n"
          ]
        }
      ],
      "source": [
        "find_similar_to = '노력'\n",
        "\n",
        "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
        "    print('Word: {0}, Similarity: {1:.2f}'.format(\n",
        "        similar_word[0], similar_word[1]\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qESCJheH94FQ",
        "outputId": "5e505c45-fb1c-446e-8db7-9768eff91786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('초식동물', 0.7804122567176819), ('거대동물', 0.7547270059585571), ('육식동물의', 0.7547166347503662), ('유두동물', 0.7535113096237183), ('반추동물', 0.7470757961273193), ('독동물', 0.7466291785240173), ('육상동물', 0.746031641960144), ('유즐동물', 0.7450904250144958), ('극피동물', 0.7449344396591187), ('복모동물', 0.7424346208572388)]\n"
          ]
        }
      ],
      "source": [
        "similarities = model_kr.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
        "print(similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqOWH02894FQ",
        "outputId": "b62f830d-2e90-434d-efc7-72410fede855"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_file = datapath('/Users/cakenpeace/2024_EWHA/EURON/EURON/Week 15/glove.6B.100d.txt')\n",
        "word2vec_glove_file = get_tmpfile('glove.6B.100d.word2vec.txt')\n",
        "glove2word2vec(glove_file, word2vec_glove_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVPjEoGO94FQ",
        "outputId": "471833ae-e4af-49de-a2a0-b558402e1f66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('legislation', 0.8072139620780945),\n",
              " ('proposal', 0.7306863069534302),\n",
              " ('senate', 0.7142541408538818),\n",
              " ('bills', 0.7044401168823242),\n",
              " ('measure', 0.6958035230636597),\n",
              " ('passed', 0.690624475479126),\n",
              " ('amendment', 0.6846879720687866),\n",
              " ('provision', 0.6845567226409912),\n",
              " ('plan', 0.6816462874412537),\n",
              " ('clinton', 0.6663140058517456)]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
        "model.most_similar('bill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_gW2K_i94FQ",
        "outputId": "3df32a92-165a-494e-88ad-12fb3e04a7e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('peach', 0.688809871673584),\n",
              " ('mango', 0.6838189959526062),\n",
              " ('plum', 0.6684104800224304),\n",
              " ('berry', 0.6590359210968018),\n",
              " ('grove', 0.658155083656311),\n",
              " ('blossom', 0.6503506898880005),\n",
              " ('raspberry', 0.6477391719818115),\n",
              " ('strawberry', 0.6442098617553711),\n",
              " ('pine', 0.6390928626060486),\n",
              " ('almond', 0.6379212737083435)]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar('cherry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywvLXWUw94FQ",
        "outputId": "33fb61d2-1091-4f08-f741-50060ffe8383"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('kazushige', 0.4834350645542145),\n",
              " ('askerov', 0.4778186082839966),\n",
              " ('lakpa', 0.46915262937545776),\n",
              " ('ex-gay', 0.45713329315185547),\n",
              " ('tadayoshi', 0.4522106647491455),\n",
              " ('turani', 0.4481006860733032),\n",
              " ('saglam', 0.4469599425792694),\n",
              " ('aijun', 0.4435270130634308),\n",
              " ('adjustors', 0.44235295057296753),\n",
              " ('nyum', 0.4423117935657501)]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar(negative=['cherry'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW1KVJsc94FQ",
        "outputId": "0bf6c280-7206-4d05-e900-6c8337218b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queen: 0.7699\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"{}: {:.4f}\".format(*result[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGM09DJO94FQ",
        "outputId": "86b54bb3-4dd2-4f74-9d79-6ec6180ed78a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'champagne'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def analogy(x1, x2, y1):\n",
        "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
        "    return result[0][0]\n",
        "analogy('australia', 'beer', 'france')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_FDpPEA94FQ",
        "outputId": "16bcc468-c56c-4b1a-8821-8edcfd07c71d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'longest'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analogy('tall', 'tallest', 'long')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7418QTL94FQ",
        "outputId": "d51b9bb2-56a8-46fd-8b5d-611f0a225de3"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "arrays to stack must be passed as a \"sequence\" type such as list or tuple.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoesnt_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbreakfast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcereal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdinner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlunch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:877\u001b[0m, in \u001b[0;36mWordEmbeddingsKeyedVectors.doesnt_match\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m used_words:\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot select a word from an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 877\u001b[0m vectors \u001b[38;5;241m=\u001b[39m \u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mused_words\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(REAL)\n\u001b[1;32m    878\u001b[0m mean \u001b[38;5;241m=\u001b[39m matutils\u001b[38;5;241m.\u001b[39munitvec(vectors\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(REAL)\n\u001b[1;32m    879\u001b[0m dists \u001b[38;5;241m=\u001b[39m dot(vectors, mean)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/core/shape_base.py:216\u001b[0m, in \u001b[0;36m_vhstack_dispatcher\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_vhstack_dispatcher\u001b[39m(tup, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_arrays_for_stack_dispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/core/shape_base.py:209\u001b[0m, in \u001b[0;36m_arrays_for_stack_dispatcher\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arrays_for_stack_dispatcher\u001b[39m(arrays):\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arrays, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 209\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrays to stack must be passed as a \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    210\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuch as list or tuple.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(arrays)\n",
            "\u001b[0;31mTypeError\u001b[0m: arrays to stack must be passed as a \"sequence\" type such as list or tuple."
          ]
        }
      ],
      "source": [
        "print(model.doesnt_match(['breakfast', 'cereal', 'dinner', 'lunch']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_rcCvcD94FQ"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy_khQaH94FQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkIPuzUL94FQ"
      },
      "outputs": [],
      "source": [
        "def normalizeString(df, lang):\n",
        "    sentence = df[lang].str.lower()\n",
        "    sentence = sentence.str.replace('[^A-Za-z\\s]+', '')\n",
        "    sentence = sentence.str.normalize('NFD')\n",
        "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "    return sentence\n",
        "\n",
        "def read_sentence(df, lang1, lang2):\n",
        "    sentence1 = normalizeString(df, lang1)\n",
        "    sentence2 = normalizeString(df, lang2)\n",
        "    return sentence1, sentence2\n",
        "\n",
        "def read_file(loc, lang1, lang2):\n",
        "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2])\n",
        "    return df\n",
        "\n",
        "def process_data(lang1,lang2):\n",
        "    df = read_file('/content/%s-%s.txt' % (lang1, lang2), lang1, lang2)\n",
        "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
        "\n",
        "    input_lang = Lang()\n",
        "    output_lang = Lang()\n",
        "    pairs = []\n",
        "    for i in range(len(df)):\n",
        "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
        "            full = [sentence1[i], sentence2[i]]\n",
        "            input_lang.addSentence(sentence1[i])\n",
        "            output_lang.addSentence(sentence2[i])\n",
        "            pairs.append(full)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggwXMcAV94FR"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(input_lang, output_lang, pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLByVf4R94FR"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_dim, self.embbed_dim)\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src).view(1, 1, -1)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgLF9pwV94FR"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, self.embbed_dim)\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.view(1, -1)\n",
        "        embedded = F.relu(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        prediction = self.softmax(self.out(output[0]))\n",
        "        return prediction, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMDZt6Tz94FR"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        input_length = input_lang.size(0)\n",
        "        batch_size = output_lang.shape[1]\n",
        "        target_length = output_lang.shape[0]\n",
        "        vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
        "\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = self.encoder(input_lang[i])\n",
        "\n",
        "        decoder_hidden = encoder_hidden.to(device)\n",
        "        decoder_input = torch.tensor([SOS_token], device=device)\n",
        "\n",
        "        for t in range(target_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            outputs[t] = decoder_output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            input = (output_lang[t] if teacher_force else topi)\n",
        "            if(teacher_force == False and input.item() == EOS_token):\n",
        "                break\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdT9DS_r94FR"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def Model(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
        "    model_optimizer.zero_grad()\n",
        "    input_length = input_tensor.size(0)\n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    output = model(input_tensor, target_tensor)\n",
        "    num_iter = output.size(0)\n",
        "\n",
        "    for ot in range(num_iter):\n",
        "        loss += criterion(output[ot], target_tensor[ot])\n",
        "\n",
        "    loss.backward()\n",
        "    model_optimizer.step()\n",
        "    epoch_loss = loss.item() / num_iter\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxqcbVUZ94FR"
      },
      "outputs": [],
      "source": [
        "\n",
        "def trainModel(model, input_lang, output_lang, pairs, num_iteration=20000):\n",
        "    model.train()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.NLLLoss()\n",
        "    total_loss_iterations = 0\n",
        "\n",
        "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
        "                      for i in range(num_iteration)]\n",
        "\n",
        "    for iter in range(1, num_iteration+1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = Model(model, input_tensor, target_tensor, optimizer, criterion)\n",
        "        total_loss_iterations += loss\n",
        "\n",
        "        if iter % 5000 == 0:\n",
        "            average_loss= total_loss_iterations / 5000\n",
        "            total_loss_iterations = 0\n",
        "            print('%d %.4f' % (iter, average_loss))\n",
        "\n",
        "    torch.save(model.state_dict(), './mytraining.pt')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdxnGNC-94FR"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
        "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
        "        decoded_words = []\n",
        "        output = model(input_tensor, output_tensor)\n",
        "\n",
        "        for ot in range(output.size(0)):\n",
        "            topv, topi = output[ot].topk(1)\n",
        "\n",
        "            if topi[0].item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
        "    return decoded_words\n",
        "\n",
        "def evaluateRandomly(model, input_lang, output_lang, pairs, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('input {}'.format(pair[0]))\n",
        "        print('output {}'.format(pair[1]))\n",
        "        output_words = evaluate(model, input_lang, output_lang, pair)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('predicted {}'.format(output_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8YmnlO_94FR",
        "outputId": "4679412e-65fd-4d0d-8e29-f907cce024ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-f2b97267f8a3>:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
            "<ipython-input-17-f2b97267f8a3>:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  full = [sentence1[i], sentence2[i]]\n",
            "<ipython-input-17-f2b97267f8a3>:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  input_lang.addSentence(sentence1[i])\n",
            "<ipython-input-17-f2b97267f8a3>:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  output_lang.addSentence(sentence2[i])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random sentence [\"ce n'est pas serieux.\", 'cc-by 2.0 (france) attribution: tatoeba.org #2249131 (ck) & #15404 (aiji)']\n",
            "Input : 49951 Output : 374182\n",
            "Encoder(\n",
            "  (embedding): Embedding(49951, 256)\n",
            "  (gru): GRU(256, 512)\n",
            ")\n",
            "Decoder(\n",
            "  (embedding): Embedding(374182, 256)\n",
            "  (gru): GRU(256, 512)\n",
            "  (out): Linear(in_features=512, out_features=374182, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "lang1 = 'eng'\n",
        "lang2 = 'fra'\n",
        "input_lang, output_lang, pairs = process_data(lang1, lang2)\n",
        "\n",
        "randomize = random.choice(pairs)\n",
        "print('random sentence {}'.format(randomize))\n",
        "\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "print('Input : {} Output : {}'.format(input_size, output_size))\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_iteration = 100\n",
        "\n",
        "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "print(encoder)\n",
        "print(decoder)\n",
        "\n",
        "model = trainModel(model, input_lang, output_lang, pairs, num_iteration)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La2SC5IK-j2U",
        "outputId": "bf4fb0b0-f039-41f5-965a-3bf2296b627f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckLSx-lI94FR"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wmn9T9K94FR"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "lRnaVedSAO-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv2VVOkZ94FR"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = Model(model, input_tensor, target_tensor, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % 5000 == 0:\n",
        "            print_loss_avg = print_loss_total / 5000\n",
        "            print_loss_total = 0\n",
        "            print('%d,  %.4f' % (iter, print_loss_avg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qos1dRje94FS",
        "outputId": "43938700-4bfd-480b-e494-7937b64580d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(49951, 256)\n",
            "  (gru): GRU(256, 512)\n",
            ")\n",
            "AttnDecoderRNN(\n",
            "  (embedding): Embedding(374182, 512)\n",
            "  (attn): Linear(in_features=1024, out_features=20, bias=True)\n",
            "  (attn_combine): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (gru): GRU(512, 512)\n",
            "  (out): Linear(in_features=512, out_features=374182, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "\n",
        "encoder1 = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_size, dropout_p=0.1).to(device)\n",
        "\n",
        "print(encoder1)\n",
        "print(attn_decoder1)\n",
        "\n",
        "attn_model = trainIters(encoder1, attn_decoder1, 100, print_every=5000, plot_every=100, learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBr4ijdgAhmm",
        "outputId": "4ed80f7a-7598-4c74-d3f1-213adc305980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers) (1.26.4)\n",
            "Collecting boto3 (from pytorch_transformers)\n",
            "  Downloading boto3-1.35.90-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers) (2024.11.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers) (0.2.0)\n",
            "Collecting sacremoses (from pytorch_transformers)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch_transformers) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->pytorch_transformers) (1.3.0)\n",
            "Collecting botocore<1.36.0,>=1.35.90 (from boto3->pytorch_transformers)\n",
            "  Downloading botocore-1.35.90-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch_transformers)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->pytorch_transformers)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_transformers) (2024.12.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch_transformers) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.90->boto3->pytorch_transformers) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->pytorch_transformers) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.90->boto3->pytorch_transformers) (1.17.0)\n",
            "Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.90-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.90-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, pytorch_transformers\n",
            "Successfully installed boto3-1.35.90 botocore-1.35.90 jmespath-1.0.1 pytorch_transformers-1.2.0 s3transfer-0.10.4 sacremoses-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpEz0SWQ94FX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drca0aL794FX"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/testing.txt', sep='\\t')\n",
        "valid_df = pd.read_csv('/content/validing.txt', sep='\\t')\n",
        "test_df = pd.read_csv('/content/testing.txt', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1df0SI294FX"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sample(frac=0.1, random_state=500)\n",
        "valid_df = valid_df.sample(frac=0.1, random_state=500)\n",
        "test_df = test_df.sample(frac=0.1, random_state=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA9qogEt94FX"
      },
      "outputs": [],
      "source": [
        "class Datasets(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx, 1]\n",
        "        label = self.df.iloc[idx, 2]\n",
        "        return text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52rKJO_z94FX"
      },
      "outputs": [],
      "source": [
        "train_dataset = Datasets(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "valid_dataset = Datasets(valid_df)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "test_dataset = Datasets(test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIkhTXjV94FX",
        "outputId": "da6ea60d-d370-458e-a2cb-eaac33ef84c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 909439.51B/s]\n",
            "100%|██████████| 433/433 [00:00<00:00, 298558.87B/s]\n",
            "100%|██████████| 440473133/440473133 [00:16<00:00, 26555361.53B/s]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_transformers/modeling_utils.py:539: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(resolved_archive_file, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VQouaz594FY"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):\n",
        "    if load_path==None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_metrics(load_path):\n",
        "    if load_path==None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKkJU0Yg94FY"
      },
      "outputs": [],
      "source": [
        "def train(model,\n",
        "          optimizer,\n",
        "          criterion = nn.BCELoss(),\n",
        "          num_epochs = 1,\n",
        "          eval_every = len(train_loader) // 2,\n",
        "          best_valid_loss = float(\"Inf\")):\n",
        "\n",
        "    total_correct = 0.0\n",
        "    total_len = 0.0\n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for text, label in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "\n",
        "            sample = torch.tensor(padded_list)\n",
        "            sample, label = sample.to(device), label.to(device)\n",
        "            labels = torch.tensor(label)\n",
        "            outputs = model(sample, labels=labels)\n",
        "            loss, logits = outputs\n",
        "\n",
        "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "            correct = pred.eq(labels)\n",
        "            total_correct += correct.sum().item()\n",
        "            total_len += len(labels)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_every == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    for text, label in valid_loader:\n",
        "                        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "                        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "                        sample = torch.tensor(padded_list)\n",
        "                        sample, label = sample.to(device), label.to(device)\n",
        "                        labels = torch.tensor(label)\n",
        "                        outputs = model(sample, labels=labels)\n",
        "                        loss, logits = outputs\n",
        "                        valid_running_loss += loss.item()\n",
        "\n",
        "                average_train_loss = running_loss / eval_every\n",
        "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                running_loss = 0.0\n",
        "                valid_running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
        "                              average_train_loss, average_valid_loss))\n",
        "\n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint('./model.pt', model, best_valid_loss)\n",
        "                    save_metrics('./metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "\n",
        "    save_metrics('./metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    print('훈련 종료!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBU67bzh94FY",
        "outputId": "715f6525-b081-4a47-9120-3ff47ad7e5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-47144ba37d09>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(label)\n",
            "<ipython-input-33-47144ba37d09>:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
            "<ipython-input-33-47144ba37d09>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(label)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [274/548], Train Loss: 0.7138, Valid Loss: 0.7021\n",
            "Model saved to ==> ./model.pt\n",
            "Model saved to ==> ./metrics.pt\n",
            "Epoch [1/1], Step [548/548], Train Loss: 0.6991, Valid Loss: 0.6999\n",
            "Model saved to ==> ./model.pt\n",
            "Model saved to ==> ./metrics.pt\n",
            "Model saved to ==> ./metrics.pt\n",
            "훈련 종료!\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "train(model=model, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "bVrmEw_M94FY",
        "outputId": "d3e8b587-9a5e-427e-fed2-279e95abb62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-6d90e8177b62>:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(load_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== ./metrics.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_loss_list, valid_loss_list, global_steps_list = load_metrics('./metrics.pt')\n",
        "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "plt.xlabel('Global Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADDkiLkI94FY"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for text, label in test_loader:\n",
        "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "\n",
        "            sample = torch.tensor(padded_list)\n",
        "            sample, label = sample.to(device), label.to(device)\n",
        "            labels = torch.tensor(label)\n",
        "            output = model(sample, labels=labels)\n",
        "\n",
        "            _, output = output\n",
        "            y_pred.extend(torch.argmax(output, 1).tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "\n",
        "    print('Classification 결과:')\n",
        "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "    ax.xaxis.set_ticklabels(['0', '1'])\n",
        "    ax.yaxis.set_ticklabels(['0', '1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "ti0ZwzrK94FY",
        "outputId": "fc29903f-5e99-40c2-8517-86de7cc844dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-6d90e8177b62>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(load_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== ./model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-241e10d74e14>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(label)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       558\n",
            "           0     0.4909    1.0000    0.6585       538\n",
            "\n",
            "    accuracy                         0.4909      1096\n",
            "   macro avg     0.2454    0.5000    0.3293      1096\n",
            "weighted avg     0.2410    0.4909    0.3232      1096\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "best_model = model.to(device)\n",
        "load_checkpoint('./model.pt', best_model)\n",
        "evaluate(best_model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AS3XBu2GB83E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}