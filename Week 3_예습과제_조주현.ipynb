{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e88b4c-da32-4f08-aac6-07b4fc219875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable \n",
    "import torch.nn.functional as F \n",
    "\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms # 데이터 전처리를 위해 사용하는 라이브러리 \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "\n",
    "# GPU 혹은 CPU 장치 확인 \n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc368b6-5a1c-4d85-9a0c-605abbcfbb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 신경망 레이어 정의\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "933512e3-403a-4873-8fe6-65921ae1c2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = Net() \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1548d8-8812-437f-8d87-5a0ceab773f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = Net() \n",
    "if torch.cuda.device_count() > 1 : \n",
    "\tmodel = nn.DataParallel(net) \n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8585f4-af37-4f35-a2d7-95509d35712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST('../sample', download = True, \n",
    "                                                  transform = transforms.Compose([transforms.ToTensor()])) \n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST('../sample', download = True, train=False, \n",
    "                                                  transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410ae2c8-0e45-4217-aa6d-27b5753f626e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62bb31b-e402-4ca4-94b1-46f62690ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', \n",
    "              5 : 'Sandal', 6 : 'Shirt', 7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'}\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))  \n",
    "columns = 4\n",
    "rows = 5\n",
    "\n",
    "for i in range(1, columns*rows + 1): \n",
    "    img_xy = np.random.randint(len(train_dataset))  \n",
    "    img = train_dataset[img_xy][0][0,:,:]  # 이미지 선택\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.title(labels_map[train_dataset[img_xy][1]])  \n",
    "    plt.axis('off')  # 축 제거\n",
    "    plt.imshow(img, cmap='gray')  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "518fa2c6-16f6-44a8-be18-172826f3624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class FashionDNN(torch.nn.Module):\n",
    "\n",
    "  def __init__(self) : \n",
    "    super(FashionMNIST,self).__init__() \n",
    "    self.fc1 = nn.Linear(in_features = 784, out_features = 256) \n",
    "\n",
    "\n",
    "    self.drop = nn.Dropout(0.25) \n",
    "\n",
    "\n",
    "    self.fc2 = nn.Linear(in_features = 256, out_features = 128) \n",
    "    self.fc3 = nn.Linear(in_features = 128, out_features = 10) \n",
    "  \n",
    "  \n",
    "  def forward(self, input_data) : \n",
    "\n",
    "    out = input_data.view(-1,784) \n",
    "    out = F.relu(self.fc1(out)) \n",
    "    out = self.drop(out) \n",
    "    out = F.relu(self.fc2(out)) \n",
    "    out = self.fc3(out) \n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c690aad-e5c1-45c1-98b7-b8b990b94fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "inputs = torch.randn(64,3,224,224) \n",
    "weight = torch.randn(64,3,3,3) \n",
    "bias = torch.randn(64) \n",
    "outputs = F.conv2d(inputs, weight, bias, padding = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbeb96ae-9b40-417b-bba9-d10be8a155a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "inputs = torch.randn(64,3,224,224) \n",
    "conv = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding = 1) \n",
    "outputs = conv(inputs) \n",
    "layer = nn.Conv2d(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20be37b2-5d5f-487a-b3ad-21f338853d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the FashionDNN model class\n",
    "class FashionDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Correct the class name in super()\n",
    "        super(FashionDNN, self).__init__()\n",
    "        \n",
    "        # Example architecture\n",
    "        self.fc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=10)  # Assuming 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor\n",
    "        x = x.view(-1, 784)  # Assuming the input size is 28x28 (FashionMNIST)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Now you can initialize and use the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FashionDNN()\n",
    "model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example input\n",
    "inputs = torch.randn(64, 1, 28, 28).to(device)  # Simulating FashionMNIST input\n",
    "outputs = model(inputs)\n",
    "\n",
    "print(outputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ac68eae-3bc6-4292-8359-dd4bc91b1979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionDNN(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001 # 학습률 \n",
    "model = FashionDNN() \n",
    "model.to(device) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 분류문제 손실함수 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # 옵티마이저 \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a569d90-1ab0-4b68-bbad-ff72e794df94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionMNIST(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001 # 학습률 \n",
    "model = FashionMNIST() \n",
    "model.to(device) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 분류문제 손실함수 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # 옵티마이저 \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcadb44-9764-48ee-a38b-bacb90bdec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 횟수 : 500, 오차 : 0.7899177670478821, 정확도 : 82.54%\n",
      "반복 횟수 : 1000, 오차 : 0.38939008116722107, 정확도 : 83.96%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Dataset setup\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 5 \n",
    "count = 0 \n",
    "loss_list = [] # 오차 \n",
    "iteration_list = [] # 반복횟수 \n",
    "accuracy_list = [] # 정확도 \n",
    "predictions_list = [] # 예측값 \n",
    "labels_list = [] # 실제값 \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):  # 전체 데이터를 5번 훈련\n",
    "    for images, labels in train_loader: \n",
    "        images, labels = images.to(device), labels.to(device) \n",
    "\n",
    "        train = Variable(images.view(100, 1, 28, 28))  # Reshape to batch size 100\n",
    "        labels = Variable(labels) \n",
    "\n",
    "        outputs = model(train) \n",
    "        loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        count += 1 \n",
    "\n",
    "        if count % 50 == 0:  # 50번 반복마다 예측\n",
    "            total = 0 \n",
    "            correct = 0 \n",
    "\n",
    "            for images, labels in test_loader: \n",
    "                images, labels = images.to(device), labels.to(device) \n",
    "                labels_list.append(labels) \n",
    "                test = Variable(images.view(100, 1, 28, 28))  # Reshape for testing\n",
    "                outputs = model(test) \n",
    "                predictions = torch.max(outputs, 1)[1].to(device) \n",
    "                predictions_list.append(predictions) \n",
    "                correct += (predictions == labels).sum().item()  # Correct predictions\n",
    "                total += len(labels) \n",
    "      \n",
    "            accuracy = correct * 100 / total  # Calculate accuracy\n",
    "            loss_list.append(loss.item())  # Log loss\n",
    "            iteration_list.append(count) \n",
    "            accuracy_list.append(accuracy) \n",
    "\n",
    "        if count % 500 == 0:  # 500 반복마다 로그\n",
    "            print(f'반복 횟수 : {count}, 오차 : {loss.item()}, 정확도 : {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6f991-51db-4b80-9062-1ece97185ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
