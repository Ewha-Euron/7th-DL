{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmbrNadxsBr7"
   },
   "source": [
    "## Convolution Layer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAyG6GGTU_mC",
    "outputId": "118b0f42-fde5-4900-8cea-f4c8709818d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연산 전 torch.Size([10, 1, 20, 20])\n",
      "conv1 연산 후 torch.Size([10, 64, 16, 16])\n",
      "conv2 연산 후 torch.Size([10, 64, 12, 12])\n",
      "차원 감소 후 torch.Size([64, 1440])\n",
      "fc1 연산 후 torch.Size([64, 256])\n",
      "fc2 연산 후 torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(CNN, self).__init__()\n",
    "      self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1)\n",
    "      self.conv2 = nn.Conv2d(64, 64, kernel_size=5, stride=1)\n",
    "      self.fc1 = nn.Linear(10 * 12 * 12, 256)\n",
    "      self.fc2 = nn.Linear(256, 10)\n",
    "      \n",
    "    ## 조건1: conv layer 2개 & fc layer 2개\n",
    "    ## 조건2: kernel size=5, stride=1로 통일\n",
    "    ## output을 참고하여 차원을 계산해주세요!\n",
    "    \n",
    "  def forward(self, x):\n",
    "    print(\"연산 전\", x.size())\n",
    "    x = F.relu(self.conv1(x))\n",
    "    print(\"conv1 연산 후\", x.size())\n",
    "    x = F.relu(self.conv2(x))\n",
    "    print(\"conv2 연산 후\",x.size())\n",
    "    x = x.view(-1, 10 * 12 * 12)\n",
    "    print(\"차원 감소 후\", x.size())\n",
    "    x = F.relu(self.fc1(x))\n",
    "    print(\"fc1 연산 후\", x.size())\n",
    "    x = self.fc2(x)\n",
    "    print(\"fc2 연산 후\", x.size())\n",
    "    return x\n",
    "\n",
    "cnn = CNN()\n",
    "output = cnn(torch.randn(10, 1, 20, 20))  # Input Size: (10, 1, 20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0It8H-mysBr-"
   },
   "source": [
    "## Max Pooling Layer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkOwXPFNchie",
    "outputId": "a3f022de-8d54-4cf8-9456-f9bbc15ed9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연산 전 torch.Size([10, 1, 20, 20])\n",
      "max_pool1 연산 후 torch.Size([10, 1, 10, 10])\n",
      "max_pool2 연산 후 torch.Size([10, 1, 5, 5])\n",
      "차원 감소 후 torch.Size([1, 250])\n",
      "fc1 연산 후 torch.Size([1, 256])\n",
      "fc2 연산 후 torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    self.max_pool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "    self.max_pool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "    self.fc1 = nn.Linear(10 * 5 * 5, 256)\n",
    "    self.fc2 = nn.Linear(256, 10)\n",
    "      \n",
    "    ## 조건1: 최대풀링 layer 2개 & fc layer 2개\n",
    "    ## 조건2: kernel size=2로 통일, stride는 따로 지정할 필요 없음\n",
    "    ## output을 참고하여 차원을 계산해주세요!\n",
    "    ## 답안 ##\n",
    "\n",
    "  def forward(self, x):\n",
    "    print(\"연산 전\", x.size())\n",
    "    x = F.relu(self.max_pool1(x))\n",
    "    print(\"max_pool1 연산 후\", x.size())\n",
    "    x = F.relu(self.max_pool2(x))\n",
    "    print(\"max_pool2 연산 후\",x.size())\n",
    "    x = x.view(-1, 10 * 5 * 5)\n",
    "    print(\"차원 감소 후\", x.size())\n",
    "    x = F.relu(self.fc1(x))\n",
    "    print(\"fc1 연산 후\", x.size())\n",
    "    x = self.fc2(x)\n",
    "    print(\"fc2 연산 후\", x.size())\n",
    "    return x\n",
    "\n",
    "cnn = CNN()\n",
    "output = cnn(torch.randn(10, 1, 20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDMn2y5_sBr-"
   },
   "source": [
    "## MNIST 데이터셋 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhfopkrQcp1P"
   },
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "CqFN5YM5cqKe"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "IJb_C4ptcu6G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9.91M/9.91M [00:03<00:00, 3.22MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 142kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1.65M/1.65M [00:01<00:00, 1.33MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 949kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST('./data/', train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])) # 학습 데이터\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=50, shuffle=True)\n",
    "\n",
    "test_data = datasets.MNIST('./data/', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])) # 테스트 데이터\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "YP3tEuo6ct8A"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 20, kernel_size = 5, stride = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 20, out_channels = 50, kernel_size = 5, stride = 1)\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "        ## 조건1: conv layer 2개 & fc layer 2개\n",
    "            ## 첫 번째 conv layer: 입력 채널 1, 출력 채널 20\n",
    "            ## 두 번째 fc layer: 출력 채널 10\n",
    "        ## 조건2: kernel_size=5, stride=1\n",
    "        ## 답안 ##\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ## 조건1: relu -> max_pool2d -> relu -> max_pool2d 순서로 이루어짐\n",
    "        ## 조건2: kernel_size=2, stride=2\n",
    "        ## 답안 ##\n",
    "        x = F.relu(self.conv1(x))    \n",
    "        x = self.max_pool2d(x)          \n",
    "        x = F.relu(self.conv2(x))       \n",
    "        x = self.max_pool2d(x) \n",
    "        \n",
    "        x = x.view(-1, 4 * 4 * 50) # [batch_size, 50, 4, 4]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "EO2ULx3Sc2GM"
   },
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gAwckNWhc4Nr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0 epoch, 0 index : 2.3078196048736572\n",
      "loss of 0 epoch, 100 index : 0.9603529572486877\n",
      "loss of 0 epoch, 200 index : 0.3161846101284027\n",
      "loss of 0 epoch, 300 index : 0.27530181407928467\n",
      "loss of 0 epoch, 400 index : 0.34337443113327026\n",
      "loss of 0 epoch, 500 index : 0.4550118148326874\n",
      "loss of 0 epoch, 600 index : 0.10822367668151855\n",
      "loss of 0 epoch, 700 index : 0.15065161883831024\n",
      "loss of 0 epoch, 800 index : 0.19055214524269104\n",
      "loss of 0 epoch, 900 index : 0.1116824522614479\n",
      "loss of 0 epoch, 1000 index : 0.2636948525905609\n",
      "loss of 0 epoch, 1100 index : 0.22089819610118866\n",
      "loss of 1 epoch, 0 index : 0.16090740263462067\n",
      "loss of 1 epoch, 100 index : 0.2011134922504425\n",
      "loss of 1 epoch, 200 index : 0.1267019808292389\n",
      "loss of 1 epoch, 300 index : 0.1540980339050293\n",
      "loss of 1 epoch, 400 index : 0.12783610820770264\n",
      "loss of 1 epoch, 500 index : 0.17173506319522858\n",
      "loss of 1 epoch, 600 index : 0.04530687630176544\n",
      "loss of 1 epoch, 700 index : 0.18114271759986877\n",
      "loss of 1 epoch, 800 index : 0.038067515939474106\n",
      "loss of 1 epoch, 900 index : 0.15647082030773163\n",
      "loss of 1 epoch, 1000 index : 0.3608699440956116\n",
      "loss of 1 epoch, 1100 index : 0.06797561794519424\n",
      "loss of 2 epoch, 0 index : 0.11541517078876495\n",
      "loss of 2 epoch, 100 index : 0.1645435094833374\n",
      "loss of 2 epoch, 200 index : 0.02078521065413952\n",
      "loss of 2 epoch, 300 index : 0.05832447484135628\n",
      "loss of 2 epoch, 400 index : 0.04755982384085655\n",
      "loss of 2 epoch, 500 index : 0.16678671538829803\n",
      "loss of 2 epoch, 600 index : 0.1622900515794754\n",
      "loss of 2 epoch, 700 index : 0.06882907450199127\n",
      "loss of 2 epoch, 800 index : 0.01626431569457054\n",
      "loss of 2 epoch, 900 index : 0.05102720111608505\n",
      "loss of 2 epoch, 1000 index : 0.021242445334792137\n",
      "loss of 2 epoch, 1100 index : 0.0247732512652874\n",
      "loss of 3 epoch, 0 index : 0.11114172637462616\n",
      "loss of 3 epoch, 100 index : 0.0250721238553524\n",
      "loss of 3 epoch, 200 index : 0.0586322657763958\n",
      "loss of 3 epoch, 300 index : 0.014000441879034042\n",
      "loss of 3 epoch, 400 index : 0.22287411987781525\n",
      "loss of 3 epoch, 500 index : 0.09995132684707642\n",
      "loss of 3 epoch, 600 index : 0.04722202941775322\n",
      "loss of 3 epoch, 700 index : 0.13266626000404358\n",
      "loss of 3 epoch, 800 index : 0.03125564754009247\n",
      "loss of 3 epoch, 900 index : 0.03812834620475769\n",
      "loss of 3 epoch, 1000 index : 0.09457781910896301\n",
      "loss of 3 epoch, 1100 index : 0.10029955953359604\n",
      "loss of 4 epoch, 0 index : 0.04085197299718857\n",
      "loss of 4 epoch, 100 index : 0.012652411125600338\n",
      "loss of 4 epoch, 200 index : 0.040815319865942\n",
      "loss of 4 epoch, 300 index : 0.03760003671050072\n",
      "loss of 4 epoch, 400 index : 0.06668862700462341\n",
      "loss of 4 epoch, 500 index : 0.06177621707320213\n",
      "loss of 4 epoch, 600 index : 0.012403827160596848\n",
      "loss of 4 epoch, 700 index : 0.036130018532276154\n",
      "loss of 4 epoch, 800 index : 0.10204970091581345\n",
      "loss of 4 epoch, 900 index : 0.00918521173298359\n",
      "loss of 4 epoch, 1000 index : 0.05394919216632843\n",
      "loss of 4 epoch, 1100 index : 0.03152595832943916\n",
      "loss of 5 epoch, 0 index : 0.15702183544635773\n",
      "loss of 5 epoch, 100 index : 0.00964679941534996\n",
      "loss of 5 epoch, 200 index : 0.024362223222851753\n",
      "loss of 5 epoch, 300 index : 0.014999844133853912\n",
      "loss of 5 epoch, 400 index : 0.020705753937363625\n",
      "loss of 5 epoch, 500 index : 0.012074584141373634\n",
      "loss of 5 epoch, 600 index : 0.0031065980438143015\n",
      "loss of 5 epoch, 700 index : 0.007924522273242474\n",
      "loss of 5 epoch, 800 index : 0.012501038610935211\n",
      "loss of 5 epoch, 900 index : 0.02770679071545601\n",
      "loss of 5 epoch, 1000 index : 0.04562275856733322\n",
      "loss of 5 epoch, 1100 index : 0.04375755414366722\n",
      "loss of 6 epoch, 0 index : 0.1884617954492569\n",
      "loss of 6 epoch, 100 index : 0.04043801873922348\n",
      "loss of 6 epoch, 200 index : 0.023414719849824905\n",
      "loss of 6 epoch, 300 index : 0.14074552059173584\n",
      "loss of 6 epoch, 400 index : 0.04368726164102554\n",
      "loss of 6 epoch, 500 index : 0.026981689035892487\n",
      "loss of 6 epoch, 600 index : 0.014360031113028526\n",
      "loss of 6 epoch, 700 index : 0.05184029042720795\n",
      "loss of 6 epoch, 800 index : 0.0025766370818018913\n",
      "loss of 6 epoch, 900 index : 0.011702287942171097\n",
      "loss of 6 epoch, 1000 index : 0.07211420685052872\n",
      "loss of 6 epoch, 1100 index : 0.029713695868849754\n",
      "loss of 7 epoch, 0 index : 0.1067495122551918\n",
      "loss of 7 epoch, 100 index : 0.009832775220274925\n",
      "loss of 7 epoch, 200 index : 0.011364344507455826\n",
      "loss of 7 epoch, 300 index : 0.015814954414963722\n",
      "loss of 7 epoch, 400 index : 0.017580414190888405\n",
      "loss of 7 epoch, 500 index : 0.003299275878816843\n",
      "loss of 7 epoch, 600 index : 0.028114721179008484\n",
      "loss of 7 epoch, 700 index : 0.0012416422832757235\n",
      "loss of 7 epoch, 800 index : 0.007393480744212866\n",
      "loss of 7 epoch, 900 index : 0.05926772207021713\n",
      "loss of 7 epoch, 1000 index : 0.025167124345898628\n",
      "loss of 7 epoch, 1100 index : 0.015844035893678665\n",
      "loss of 8 epoch, 0 index : 0.0020291174296289682\n",
      "loss of 8 epoch, 100 index : 0.09532418102025986\n",
      "loss of 8 epoch, 200 index : 0.006194651126861572\n",
      "loss of 8 epoch, 300 index : 0.034055858850479126\n",
      "loss of 8 epoch, 400 index : 0.0034426262136548758\n",
      "loss of 8 epoch, 500 index : 0.005224176682531834\n",
      "loss of 8 epoch, 600 index : 0.1445891410112381\n",
      "loss of 8 epoch, 700 index : 0.027879707515239716\n",
      "loss of 8 epoch, 800 index : 0.08084966987371445\n",
      "loss of 8 epoch, 900 index : 0.03180282562971115\n",
      "loss of 8 epoch, 1000 index : 0.004492260981351137\n"
     ]
    }
   ],
   "source": [
    "cnn.train()  # 학습을 위함\n",
    "for epoch in range(10):\n",
    "  for index, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()  # 기울기 초기화\n",
    "    output = cnn(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()  # 역전파\n",
    "    optimizer.step()\n",
    "\n",
    "    if index % 100 == 0:\n",
    "      print(\"loss of {} epoch, {} index : {}\".format(epoch, index, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2PnlaXIc6dm"
   },
   "outputs": [],
   "source": [
    "cnn.eval()  # test case 학습 방지를 위함\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "  for data, target in test_loader:\n",
    "    output = cnn(data)\n",
    "    test_loss += criterion(output, target).item() # sum up batch loss\n",
    "    pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
