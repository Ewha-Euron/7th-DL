{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "_01C1NDoAmIQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "arqtm-7FAmjI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizeString(df, lang):\n",
        "    sentence = df[lang].str.lower()\n",
        "    sentence = sentence.str.replace('[^A-Za-z\\s]+', '')\n",
        "    sentence = sentence.str.normalize('NFD')\n",
        "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "    return sentence\n",
        "\n",
        "def read_sentence(df, lang1, lang2):\n",
        "    sentence1 = normalizeString(df, lang1)\n",
        "    sentence2 = normalizeString(df, lang2)\n",
        "    return sentence1, sentence2\n",
        "\n",
        "def read_file(loc, lang1, lang2):\n",
        "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2])\n",
        "    return df\n",
        "\n",
        "def process_data(lang1,lang2):\n",
        "    df = read_file('./eng-fra.txt', lang1, lang2)\n",
        "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
        "\n",
        "    input_lang = Lang()\n",
        "    output_lang = Lang()\n",
        "    pairs = []\n",
        "    for i in range(len(df)):\n",
        "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
        "            full = [sentence1[i], sentence2[i]]\n",
        "            input_lang.addSentence(sentence1[i])\n",
        "            output_lang.addSentence(sentence2[i])\n",
        "            pairs.append(full)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "X8r1GMf4AoKA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(input_lang, output_lang, pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "ysJ6Uo0CAu-4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_dim, self.embbed_dim)\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src).view(1,1,-1)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "f7xDqOA1AvdI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, self.embbed_dim)\n",
        "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.view(1, -1)\n",
        "        embedded = F.relu(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        prediction = self.softmax(self.out(output[0]))\n",
        "        return prediction, hidden"
      ],
      "metadata": {
        "id": "DAQuLhZ-Aw8K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        input_length = input_lang.size(0)\n",
        "        batch_size = output_lang.shape[1]\n",
        "        target_length = output_lang.shape[0]\n",
        "        vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
        "\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = self.encoder(input_lang[i])\n",
        "\n",
        "        decoder_hidden = encoder_hidden.to(device)\n",
        "        decoder_input = torch.tensor([SOS_token], device=device)\n",
        "\n",
        "        for t in range(target_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            outputs[t] = decoder_output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            input = (output_lang[t] if teacher_force else topi)\n",
        "            if(teacher_force == False and input.item() == EOS_token):\n",
        "                break\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "Ggh7YWt1AyfZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def Model(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
        "    model_optimizer.zero_grad()\n",
        "    input_length = input_tensor.size(0)\n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    output = model(input_tensor, target_tensor)\n",
        "    num_iter = output.size(0)\n",
        "\n",
        "    for ot in range(num_iter):\n",
        "        loss += criterion(output[ot], target_tensor[ot])\n",
        "\n",
        "    loss.backward()\n",
        "    model_optimizer.step()\n",
        "    epoch_loss = loss.item() / num_iter\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "uqi63L9nA0AR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel(model, input_lang, output_lang, pairs, num_iteration=20000):\n",
        "    model.train()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.NLLLoss()\n",
        "    total_loss_iterations = 0\n",
        "\n",
        "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
        "                      for i in range(num_iteration)]\n",
        "\n",
        "    for iter in range(1, num_iteration+1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = Model(model, input_tensor, target_tensor, optimizer, criterion)\n",
        "        total_loss_iterations += loss\n",
        "\n",
        "        if iter % 5000 == 0:\n",
        "            avarage_loss= total_loss_iterations / 5000\n",
        "            total_loss_iterations = 0\n",
        "            print('%d %.4f' % (iter, avarage_loss))\n",
        "\n",
        "    torch.save(model.state_dict(), f'./mytraining.pt')\n",
        "    return model"
      ],
      "metadata": {
        "id": "9xkETvuFA1fY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
        "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
        "        decoded_words = []\n",
        "        output = model(input_tensor, output_tensor)\n",
        "\n",
        "        for ot in range(output.size(0)):\n",
        "            topv, topi = output[ot].topk(1)\n",
        "\n",
        "            if topi[0].item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
        "    return decoded_words\n",
        "\n",
        "def evaluateRandomly(model, input_lang, output_lang, pairs, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('input {}'.format(pair[0]))\n",
        "        print('output {}'.format(pair[1]))\n",
        "        output_words = evaluate(model, input_lang, output_lang, pair)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('predicted {}'.format(output_sentence))"
      ],
      "metadata": {
        "id": "djCg4TI1A97o"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang1 = 'eng'\n",
        "lang2 = 'fra'\n",
        "input_lang, output_lang, pairs = process_data(lang1, lang2)\n",
        "\n",
        "randomize = random.choice(pairs)\n",
        "print('random sentence {}'.format(randomize))\n",
        "\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "print('Input : {} Output : {}'.format(input_size, output_size))\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_iteration = 75000\n",
        "\n",
        "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "print(encoder)\n",
        "print(decoder)\n",
        "\n",
        "model = trainModel(model, input_lang, output_lang, pairs, num_iteration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "fAnnnKv5A_sY",
        "outputId": "1d1c53d8-b2e9-4b88-b286-f29f5f331e6b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random sentence ['my new job leaves me little time to socialize.', 'mon nouvel emploi me laisse peu de temps pour rencontrer des gens.']\n",
            "Input : 23191 Output : 39387\n",
            "Encoder(\n",
            "  (embedding): Embedding(23191, 256)\n",
            "  (gru): GRU(256, 512)\n",
            ")\n",
            "Decoder(\n",
            "  (embedding): Embedding(39387, 256)\n",
            "  (gru): GRU(256, 512)\n",
            "  (out): Linear(in_features=512, out_features=39387, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c592d37ecc03>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-6f45e19f1e3a>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(model, input_lang, output_lang, pairs, num_iteration)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtotal_loss_iterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-74f0bbe58d20>\u001b[0m in \u001b[0;36mModel\u001b[0;34m(model, input_tensor, target_tensor, model_optimizer, criterion)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(model, input_lang, output_lang, pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqIsrG-0BBey",
        "outputId": "5c9c571d-f2e9-4643-e8e0-7af83c362b40"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input i want you to be prepared.\n",
            "output je veux que vous soyez preparees.\n",
            "predicted je ne de ? ? ? ?\n",
            "input tom knows almost nothing about mary.\n",
            "output tom ne sait presque rien a propos de mary.\n",
            "predicted je ne de ? ? ? ? ? ? ?\n",
            "input what game do you want to play now?\n",
            "output a quel jeu voulez-vous jouer, maintenant ?\n",
            "predicted je ne de ? ? ? ? ?\n",
            "input you had better prepare for the future.\n",
            "output vous feriez mieux de vous appreter pour le futur.\n",
            "predicted je ne de ? ? ? ? ? ? ?\n",
            "input you should lower your standards.\n",
            "output vous devriez abaisser vos pretentions.\n",
            "predicted je ne de ? ? ?\n",
            "input we took an examination in math last week.\n",
            "output nous avons passe un examen de mathematiques la semaine passee.\n",
            "predicted je ne de ? ? ? ? ? ? ? ?\n",
            "input i'm very upset.\n",
            "output je suis fort contrariee.\n",
            "predicted je ne de ? ?\n",
            "input he saw it, too.\n",
            "output il la vu aussi.\n",
            "predicted je ne de ? ?\n",
            "input he sees nothing wrong with it.\n",
            "output il n'y voit rien de mal.\n",
            "predicted je ne de ? ? ? ?\n",
            "input is this typewriter yours?\n",
            "output cette machine a ecrire est-elle la tienne ?\n",
            "predicted je ne de ? ? ? ? ? ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "f1s-oDO5BDXA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = Model(model, input_tensor, target_tensor, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % 5000 == 0:\n",
        "            print_loss_avg = print_loss_total / 5000\n",
        "            print_loss_total = 0\n",
        "            print('%d,  %.4f' % (iter, print_loss_avg))"
      ],
      "metadata": {
        "id": "USxd62F1BFqu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "\n",
        "encoder1 = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_size, dropout_p=0.1).to(device)\n",
        "\n",
        "print(encoder1)\n",
        "print(attn_decoder1)\n",
        "\n",
        "attn_model = trainIters(encoder1, attn_decoder1, 75000, print_every=5000, plot_every=100, learning_rate=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOcZnZEXBHaH",
        "outputId": "a06dc1c9-d111-4393-f87f-3d8d56a56a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(23191, 256)\n",
            "  (gru): GRU(256, 512)\n",
            ")\n",
            "AttnDecoderRNN(\n",
            "  (embedding): Embedding(39387, 512)\n",
            "  (attn): Linear(in_features=1024, out_features=20, bias=True)\n",
            "  (attn_combine): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (gru): GRU(512, 512)\n",
            "  (out): Linear(in_features=512, out_features=39387, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0wON206729p",
        "outputId": "536de3fb-02a6-489a-97fe-11fbfec416c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfpY8SB-77V3",
        "outputId": "4610dba4-e843-48fc-b97a-45b8752df174"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (1.26.4)\n",
            "Collecting boto3 (from pytorch-transformers)\n",
            "  Downloading boto3-1.35.90-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2024.11.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (0.2.0)\n",
            "Collecting sacremoses (from pytorch-transformers)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->pytorch-transformers) (1.3.0)\n",
            "Collecting botocore<1.36.0,>=1.35.90 (from boto3->pytorch-transformers)\n",
            "  Downloading botocore-1.35.90-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-transformers)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->pytorch-transformers)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2024.12.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.90->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.90->boto3->pytorch-transformers) (1.17.0)\n",
            "Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.90-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.90-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "Successfully installed boto3-1.35.90 botocore-1.35.90 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.10.4 sacremoses-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "OIVGRlWQ799Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./training.txt', sep='\\t')\n",
        "valid_df = pd.read_csv('./validing.txt', sep='\\t')\n",
        "test_df = pd.read_csv('./testing.txt', sep='\\t')"
      ],
      "metadata": {
        "id": "B7vzWhvl8ITJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.sample(frac=0.1, random_state=500)\n",
        "valid_df = valid_df.sample(frac=0.1, random_state=500)\n",
        "test_df = test_df.sample(frac=0.1, random_state=500)"
      ],
      "metadata": {
        "id": "txpHn4K48xSJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Datasets(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx, 1]\n",
        "        label = self.df.iloc[idx, 2]\n",
        "        return text, label"
      ],
      "metadata": {
        "id": "SCa_TWFj9D_I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Datasets(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "valid_dataset = Datasets(valid_df)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "test_dataset = Datasets(test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "u7pDfMbp9Fro"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voxX552w9HQ_",
        "outputId": "ad471ea2-150b-4871-fae9-7273bb36dee0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 310923.87B/s]\n",
            "100%|██████████| 433/433 [00:00<00:00, 133069.58B/s]\n",
            "100%|██████████| 440473133/440473133 [00:28<00:00, 15686440.03B/s]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_transformers/modeling_utils.py:539: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(resolved_archive_file, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):\n",
        "    if load_path==None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_metrics(load_path):\n",
        "    if load_path==None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ],
      "metadata": {
        "id": "jVfUH9HX9JdR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          optimizer,\n",
        "          criterion = nn.BCELoss(),\n",
        "          num_epochs = 5,\n",
        "          eval_every = len(train_loader) // 2,\n",
        "          best_valid_loss = float(\"Inf\")):\n",
        "\n",
        "    total_correct = 0.0\n",
        "    total_len = 0.0\n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for text, label in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "\n",
        "            sample = torch.tensor(padded_list)\n",
        "            sample, label = sample.to(device), label.to(device)\n",
        "            labels = torch.tensor(label)\n",
        "            outputs = model(sample, labels=labels)\n",
        "            loss, logits = outputs\n",
        "\n",
        "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "            correct = pred.eq(labels)\n",
        "            total_correct += correct.sum().item()\n",
        "            total_len += len(labels)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_every == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    for text, label in valid_loader:\n",
        "                        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "                        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "                        sample = torch.tensor(padded_list)\n",
        "                        sample, label = sample.to(device), label.to(device)\n",
        "                        labels = torch.tensor(label)\n",
        "                        outputs = model(sample, labels=labels)\n",
        "                        loss, logits = outputs\n",
        "                        valid_running_loss += loss.item()\n",
        "\n",
        "                average_train_loss = running_loss / eval_every\n",
        "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                running_loss = 0.0\n",
        "                valid_running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
        "                              average_train_loss, average_valid_loss))\n",
        "\n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint('/content/drive/MyDrive/Colab Notebooks/model.pt', model, best_valid_loss)\n",
        "                    save_metrics('/content/drive/MyDrive/Colab Notebooks/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "\n",
        "    save_metrics('./metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    print('훈련 종료!')"
      ],
      "metadata": {
        "id": "ipo9khmJ9WIh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "train(model=model, optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "wik44wnn9ZiR",
        "outputId": "f18a6d51-aad2-4651-bc5f-5dcd9baa4b9c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-ea9050ff6432>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(label)\n",
            "<ipython-input-11-ea9050ff6432>:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred = torch.argmax(F.softmax(logits), dim=1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ef60a3c0af9f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-ea9050ff6432>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, num_epochs, eval_every, best_valid_loss)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtotal_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list, valid_loss_list, global_steps_list = load_metrics('/content/drive/MyDrive/Colab Notebooks/metrics.pt')\n",
        "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "plt.xlabel('Global Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fO-4PNfQ9b7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for text, label in test_loader:\n",
        "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "\n",
        "            sample = torch.tensor(padded_list)\n",
        "            sample, label = sample.to(device), label.to(device)\n",
        "            labels = torch.tensor(label)\n",
        "            output = model(sample, labels=labels)\n",
        "\n",
        "            _, output = output\n",
        "            y_pred.extend(torch.argmax(output, 1).tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "\n",
        "    print('Classification 결과:')\n",
        "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "    ax.xaxis.set_ticklabels(['0', '1'])\n",
        "    ax.yaxis.set_ticklabels(['0', '1'])"
      ],
      "metadata": {
        "id": "MkYsQqX5_HOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "best_model = model.to(device)\n",
        "load_checkpoint('/content/drive/MyDrive/Colab Notebooks/model.pt', best_model)\n",
        "evaluate(best_model, test_loader)"
      ],
      "metadata": {
        "id": "jyxYji7x_HqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "metadata": {
        "id": "BhcxkgkY_KDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"나는 파이토치를 이용한 딥러닝을 학습중이다.\"\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "ux3HHiFd_Msr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"과수원에 사과가 많았다.\" \\\n",
        "       \"친구가 나에게 사과했다.\"\\\n",
        "       \"백설공주는 독이 든 사과를 먹었다.\"\n",
        "\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
      ],
      "metadata": {
        "id": "uc5KEc0n_Ocf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments_ids = [1] * len(tokenized_text)\n",
        "print (segments_ids)"
      ],
      "metadata": {
        "id": "XdMaBo3N_QII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])"
      ],
      "metadata": {
        "id": "lFPecLtx_Rni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained('bert-base-multilingual-cased',\n",
        "                                  output_hidden_states = True,)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "t3KkljR3_TKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    hidden_states = outputs[2]"
      ],
      "metadata": {
        "id": "nkhZfUUG_Uco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"계층 수:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "layer_i = 0\n",
        "\n",
        "print (\"배치 수:\", len(hidden_states[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"토큰 수:\", len(hidden_states[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"은닉층 유닛 수:\", len(hidden_states[layer_i][batch_i][token_i]))"
      ],
      "metadata": {
        "id": "-R7jxHuZ_XAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('은닉 상태의 유형: ', type(hidden_states))\n",
        "print('각 계층에서의 텐서 형태: ', hidden_states[0].size())"
      ],
      "metadata": {
        "id": "GzA3GliC_ZKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "token_embeddings.size()"
      ],
      "metadata": {
        "id": "62VL-E0i_afn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "token_embeddings.size()"
      ],
      "metadata": {
        "id": "Dk43ZQLS_b8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "token_embeddings.size()"
      ],
      "metadata": {
        "id": "HVVeGt8a_dh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_vecs_cat = []\n",
        "for token in token_embeddings:\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "print ('형태는: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "metadata": {
        "id": "InMl_dM7_e5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_vecs_sum = []\n",
        "for token in token_embeddings:\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "print ('형태는: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
      ],
      "metadata": {
        "id": "2dAd-Oi2_gTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_vecs = hidden_states[-2][0]\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "print (\"최종 임베딩 벡터의 형태:\", sentence_embedding.size())"
      ],
      "metadata": {
        "id": "P5hLICWO_iL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "    print (i, token_str)"
      ],
      "metadata": {
        "id": "enO5_f3w_joz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"사과가 많았다\", str(token_vecs_sum[6][:5]))\n",
        "print(\"나에게 사과했다\", str(token_vecs_sum[10][:5]))\n",
        "print(\"사과를 먹었다\", str(token_vecs_sum[19][:5]))"
      ],
      "metadata": {
        "id": "uxM5BPGE_kzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "diff_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[27])\n",
        "same_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[16])\n",
        "print('*유사한* 의미에 대한 벡터 유사성:  %.2f' % same_apple)\n",
        "print('*다른* 의미에 대한 벡터 유사성:  %.2f' % diff_apple)"
      ],
      "metadata": {
        "id": "lpWAq-9s_mPw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}